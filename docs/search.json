[
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "La presente evaluación tiene por objetivo que las y los estudiantes apliquen de forma integral los contenidos del curso a una temática de interés específica utilizando la base de datos del Estudio Social Longitudinal de Chile (ELSOC) 2022, en formato de reporte de investigación breve. Se espera un ejercicio de investigación que logre dar cuenta del aprendizaje de las herramientas de análisis estadístico que configuran las habilidades básicas para desarrollar procesos de investigación social, analizando fuentes de información de carácter cuantitativo desde una perspectiva sociológica.\nEn este informe, los estudiantes deberán elaborar un reporte de investigación que desarrolle de forma integrada los aspectos de diseño de la investigación, análisis estadístico y presentación de resultados, así como la elaboración de conclusiones.\nCuestiones a considerar:\n\nEl trabajo debe ser realizado en parejas\nSe realizará una entrega final tipo reporte de investigación, que se irá construyendo a lo largo del semestre\nSe recomienda que elaboren un problema de investigación que trate sobre las características sociales de algún problema actual de la sociedad chilena, y que sea factible de investigar con los datos del Estudio Social Longitudinal de Chile (ELSOC) 2022.\nLa investigación a desarrollar debe ser de tipo descriptiva, esto quiere decir que se trata de una pregunta de investigación que se refiere a la forma, magnitud o características que tienen unas determinadas variables en una población."
  },
  {
    "objectID": "trabajos.html#evaluación",
    "href": "trabajos.html#evaluación",
    "title": "Trabajos",
    "section": "",
    "text": "La presente evaluación tiene por objetivo que las y los estudiantes apliquen de forma integral los contenidos del curso a una temática de interés específica utilizando la base de datos del Estudio Social Longitudinal de Chile (ELSOC) 2022, en formato de reporte de investigación breve. Se espera un ejercicio de investigación que logre dar cuenta del aprendizaje de las herramientas de análisis estadístico que configuran las habilidades básicas para desarrollar procesos de investigación social, analizando fuentes de información de carácter cuantitativo desde una perspectiva sociológica.\nEn este informe, los estudiantes deberán elaborar un reporte de investigación que desarrolle de forma integrada los aspectos de diseño de la investigación, análisis estadístico y presentación de resultados, así como la elaboración de conclusiones.\nCuestiones a considerar:\n\nEl trabajo debe ser realizado en parejas\nSe realizará una entrega final tipo reporte de investigación, que se irá construyendo a lo largo del semestre\nSe recomienda que elaboren un problema de investigación que trate sobre las características sociales de algún problema actual de la sociedad chilena, y que sea factible de investigar con los datos del Estudio Social Longitudinal de Chile (ELSOC) 2022.\nLa investigación a desarrollar debe ser de tipo descriptiva, esto quiere decir que se trata de una pregunta de investigación que se refiere a la forma, magnitud o características que tienen unas determinadas variables en una población."
  },
  {
    "objectID": "trabajos.html#instrucciones",
    "href": "trabajos.html#instrucciones",
    "title": "Trabajos",
    "section": "Instrucciones",
    "text": "Instrucciones\nPara la entrega del informe se espera que, habiendo seleccionado un fenómeno específico de interés, se desarrollen los siguientes puntos:\n\n\n\n\n\n\n\n\nCOMPONENTES\nDETALLE\nPUNTAJE\n\n\nFormulación del problema\nFundamente el interés sociológico que habilita el estudio de la temática elegida (¿Qué se va a estudiar?, ¿Por qué es importante?, ¿Qué se sabe sobre el tema?), utilizando al menos 3 referencias bibliográficas. Además, formule una pregunta y un objetivo general de investigación. Estos deben ser coherentes entre sí y con la formulación del problema expuesta en el apartado anterior. El objetivo de investigación formulado debe permitir entender cómo se analizará la temática elegida. Además, la pregunta debe ser de carácter descriptiva. (1 plana)\n1,0\n\n\n\n\nDefinición base de datos\nDefina la fuente de información a utilizar indicando el nombre de la base de datos y la institución que la disponibiliza, la población que busca representar el estudio, el procedimiento de muestreo utilizado y el tamaño de la muestra. Dado que trabajaremos solo con el Estudio Social Longitudinal de Chile (ELSOC) 2022, se espera que los grupos describan qué busca medir y representar el módulo de la encuesta elegido. (½ plana)\n0,5\n\n\n\n\nDefinición variables a utilizar\nSeleccionar un mínimo de 4 variables para, mediante su estudio, responder a la pregunta de investigación. Todas las variables deben remitir al tema de interés: 2 de las variables deben ser de nivel de medición de intervalo o razón, 1 variable debe ser de nivel de medición ordinal y 1 variable debe ser de nivel de medición nominal, además, un conjunto de variables para armar una escala o índice.\nPara cada variable debe indicar: i) una breve descripción que especifique el nivel de medición de la  variable, su nombre en la base de datos y el fraseo en la encuesta, ii) explique qué aspecto del fenómeno de interés representa y iii) su utilidad para resolver la pregunta de investigación. La selección de variables debe ser coherente con la formulación del problema y la pregunta y objetivos de investigación propuestos. (1 plana)\n2,0\n\n\nTablas de frecuencia\nCalcular una tabla de frecuencia (absoluta y relativa) para las variables nominales y ordinales e interpretar. La interpretación de tablas debe buscar aportar con elementos que permitan construir una respuesta a la pregunta y objetivos de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nMedidas de tendencia central\nCalcular e interpretar las medidas de tendencia central (estadístico muestral) para las variables intervalares y de razón seleccionadas. Colocarlas en una tabla. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nMedidas de dispersión\nCalcular el rango, la desviación estándar y el coeficiente de variación (estadístico muestral) para las variables intervalares y de razón seleccionadas. Colocarlas en una tabla. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nMedidas de posición\nCalcular el valor mínimo y máximo, el cuartil 1 y el cuartil 3 (estadístico muestral) para las variables intervalares y de razón seleccionadas. Colocarlas en una tabla. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nGráficos\nPresentar al menos 2 gráficos seleccionando para su construcción aquellas variables más relevantes para el problema de investigación. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los gráficos deben ser realizados en R.\n2,0\n\n\nÍndices y escalas\nConstruir al menos un índice o escala a partir del conjunto de variables seleccionado. Este índice o escala debe reportar e interpretar el nivel de consistencia interna de las variables\n2,0\n\n\nEstimación puntual, intervalo de confianza y error\nCalcular los parámetros e intervalos de confianza para dos de las variables seleccionadas. Además, debe elaborar una tabla resumen que sintetice todos los indicadores que considere relevantes para interpretar la información. La interpretación debe ser relevante para responder la pregunta y objetivo de investigación. Los cálculos deben ser realizados en R.\n2,0\n\n\nConclusiones\nEn las conclusiones se deben sintetizar los aspectos más relevantes de los análisis estadísticos ya expuestos, articulando toda la información trabajada debe presentarse una respuesta tentativa a la pregunta de investigación. Este resumen de los resultados, así como las conclusiones, deben dialogar con lo planteado en la introducción de su trabajo, haciendo referencia a las fuentes bibliográficas utilizadas en la presentación del problema de investigación. Además, debe reflexionar sobre los límites de su diseño de investigación y señalar posibles ejes de investigación que podrían ser considerados en futuras indagaciones. Se valorará la pertinencia sociológica de la conclusión (1 plana).\n2,0\n\n\nTrabajo en R\nAdemás del informe, entregar la carpeta con el Proyecto R, que contenga un archivo .Rproject, y las carpetas input, procesamiento y output.\n\nLa carpeta input debe contener la base de datos, manual de usuario, libro de códigos.\nLa carpeta procesamiento debe contener un archivo de sintaxis para el procesamiento y otro para el análisis de los datos.\nLa carpeta output debe contener la base de datos procesada y el resto de salidas asociadas (tablas, gráficos, etc.).\n\nSe evaluará que los códigos utilizados generen las salidas (tablas, gráficos, etc.) que se presentan en el informe.\n3,0"
  },
  {
    "objectID": "trabajos.html#fecha-y-formato-de-entrega",
    "href": "trabajos.html#fecha-y-formato-de-entrega",
    "title": "Trabajos",
    "section": "Fecha y formato de entrega",
    "text": "Fecha y formato de entrega\nEl formato de entrega del informe debe ser un documento en formato PDF (.pdf), que debe estar alojado en la carpeta output del Proyecto R. Fecha de entrega: viernes 12 de julio hasta las 23:59 vía módulo Tareas en plataforma U-Cursos. \n\nEntregas atrasadas hasta las 23:59 del sábado 13 de julio tendrán 0,5 puntos de descuento  sobre la nota final. \nEntregas atrasadas hasta el domingo 14 de julio hasta las 23:59 tendrán 1,0 punto de descuento sobre la nota final. No serán evaluadas entregas posteriores a esta fecha."
  },
  {
    "objectID": "trabajos.html#sobre-plagio",
    "href": "trabajos.html#sobre-plagio",
    "title": "Trabajos",
    "section": "Sobre plagio",
    "text": "Sobre plagio\nTodos los trabajos se procesan en software para detección de plagio: evidencia de una situación de plagio implica obtención de la nota mínima en la evaluación (1,0) junto con constituirse como causal de reprobación de la asignatura."
  },
  {
    "objectID": "trabajos.html#recomendaciones-para-la-entrega",
    "href": "trabajos.html#recomendaciones-para-la-entrega",
    "title": "Trabajos",
    "section": "Recomendaciones para la entrega",
    "text": "Recomendaciones para la entrega\n\nMáxima de escritura: una idea por párrafo. Si comienza una idea nueva, se recomienda comenzar otro párrafo. Al revés, si el párrafo siguiente habla de lo mismo, sumarlo al párrafo anterior. \nLa idea del párrafo se resume en la primera parte del párrafo, lo que en inglés se llama “topic sentence”. \nDeclarar domicilio disciplinar: ej, mencionar la palabra “sociología” en el primer/segundo párrafo, esto fuerza que la investigación se enmarque en la disciplina.\n\nEn caso de tener dudas, no dude en contactar a sus ayudantes respectivos, o bien, vía foro U-Cursos al equipo docente de la asignatura."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los dos componentes centrales del curso son las clases teóricas y las actividades prácticas. Las clases se realizarán los días Viernes 09:00 a 10:50 en sala 329\n\nClases ( ): Lecturas, documentos de presentación y video (en caso que la sesión sea grabada)\nPrácticas y evaluaciones (): Actividades prácticas a desarrollar durante la semana.\nLecturas (): Llegar a la clase con los textos leídos.\n\n\n\n\n\n Clases\n Prácticas y evaluaciones\n Lecturas y material adicional\n\n\n\n\n Marzo \n\n\n\n\n\nViernes 17\n00. Presentación e 01. introducción\n1. Aproximación inicial a R\n- Leer detalladamente programa del curso\n\n\n\n\nUNIDAD 1: Estadística descriptiva\n\n\n\nViernes 24\n2.Operacionalización de variables \n2.Operacionalización de variables\n- Wickham & Grolemund, (2017). cap. 1 Introducción \n\n\nViernes 31\n3. Visualización de datos\n-\n- Wickham & Grolemund, (2017). cap. 2 Explorar\n\n\n Abril \n\n\n\n\n\nViernes 07\nViernes santo\n\n\n\n\nViernes 14\n1° semana presencial\n\n\n\n\nViernes 21\n\nEvaluación\n\n\n\n\n\n\nUNIDAD 2: Estadística Correlacional\n\n\n\nViernes 28\n4. Introducción a la inferencia estadística\n\n\n\n\n Mayo \n\n\n\n\n\nViernes 05\n1° semana de pausa reflexiva\n\n\n\n\nViernes 12\n5. Correlación\n\n\n\n\nViernes 19\n6. Índices y análisis factorial\n\n\n\n\nViernes 26\n2° semana presencial\n\n\n\n\n\n\n\nUNIDAD 3: Regresión lineal y regresión logística\n\n\n\n Junio \n\n\n\n\n\nViernes 02\n7. Regresión lineal de mínimos cuadrados\n\n\n\n\nViernes 09\n2° semana de pausa reflexiva\n\n\n\n\nViernes 16\n**8. Regresión logística binaria: interpretación de coeficientes y cálculo de probabilidades\n\n\n\n\nViernes 23\n10. Análisis factorial y regresión lineal en R\n\n\n\n\nViernes 30\n11. Supuestos de regresión y valores predichos\n\n\n\n\n Julio \n\n\n\n\n\nViernes 07\n3° semana presencial\n\n\n\n\nViernes 14\n\nEvaluación"
  },
  {
    "objectID": "resource/07-resource.html",
    "href": "resource/07-resource.html",
    "title": "Práctica 7 Correlación y regresióna",
    "section": "",
    "text": "La siguiente práctica tiene el objetivo de repasar en la interpretación de coeficientes de correlación y la construcción de índices, así como también en la interpretación de coeficientes de regresión lineal y logística. Para ello, utilizaremos la base de datos de la tercera ola del Estudio Longitudinal Social del Chile 2018 con el objetivo de analizar los determinantes de la Participación Ciudadana.\nLa versión original de este ejercicio proviene del curso de Estadística multivariada versión 2022."
  },
  {
    "objectID": "resource/07-resource.html#explorar-datos",
    "href": "resource/07-resource.html#explorar-datos",
    "title": "Práctica 7 Correlación y regresióna",
    "section": "Explorar datos",
    "text": "Explorar datos\nA partir de la siguiente tabla se obtienen estadísticos descriptivos que luego serán relevantes para realizar las transformaciones y análisis posteriores.\n\nview_df(elsoc,max.len = 50)\n\n\n\nData frame: elsoc\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nsexo\nSexo entrevistado\n0\n1\nHombre\nMujer\n\n\n2\nedad\nEdad entrevistado\nrange: 18-90\n\n\n3\neduc\nNivel educacional\n1\n2\n3\n4\n5\nPrimaria incompleta menos\nPrimaria y secundaria baja\nSecundaria alta\nTerciaria ciclo corto\nTerciaria y Postgrado\n\n\n4\npospol\nAutoubicacion escala izquierda-derecha\n1\n2\n3\n4\nDerecha\nCentro\nIzquierda\nIndep./Ninguno\n\n\n5\npart01\nFrecuencia: Firma carta o peticion apoyando causa\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n6\npart02\nFrecuencia: Asiste a mbackground-color:#eeeeeeha o manifestacion\npacifica\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n7\npart03\nFrecuencia: Participa en huelga\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n8\npart04\nFrecuencia: Usa redes sociales para opinar en\ntemas publicos\n1\n2\n3\n4\n5\nNunca\nCasi nunca\nA veces\nFrecuentemente\nMuy frecuentemente\n\n\n9\ninghogar\nIngreso total del hogar\nrange: 30000-17000000\n\n\n10\ninghogar_t\nIngreso total del hogar (en tramos)\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\nMenos de $220.000 mensuales liquidos\nDe $220.001 a $280.000 mensuales liquidos\nDe $280.001 a $330.000 mensuales liquidos\nDe $330.001 a $380.000 mensuales liquidos\nDe $380.001 a $420.000 mensuales liquidos\nDe $420.001 a $470.000 mensuales liquidos\nDe $470.001 a $510.000 mensuales liquidos\nDe $510.001 a $560.000 mensuales liquidos\nDe $560.001 a $610.000 mensuales liquidos\nDe $610.001 a $670.000 mensuales liquidos\nDe $670.001 a $730.000 mensuales liquidos\nDe $730.001 a $800.000 mensuales liquidos\nDe $800.001 a $890.000 mensuales liquidos\nDe $890.001 a $980.000 mensuales liquidos\nDe $980.001 a $1.100.000 mensuales liquidos\nDe $1.100.001 a $1.260.000 mensuales liquidos\nDe $1.260.001 a $1.490.000 mensuales liquidos\nDe $1.490.001 a $1.850.000 mensuales liquidos\nDe $1.850.001 a $2.700.000 mensuales liquidos\nMas de $2.700.000 a mensuales liquidos\n\n\n11\ntamhogar\nHabitantes del hogar\nrange: 1-14"
  },
  {
    "objectID": "resource/07-resource.html#variable-dependiente-participación-política",
    "href": "resource/07-resource.html#variable-dependiente-participación-política",
    "title": "Práctica 7 Correlación y regresióna",
    "section": "Variable dependiente: participación política",
    "text": "Variable dependiente: participación política\n\nplot_stackfrq(elsoc[,c(\"part01\",\"part02\",\"part03\",\"part04\")]) + theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\ncorrplot.mixed(cor(select(elsoc,part01,part02,part03,part04),\n                   use = \"complete.obs\"))\n\n\n\n\n\n\n\n\n\nelsoc &lt;- elsoc %&gt;% mutate(partpol=rowSums(select(., part01,part02,part03,part04)))\nsummary(elsoc$partpol)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  4.000   4.000   4.000   5.473   6.000  20.000       8"
  },
  {
    "objectID": "resource/07-resource.html#variable-independiente-ingresos",
    "href": "resource/07-resource.html#variable-independiente-ingresos",
    "title": "Práctica 7 Correlación y regresióna",
    "section": "Variable independiente: ingresos",
    "text": "Variable independiente: ingresos\ningresos hogar variable continua\n\nsummary(elsoc$inghogar)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n   30000   300000   500000   678843   800000 17000000      668 \n\n\ningreso hogar en tramos\n\nsjmisc::frq(elsoc$inghogar_t,\n            out = \"txt\",\n            show.na = T) %&gt;% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nval\nlabel\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\n\n1\nMenos de $220.000 mensuales liquidos\n62\n1.65\n13.00\n13.00\n\n\n2\nDe $220.001 a $280.000 mensuales liquidos\n46\n1.23\n9.64\n22.64\n\n\n3\nDe $280.001 a $330.000 mensuales liquidos\n57\n1.52\n11.95\n34.59\n\n\n4\nDe $330.001 a $380.000 mensuales liquidos\n40\n1.07\n8.39\n42.98\n\n\n5\nDe $380.001 a $420.000 mensuales liquidos\n38\n1.01\n7.97\n50.94\n\n\n6\nDe $420.001 a $470.000 mensuales liquidos\n37\n0.99\n7.76\n58.70\n\n\n7\nDe $470.001 a $510.000 mensuales liquidos\n27\n0.72\n5.66\n64.36\n\n\n8\nDe $510.001 a $560.000 mensuales liquidos\n15\n0.40\n3.14\n67.51\n\n\n9\nDe $560.001 a $610.000 mensuales liquidos\n24\n0.64\n5.03\n72.54\n\n\n10\nDe $610.001 a $670.000 mensuales liquidos\n12\n0.32\n2.52\n75.05\n\n\n11\nDe $670.001 a $730.000 mensuales liquidos\n15\n0.40\n3.14\n78.20\n\n\n12\nDe $730.001 a $800.000 mensuales liquidos\n16\n0.43\n3.35\n81.55\n\n\n13\nDe $800.001 a $890.000 mensuales liquidos\n8\n0.21\n1.68\n83.23\n\n\n14\nDe $890.001 a $980.000 mensuales liquidos\n14\n0.37\n2.94\n86.16\n\n\n15\nDe $980.001 a $1.100.000 mensuales liquidos\n14\n0.37\n2.94\n89.10\n\n\n16\nDe $1.100.001 a $1.260.000 mensuales liquidos\n10\n0.27\n2.10\n91.19\n\n\n17\nDe $1.260.001 a $1.490.000 mensuales liquidos\n7\n0.19\n1.47\n92.66\n\n\n18\nDe $1.490.001 a $1.850.000 mensuales liquidos\n11\n0.29\n2.31\n94.97\n\n\n19\nDe $1.850.001 a $2.700.000 mensuales liquidos\n14\n0.37\n2.94\n97.90\n\n\n20\nMas de $2.700.000 a mensuales liquidos\n10\n0.27\n2.10\n100.00\n\n\nNA\nNA\n3271\n87.27\nNA\nNA\n\n\n\n\n\n\n\n\n\npodemos obtener la mediana de cada tramo\n\nelsoc$inghogar_t[elsoc$inghogar_t==1] &lt;-(       220000 )    # [1]  \"Menos de $220.000 mensuales liquidos\"          \nelsoc$inghogar_t[elsoc$inghogar_t==2] &lt;-(220001 +280000 )/2 # [2]  \"De $220.001 a $280.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==3] &lt;-(280001 +330000 )/2 # [3]  \"De $280.001 a $330.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==4] &lt;-(330001 +380000 )/2 # [4]  \"De $330.001 a $380.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==5] &lt;-(380001 +420000 )/2 # [5]  \"De $380.001 a $420.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==6] &lt;-(420001 +470000 )/2 # [6]  \"De $420.001 a $470.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==7] &lt;-(470001 +510000 )/2 # [7]  \"De $470.001 a $510.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==8] &lt;-(510001 +560000 )/2 # [8]  \"De $510.001 a $560.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==9] &lt;-(560001 +610000 )/2 # [9]  \"De $560.001 a $610.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==10]&lt;-(610001 +670000 )/2 # [10] \"De $610.001 a $670.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==11]&lt;-(670001 +730000 )/2 # [11] \"De $670.001 a $730.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==12]&lt;-(730001 +800000 )/2 # [12] \"De $730.001 a $800.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==13]&lt;-(800001 +890000 )/2 # [13] \"De $800.001 a $890.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==14]&lt;-(890001 +980000 )/2 # [14] \"De $890.001 a $980.000 mensuales liquidos\"       \nelsoc$inghogar_t[elsoc$inghogar_t==15]&lt;-(980001 +1100000)/2 # [15] \"De $980.001 a $1.100.000 mensuales liquidos\"      \nelsoc$inghogar_t[elsoc$inghogar_t==16]&lt;-(1100001+1260000)/2 # [16] \"De $1.100.001 a $1.260.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==17]&lt;-(1260001+1490000)/2 # [17] \"De $1.260.001 a $1.490.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==18]&lt;-(1490001+1850000)/2 # [18] \"De $1.490.001 a $1.850.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==19]&lt;-(1850001+2700000)/2 # [19] \"De $1.850.001 a $2.700.000 mensuales liquidos\"    \nelsoc$inghogar_t[elsoc$inghogar_t==20]&lt;-(2700000)           # [20] \"Mas de $2.700.000 a mensuales liquidos\"\n\ny luego imputar este valor medio a los casos NA\n\nelsoc$inghogar_i &lt;- ifelse(test = (is.na(elsoc$inghogar)), #¿existen NA en ingresos?\n                           yes = elsoc$inghogar_t,         #VERDADERO, remplazar con la media del tramo\n                           no = elsoc$inghogar)            #FALSE, mantener la variable original.\n\nelsoc$inghogar_i &lt;- set_label(elsoc$inghogar_i,\"Ingreso total del hogar (imputada)\")\n\n\nelsoc$ing_pcap &lt;- elsoc$inghogar_i/elsoc$tamhogar\nelsoc$ing_pcap &lt;- set_label(elsoc$ing_pcap,\"Ingreso per cápita del hogar\")\n\n\nelsoc$quintile&lt;- dplyr::ntile(x = elsoc$ing_pcap,\n                              n = 5) # n de categorias, para quintiles usamos 5 \nelsoc$quintile &lt;- factor(elsoc$quintile,c(1,2,3,4,5), c(\"Quintil 1\",\"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\")) \nelsoc %&gt;% \n  group_by(quintile) %&gt;% \n  summarise(n=n(),\n            Media=mean(ing_pcap,na.rm = T),\n            Mediana=median(ing_pcap,na.rm = T)) %&gt;% \n  knitr::kable()\n\n\n\n\nquintile\nn\nMedia\nMediana\n\n\n\n\nQuintil 1\n711\n62859.09\n66666.67\n\n\nQuintil 2\n711\n112218.97\n111250.12\n\n\nQuintil 3\n710\n167748.23\n166666.67\n\n\nQuintil 4\n710\n262710.27\n250000.50\n\n\nQuintil 5\n710\n710246.41\n500000.00\n\n\nNA\n196\nNaN\nNA\n\n\n\n\n\n\nelsoc$quintilemiss &lt;- factor(elsoc$quintile,ordered = T)\nelsoc$quintilemiss &lt;- ifelse(test=is.na(elsoc$quintilemiss),yes = 6,no = elsoc$quintilemiss)\nelsoc$quintilemiss &lt;- factor(elsoc$quintilemiss ,levels = c(1,2,3,4,5,6),labels =  c(\"Quintil 1\",\"Quintil 2\",\"Quintil 3\",\"Quintil 4\",\"Quintil 5\",\"Missing\")) \nelsoc %&gt;% group_by(quintilemiss) %&gt;% summarise(n=n())\n\n# A tibble: 6 × 2\n  quintilemiss     n\n  &lt;fct&gt;        &lt;int&gt;\n1 Quintil 1      711\n2 Quintil 2      711\n3 Quintil 3      710\n4 Quintil 4      710\n5 Quintil 5      710\n6 Missing        196"
  },
  {
    "objectID": "resource/07-resource.html#variables-dummy",
    "href": "resource/07-resource.html#variables-dummy",
    "title": "Práctica 7 Correlación y regresióna",
    "section": "Variables dummy",
    "text": "Variables dummy\nUna forma de pasar una variable categórica a dummies es con la función dummy_cols del paquete fastDummies\n\nelsoc &lt;- dummy_cols(elsoc, select_columns = \"quintilemiss\")\nhead(elsoc[,16:22])\n\n  quintilemiss quintilemiss_Quintil 1 quintilemiss_Quintil 2\n1    Quintil 1                      1                      0\n2    Quintil 5                      0                      0\n3    Quintil 1                      1                      0\n4    Quintil 5                      0                      0\n5      Missing                      0                      0\n6    Quintil 3                      0                      0\n  quintilemiss_Quintil 3 quintilemiss_Quintil 4 quintilemiss_Quintil 5\n1                      0                      0                      0\n2                      0                      0                      1\n3                      0                      0                      0\n4                      0                      0                      1\n5                      0                      0                      0\n6                      1                      0                      0\n  quintilemiss_Missing\n1                    0\n2                    0\n3                    0\n4                    0\n5                    1\n6                    0\n\n\n¿cómo hacerlo para una variable numérica?\nTambién existen muchas formas, como por ejemplo establecer como punto de corte la media o la mediana, o ver la distribución de las respuestas y tratar de establecer una distribución homogénea entre las dos nuevas categorías.\nSi recordamos la distribución de nuestra variable dependiente antes de construir el índice de participación:\n\nplot_stackfrq(elsoc[,c(\"part01\",\"part02\",\"part03\",\"part04\")]) + theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\ny luego en el índice de participación\n\nsummary(elsoc$partpol)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  4.000   4.000   4.000   5.473   6.000  20.000       8 \n\n\nPodemos notar que la mayoría de las respuestas se agrupan en la categoría “nunca” de las variables por separado y luego en el índice la mediana también corresponde al valor mínimo posible de “4” que es la suma de todas las personas que nunca han participado en ninguna de las opciones. Por lo tanto, tenemos dos criterios que nos permiten decidir que nuestra variable dependiente puede ser considera como dummy bajo los valores 0=nunca ha participado; y 1=si ha participado.\nUna forma de hacer esta agrupación de valores es con la función case_when del paquete dplyr (similar a ifelse)\n\nelsoc &lt;- elsoc %&gt;% rowwise() %&gt;%  mutate(partpol_dummy = case_when(partpol==4~0,\n                                                                   partpol&gt;4~1,\n                                                                   TRUE ~ NA))\ntable(elsoc$partpol_dummy)\n\n\n   0    1 \n2074 1666"
  },
  {
    "objectID": "resource/05-resource.html",
    "href": "resource/05-resource.html",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "Github es una plataforma de desarrollo colaborativo que permite alojar proyectos utilizando el sistema de control de versiones Git. Se utiliza principalmente para la creación de código fuente de programas (software).\n\n\n\n\n\n\nNota\n\n\n\nEl 4 de junio de 2018 Microsoft compró GitHub por la cantidad de 7500 millones de dólares. Al inicio, el cambio de propietario generó preocupaciones y la salida de algunos proyectos de este sitio; sin embargo, no fueron representativos. GitHub continúa siendo la plataforma más importante de colaboración para proyectos de código abierto.\n\n\n\n\n\nUn repositorio contiene todo el código, tus archivos y el historial de revisiones y cambios de cada uno de ellos. Es el elemento más básico de Github.\nLos repositorios pueden contar con múltiples colaboradores y pueden ser públicos o privados.\n\n\n\n\n\n\n\n\n\n\nTérmino\nDefinición\n\n\n\n\nBranch\nUna versión paralela del código contenido en el repositorio, pero que no afecta a la rama principal.\n\n\nClonar\nPara descargar una copia completa de los datos de un repositorio de GitHub.com, incluidas todas las versiones de cada archivo y carpeta.\n\n\nFork\nUn nuevo repositorio que comparte la configuración de visibilidad y código con el repositorio «ascendente» original.\n\n\nMerge\nPara aplicar los cambios de una rama y en otra.\n\n\nPull request\nUna solicitud para combinar los cambios de una branch en otra.\n\n\nRemote\nUn repositorio almacenado en GitHub, no en el equipo.\n\n\nUpstream\nLa branch de un repositorio original que se ha forkeado o clonado. La branch correspondiente de la branch clonada o forkeada se denomina «descendente».\n\n\n\n\n\n\n\nAcceder a la página de github\n\nRegistrarse ingresando correo electrónico y siguiendo los pasos siguientes (crear contraseña y nombre de usuario)\n\nLa personalización de la cuenta se puede saltar haciendo click en skip abajo de la selección de opciones\n\nDescargar e instalar Github Desktop\n\n\n\n\n\nEn la página principal de github hacer click en el ícono de usuario de la esquina superior derecha y luego ir a Tus repositorios\n\nUna vez accedemos a Tus repositorios hacemos click en New/Nuevo\n\nLuego le ponemos un nombre a nuestro repositorio, evitando siempre espacios, ñ y tíldes, y apretamos Crear repositorio\n\n\n\n\nUna vez creado un repositorio, lo que nos interesa es descargarlo. Al abrir la aplicación de Github desktop por primera vez (descargada anteriormente), nos debería aparecer la opción de clonar nuestro repositorio R-data-analisis en la pantalla de inicio. Lo clonamos y seleccionamos una carpeta de nuestro computador para almacenarlo.\nPara todas las siguientes veces, las instrucciones son estas:\n1- Apretamos Repositorio actual en la esquina superior izquierda\n2- Apretamos añadir\n3- Apretamos clonar repositorio…\n\n4- Seleccionamos nuestro repositorio\n5- seleccionamos la carpeta donde se almacenará. Siempre evitando tener tíldes, ñ y espacios en la dirección de almacenamiento y apretamos ‘clone’.\n\n\n\n\n\nAcceder a la página de zotero\n\nVamos a Log in\n\n\nY creamos una cuenta gratis\n\n\n\nFinalmente volvemos al inicio y descargamos el programa:\n\n\n\n\n\nZotero es un gestor bibliográfico que nos permite almacenar referencias bibliográficas.\n\nEs posible crear distintas bibliotecas personales (esquina superior izquierda) o grupales (abajo). Se recomienda separar las bibliotecas por temas o proyectos\nAl visualizar una referencia bibliográfica nos muestra todos los metadatos: Título, autores, nombre de la revista, año de publicación, DOI, ISBN de la revista, número de páginas, etc.\nEl dato central que nos va a servir en esta parte del proceso es el DOI\n\n\n\n\n\n\n\nNota\n\n\n\nDOI: Digital Object Identifier (Identificador de objetos digitales)\nEl DOI consiste en un código alfanumérico que identifica en la web un artículo y que lo recupera incluso si éste se ubica en un servidor distinto al que fue alojado en un principio. Se evita así el típico problema de los enlaces rotos, muy habitual en macrowebs como las universitarias.\n\n\n\n\nPara crear una biblioteca en zotero vamos a Archivo -&gt; Nueva colección y le ponemos un nombre que no tenga tíldes, ñ o espacios\n\n\nEn este caso mi biblioteca se llama “percepcion-desigualdad”.\n\nZotero tiene dos funciones para agregar referencias botón verde “Nuevo elemento” o varita mágica “añadir elemento por identificador”. Esta vez vamos por la segunda opción\nBuscamos un paper que nos interese: en este caso busqué el paper The paradox of inequality: income inequality and belief in meritocracy go hand in hand de Jonathan Mijs (2021). Su DOI es https://doi.org/10.1093/ser/mwy051\nUsamos la función Añadir elemento por identificador para agregar nuestra referencia a zotero\n\n\n¿Cuál es la forma más eficiente de buscar bibliografía sobre un mismo tema?\n\n\n\n\nResearch Rabbit es una plataforma que a partir de un paper busca otros similares, cruzando referencias y autores. Además, tiene una ventaja: Se vincula con Zotero\n\nIngresar a la página https://researchrabbitapp.com/.\nCrear cuenta\n\n\n\nUna vez dentro apretamos “Import Zotero Collection” y seleccionamos nuestra biblioteca\n\n\n\nAsí se ve research rabbit\n\n\n\nPodemos revisar el abstract de algún paper y, si nos interesa, lo agregamos a nuestra biblioteca\n\n\n\nDespués volvemos a Zotero, actualizamos y aparece nuestro nuevo paper\n\n\nAhora solo nos interesa lograr una cosa más: vincular nuestra biblioteca de Zotero con R\n\nVamos a este link y descargamos zotero-better-bibtex-6.7.169.xpi\nVolvemos a Zotero –&gt; Herramientas –&gt; Complementos –&gt; La tuerca en la esquina superior derecha –&gt; Instalar Add-on desde archivo –&gt; Seleccionamos el archivo que acabamos de descargar\n\n\n\nPaso final: exportamos nuestra biblioteca. Click derecho en nuestra biblioteca –&gt; Exportar colección\n\n\n\nSeleccionamos formato: Better BibTeX y marcamos la casilla “Keep updated”. Esto último actualizará el archivo automáticamente cuando agreguemos nueva bibliografía\n\n\n\nGuardamos nuestro archivo .bib en la misma carpeta de nuestro proyecto de trabajo\n\n\n\n\nLa escritura en Quarto tiene algunos códigos o funciones, aquí un resumen de su mayoría:\n\n\n\nCódigo\nAsí se ve\n\n\n\n\nAlgo de texto en el párrafo.\n\nMás texto\nespacio entre lineas.\nAlgo de texto.\nAlgo de texto en el párrafo. Siempre utilizando espacios para dividir párrafos\n\n\n`*Cursivas*`\nCursivas\n\n\n`**Negrita**`\nNegrita\n\n\n# Título 1\n\n\n\n## Título 2\n\n\n\n### Título 3\n\n\n\n(puedes llegar hasta un título N° 6 con ######)\n\n\n\n`[Texto enlace](https://quarto.org/)`\nTexto enlace\n\n\n`![Texto imagen](/path/to/image.png)`\n\n\n\nTexto imagen\n\n\n\n\n&gt; Citas\n\nCitas\n\n\n\n1. Una\n2. lista\n3 ordenada\n\nUna\nlista\nordenada\n\n\n\n- Otro\n- tipo\n- de lista\n\nOtro\ntipo\nde lista\n\n\n\n\n\nAbrimos nuestro Rproject y creamos un nuevo documento de Quarto file –&gt; new file –&gt; Quarto document\nEditamos el yaml, agregando bibliography: percepcion-desigualdad.bib y link-citations: yes\n\n\n\n\n\n\n\nNota\n\n\n\nYAML: Lenguaje de programación. Es un formato de serialización de datos que proporcionan un mecanismo de intercambio de datos legible por humanos. Dan formato a los datos de manera estandarizada para su intercambio entre aplicaciones de software.\n\n\n\n\nComenzamos a escribir la introducción de nuestra investigación\nPara insertar referencias:\n\nSe pueden insertar citas usando el comando Insert -&gt; Citation o usando la sintaxis directamente (por ejemplo, [@cita] o @cita).\nLas citas van entre corchetes y están separadas por punto y coma. Cada cita debe tener una clave, compuesta por ‘@’ + el identificador de la cita en zotero.\n\nEn este caso, [@mijsParadoxInequalityIncome2021a]\nAquí hay otros ejemplos:\nLa investigación sobre percepción de desigualdad económica ha tenido un auge durante los últimos años [@mijsParadoxInequalityIncome2021a; @crucesBiasedPerceptionsIncome2013].\nEspecíficamente, se ha encontrado evidencia sobre que… [@mijsParadoxInequalityIncome2021a]. De todas formas, @crucesBiasedPerceptionsIncome2013 plantea que…\nAsí mismo, Mijs señala que… [-@mijsParadoxInequalityIncome2021a]\nAunque ambos concluyen que… [@mijsParadoxInequalityIncome2021a; @crucesBiasedPerceptionsIncome2013]\n\n\nLuego renderizamos y se debería ver así:\n\n\nCon referencias automáticas!\n\nAhora que tenemos la introducción de nuestra investigación podemos subirla a Github Pages a través de Github Desktop.\n\n\n\n\n\n\n\n\nAhora podemos ver los documentos modificados en nuestro repositorio online de github.\n\nVamos a settings\n\n\n\nDentro de Settings vamos a Pages, luego ‘none’ y seleccionamos ‘main’. Luego apretamos Save\n\n\nLuego de aproximadamente un minuto se actualiza la página y aparecerá un link en la parte superior, algo así como kevincarrascoq.github.ui/R-data-analisis que es nuestra página principal de nuestro sitio web de github.\nEl link para llegar a nuestro documento renderizado de quarto sigue la estructura del repositorio:",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/05-resource.html#descripción",
    "href": "resource/05-resource.html#descripción",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "Github es una plataforma de desarrollo colaborativo que permite alojar proyectos utilizando el sistema de control de versiones Git. Se utiliza principalmente para la creación de código fuente de programas (software).\n\n\n\n\n\n\nNota\n\n\n\nEl 4 de junio de 2018 Microsoft compró GitHub por la cantidad de 7500 millones de dólares. Al inicio, el cambio de propietario generó preocupaciones y la salida de algunos proyectos de este sitio; sin embargo, no fueron representativos. GitHub continúa siendo la plataforma más importante de colaboración para proyectos de código abierto.",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/05-resource.html#repositorios",
    "href": "resource/05-resource.html#repositorios",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "Un repositorio contiene todo el código, tus archivos y el historial de revisiones y cambios de cada uno de ellos. Es el elemento más básico de Github.\nLos repositorios pueden contar con múltiples colaboradores y pueden ser públicos o privados.",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/05-resource.html#principales-términos",
    "href": "resource/05-resource.html#principales-términos",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "Término\nDefinición\n\n\n\n\nBranch\nUna versión paralela del código contenido en el repositorio, pero que no afecta a la rama principal.\n\n\nClonar\nPara descargar una copia completa de los datos de un repositorio de GitHub.com, incluidas todas las versiones de cada archivo y carpeta.\n\n\nFork\nUn nuevo repositorio que comparte la configuración de visibilidad y código con el repositorio «ascendente» original.\n\n\nMerge\nPara aplicar los cambios de una rama y en otra.\n\n\nPull request\nUna solicitud para combinar los cambios de una branch en otra.\n\n\nRemote\nUn repositorio almacenado en GitHub, no en el equipo.\n\n\nUpstream\nLa branch de un repositorio original que se ha forkeado o clonado. La branch correspondiente de la branch clonada o forkeada se denomina «descendente».",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/05-resource.html#crear-cuenta-e-instalación",
    "href": "resource/05-resource.html#crear-cuenta-e-instalación",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "Acceder a la página de github\n\nRegistrarse ingresando correo electrónico y siguiendo los pasos siguientes (crear contraseña y nombre de usuario)\n\nLa personalización de la cuenta se puede saltar haciendo click en skip abajo de la selección de opciones\n\nDescargar e instalar Github Desktop",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/05-resource.html#crear-repositorio",
    "href": "resource/05-resource.html#crear-repositorio",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "En la página principal de github hacer click en el ícono de usuario de la esquina superior derecha y luego ir a Tus repositorios\n\nUna vez accedemos a Tus repositorios hacemos click en New/Nuevo\n\nLuego le ponemos un nombre a nuestro repositorio, evitando siempre espacios, ñ y tíldes, y apretamos Crear repositorio",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/05-resource.html#github-desktop",
    "href": "resource/05-resource.html#github-desktop",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "Una vez creado un repositorio, lo que nos interesa es descargarlo. Al abrir la aplicación de Github desktop por primera vez (descargada anteriormente), nos debería aparecer la opción de clonar nuestro repositorio R-data-analisis en la pantalla de inicio. Lo clonamos y seleccionamos una carpeta de nuestro computador para almacenarlo.\nPara todas las siguientes veces, las instrucciones son estas:\n1- Apretamos Repositorio actual en la esquina superior izquierda\n2- Apretamos añadir\n3- Apretamos clonar repositorio…\n\n4- Seleccionamos nuestro repositorio\n5- seleccionamos la carpeta donde se almacenará. Siempre evitando tener tíldes, ñ y espacios en la dirección de almacenamiento y apretamos ‘clone’.",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/05-resource.html#zotero",
    "href": "resource/05-resource.html#zotero",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "Acceder a la página de zotero\n\nVamos a Log in\n\n\nY creamos una cuenta gratis\n\n\n\nFinalmente volvemos al inicio y descargamos el programa:\n\n\n\n\n\nZotero es un gestor bibliográfico que nos permite almacenar referencias bibliográficas.\n\nEs posible crear distintas bibliotecas personales (esquina superior izquierda) o grupales (abajo). Se recomienda separar las bibliotecas por temas o proyectos\nAl visualizar una referencia bibliográfica nos muestra todos los metadatos: Título, autores, nombre de la revista, año de publicación, DOI, ISBN de la revista, número de páginas, etc.\nEl dato central que nos va a servir en esta parte del proceso es el DOI\n\n\n\n\n\n\n\nNota\n\n\n\nDOI: Digital Object Identifier (Identificador de objetos digitales)\nEl DOI consiste en un código alfanumérico que identifica en la web un artículo y que lo recupera incluso si éste se ubica en un servidor distinto al que fue alojado en un principio. Se evita así el típico problema de los enlaces rotos, muy habitual en macrowebs como las universitarias.\n\n\n\n\nPara crear una biblioteca en zotero vamos a Archivo -&gt; Nueva colección y le ponemos un nombre que no tenga tíldes, ñ o espacios\n\n\nEn este caso mi biblioteca se llama “percepcion-desigualdad”.\n\nZotero tiene dos funciones para agregar referencias botón verde “Nuevo elemento” o varita mágica “añadir elemento por identificador”. Esta vez vamos por la segunda opción\nBuscamos un paper que nos interese: en este caso busqué el paper The paradox of inequality: income inequality and belief in meritocracy go hand in hand de Jonathan Mijs (2021). Su DOI es https://doi.org/10.1093/ser/mwy051\nUsamos la función Añadir elemento por identificador para agregar nuestra referencia a zotero\n\n\n¿Cuál es la forma más eficiente de buscar bibliografía sobre un mismo tema?",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/05-resource.html#researchrabbit",
    "href": "resource/05-resource.html#researchrabbit",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "Research Rabbit es una plataforma que a partir de un paper busca otros similares, cruzando referencias y autores. Además, tiene una ventaja: Se vincula con Zotero\n\nIngresar a la página https://researchrabbitapp.com/.\nCrear cuenta\n\n\n\nUna vez dentro apretamos “Import Zotero Collection” y seleccionamos nuestra biblioteca\n\n\n\nAsí se ve research rabbit\n\n\n\nPodemos revisar el abstract de algún paper y, si nos interesa, lo agregamos a nuestra biblioteca\n\n\n\nDespués volvemos a Zotero, actualizamos y aparece nuestro nuevo paper\n\n\nAhora solo nos interesa lograr una cosa más: vincular nuestra biblioteca de Zotero con R\n\nVamos a este link y descargamos zotero-better-bibtex-6.7.169.xpi\nVolvemos a Zotero –&gt; Herramientas –&gt; Complementos –&gt; La tuerca en la esquina superior derecha –&gt; Instalar Add-on desde archivo –&gt; Seleccionamos el archivo que acabamos de descargar\n\n\n\nPaso final: exportamos nuestra biblioteca. Click derecho en nuestra biblioteca –&gt; Exportar colección\n\n\n\nSeleccionamos formato: Better BibTeX y marcamos la casilla “Keep updated”. Esto último actualizará el archivo automáticamente cuando agreguemos nueva bibliografía\n\n\n\nGuardamos nuestro archivo .bib en la misma carpeta de nuestro proyecto de trabajo",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/05-resource.html#quarto",
    "href": "resource/05-resource.html#quarto",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "La escritura en Quarto tiene algunos códigos o funciones, aquí un resumen de su mayoría:\n\n\n\nCódigo\nAsí se ve\n\n\n\n\nAlgo de texto en el párrafo.\n\nMás texto\nespacio entre lineas.\nAlgo de texto.\nAlgo de texto en el párrafo. Siempre utilizando espacios para dividir párrafos\n\n\n`*Cursivas*`\nCursivas\n\n\n`**Negrita**`\nNegrita\n\n\n# Título 1\n\n\n\n## Título 2\n\n\n\n### Título 3\n\n\n\n(puedes llegar hasta un título N° 6 con ######)\n\n\n\n`[Texto enlace](https://quarto.org/)`\nTexto enlace\n\n\n`![Texto imagen](/path/to/image.png)`\n\n\n\nTexto imagen\n\n\n\n\n&gt; Citas\n\nCitas\n\n\n\n1. Una\n2. lista\n3 ordenada\n\nUna\nlista\nordenada\n\n\n\n- Otro\n- tipo\n- de lista\n\nOtro\ntipo\nde lista\n\n\n\n\n\nAbrimos nuestro Rproject y creamos un nuevo documento de Quarto file –&gt; new file –&gt; Quarto document\nEditamos el yaml, agregando bibliography: percepcion-desigualdad.bib y link-citations: yes\n\n\n\n\n\n\n\nNota\n\n\n\nYAML: Lenguaje de programación. Es un formato de serialización de datos que proporcionan un mecanismo de intercambio de datos legible por humanos. Dan formato a los datos de manera estandarizada para su intercambio entre aplicaciones de software.\n\n\n\n\nComenzamos a escribir la introducción de nuestra investigación\nPara insertar referencias:\n\nSe pueden insertar citas usando el comando Insert -&gt; Citation o usando la sintaxis directamente (por ejemplo, [@cita] o @cita).\nLas citas van entre corchetes y están separadas por punto y coma. Cada cita debe tener una clave, compuesta por ‘@’ + el identificador de la cita en zotero.\n\nEn este caso, [@mijsParadoxInequalityIncome2021a]\nAquí hay otros ejemplos:\nLa investigación sobre percepción de desigualdad económica ha tenido un auge durante los últimos años [@mijsParadoxInequalityIncome2021a; @crucesBiasedPerceptionsIncome2013].\nEspecíficamente, se ha encontrado evidencia sobre que… [@mijsParadoxInequalityIncome2021a]. De todas formas, @crucesBiasedPerceptionsIncome2013 plantea que…\nAsí mismo, Mijs señala que… [-@mijsParadoxInequalityIncome2021a]\nAunque ambos concluyen que… [@mijsParadoxInequalityIncome2021a; @crucesBiasedPerceptionsIncome2013]\n\n\nLuego renderizamos y se debería ver así:\n\n\nCon referencias automáticas!\n\nAhora que tenemos la introducción de nuestra investigación podemos subirla a Github Pages a través de Github Desktop.",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/05-resource.html#github-pages",
    "href": "resource/05-resource.html#github-pages",
    "title": "Práctica 5 Herramientas y documentos dinámicos",
    "section": "",
    "text": "Ahora podemos ver los documentos modificados en nuestro repositorio online de github.\n\nVamos a settings\n\n\n\nDentro de Settings vamos a Pages, luego ‘none’ y seleccionamos ‘main’. Luego apretamos Save\n\n\nLuego de aproximadamente un minuto se actualiza la página y aparecerá un link en la parte superior, algo así como kevincarrascoq.github.ui/R-data-analisis que es nuestra página principal de nuestro sitio web de github.\nEl link para llegar a nuestro documento renderizado de quarto sigue la estructura del repositorio:",
    "crumbs": [
      "Practicos",
      "Práctico 5"
    ]
  },
  {
    "objectID": "resource/03-resource.html",
    "href": "resource/03-resource.html",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\n\nDe rutas, estructura de carpetas y otros \n\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado anteriormente. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos.\n\n\n\n\n\n\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de confianza en instituciones políticas y variables de caracterización sociodemográfica utilizando los datos de la encuesta Latinobarómetro .\n\n\n\n\nLatinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 20.000 entrevistas en 18 países de América Latina representando a más de 600 millones de habitantes\n“Los gobiernos latinoamericanos, que venían en declive junto con sus democracias desde inicios de la década de 2010, como reflejan los datos de Latinobarómetro, llegaron a fines de 2018 al annus horribilis con la caída de Nicaragua y Venezuela desde su condición de democracias para entrar en la categoría de autocracias y dictadura.\nDe los hiperpresidentes de la primera década del siglo con altos niveles de crecimiento en todos los países y altos niveles de aprobación, la región pasó en la segunda década a los subpresidentes, con una baja en aprobación de gobierno a la mitad, en menos de 10 años. Este rechazo al desempeño de las elites gobernantes, indica su fracaso a fines de 2019 en varios países de la región.” (Latinobarómetro, informe 2021, p. 7)\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Confianza en instituciones políticas, entendida como el grado en que los individuos confian en distintas instituciones políticas a nivel nacional, como el gobierno, la justicia, los partidos políticos, etc. Para ello, junto con variables de confianza, consideraremos también variables de estatus (educación), y variables de caracterización sociodemográfica (sexo y edad).",
    "crumbs": [
      "Practicos",
      "Práctico 3"
    ]
  },
  {
    "objectID": "resource/03-resource.html#objetivo-de-la-práctica",
    "href": "resource/03-resource.html#objetivo-de-la-práctica",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\n\nDe rutas, estructura de carpetas y otros \n\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado anteriormente. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos.\n\n\n\n\n\n\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de confianza en instituciones políticas y variables de caracterización sociodemográfica utilizando los datos de la encuesta Latinobarómetro .",
    "crumbs": [
      "Practicos",
      "Práctico 3"
    ]
  },
  {
    "objectID": "resource/03-resource.html#antecedentes-de-los-datos-a-utilizar",
    "href": "resource/03-resource.html#antecedentes-de-los-datos-a-utilizar",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "",
    "text": "Latinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 20.000 entrevistas en 18 países de América Latina representando a más de 600 millones de habitantes\n“Los gobiernos latinoamericanos, que venían en declive junto con sus democracias desde inicios de la década de 2010, como reflejan los datos de Latinobarómetro, llegaron a fines de 2018 al annus horribilis con la caída de Nicaragua y Venezuela desde su condición de democracias para entrar en la categoría de autocracias y dictadura.\nDe los hiperpresidentes de la primera década del siglo con altos niveles de crecimiento en todos los países y altos niveles de aprobación, la región pasó en la segunda década a los subpresidentes, con una baja en aprobación de gobierno a la mitad, en menos de 10 años. Este rechazo al desempeño de las elites gobernantes, indica su fracaso a fines de 2019 en varios países de la región.” (Latinobarómetro, informe 2021, p. 7)\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Confianza en instituciones políticas, entendida como el grado en que los individuos confian en distintas instituciones políticas a nivel nacional, como el gobierno, la justicia, los partidos políticos, etc. Para ello, junto con variables de confianza, consideraremos también variables de estatus (educación), y variables de caracterización sociodemográfica (sexo y edad).",
    "crumbs": [
      "Practicos",
      "Práctico 3"
    ]
  },
  {
    "objectID": "resource/03-resource.html#librerias",
    "href": "resource/03-resource.html#librerias",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\nComo sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer, haven)\n\nPara esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nsjmisc: descripción y exploración de base de datos\ncar: principalmente la función recode para recodificar/agrupar valores de variable\nstargazer: para tabla descriptiva",
    "crumbs": [
      "Practicos",
      "Práctico 3"
    ]
  },
  {
    "objectID": "resource/03-resource.html#cargar-base-de-datos",
    "href": "resource/03-resource.html#cargar-base-de-datos",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: latinobarometro2020.RData. Abrir bases de datos en otros formatos: Los formatos mas comunes en que se almacenan las bases de datos son .dta (Stata), .sav (Spss) y RData (R). Para abrir desde R utlilizamos la librería haven y sus funciones read_dta y read_sav según corresponda. Ej: datos &lt;- read_dta(\"base_casen.dta\"). Recordar antes instalar/cargar la librería: pacman::p_load(haven) \n\n#cargamos la base de datos desde internet\nload(url(\"https://github.com/Kevin-carrasco/metod1-MCS/raw/main/files/data/external_data/latinobarometro2020.RData\"))\n\no de manera local:\n\nlatinobarometro2020 &lt;- read_dta(\"../files/data/external_data/latinobarometro2020.dta\", encoding = \"UTF-8\")\n\nLa base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (latinobarometro2020):\n\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 20204, 408 ).\n\ndim(latinobarometro2020) # dimension de la base\n\n[1] 20204   408\n\n\nY si se quiere revisar en formato de planilla de datos:\n\nView(latinobarometro2020)",
    "crumbs": [
      "Practicos",
      "Práctico 3"
    ]
  },
  {
    "objectID": "resource/03-resource.html#selección-de-variables-a-utilizar",
    "href": "resource/03-resource.html#selección-de-variables-a-utilizar",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "3. Selección de variables a utilizar",
    "text": "3. Selección de variables a utilizar\nEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\n\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto Confianza:\n\n\nfind_var(data = latinobarometro2020,\"Confianza\")\n\n   col.nr   var.name\n1      36    p9stgbs\n2      41 P13STGBS_A\n3      42 P13STGBS_B\n4      43    p13st_c\n5      44    p13st_d\n6      45    p13st_e\n7      46    p13st_f\n8      47    p13st_g\n9      48    p13st_h\n10     49    p13st_i\n11     51    p15st_a\n12     52    p15st_b\n13     53    p15st_c\n14     54    p15st_d\n15     55    p15st_e\n16     56    p15st_f\n17     57    p15st_g\n18     58     p15n_h\n19     59     p15n_i\n20     60     p15n_j\n21     61     p15n_k\n22    154     p36n_a\n23    155     p36n_b\n24    160  P36STMB_A\n25    161  P36STMB_B\n26    162  P36STMB_C\n27    163  P36STMB_D\n                                                                          var.label\n1                                                   P9STGBS Confianza Interpersonal\n2                                       P13STGBS.A Confianza en las Fuerzas Armadas\n3                                  P13STGBS.B Confianza en la Policía / Carabineros\n4                                                   P13ST.C Confianza en la Iglesia\n5                                                  P13ST.D Confianza en el Congreso\n6                                                  P13ST.E Confianza en el Gobierno\n7                                            P13ST.F Confianza en el Poder Judicial\n8                                       P13ST.G Confianza en los Partidos Políticos\n9                           P13ST.H Confianza en: La institución Electoral del país\n10                                              P13ST.I Confianza en: El presidente\n11 P15ST.A Confianza en que las instituciones operan para mejorar nuestra calidad d\n12 P15ST.B Confianza en que las instituciones operan para mejorar nuestra calidad d\n13 P15ST.C Confianza en que las instituciones operan para mejorar nuestra calidad d\n14 P15ST.D Confianza en que las instituciones operan para mejorar nuestra calidad d\n15 P15ST.E Confianza en que las instituciones operan para mejorar nuestra calidad d\n16 P15ST.F Confianza en que las instituciones operan para mejorar nuestra calidad d\n17 P15ST.G Confianza en que las instituciones operan para mejorar nuestra calidad d\n18 P15N.H Confianza en que las instituciones operan para mejorar nuestra calidad de\n19 P15N.I Confianza en que las instituciones operan para mejorar nuestra calidad de\n20 P15N.J Confianza en que las instituciones operan para mejorar nuestra calidad de\n21 P15N.K Confianza en que las instituciones operan para mejorar nuestra calidad de\n22                        P36N.A Confianza en las Fuerzas Armadas de Estados Unidos\n23                                   P36N.B Confianza en las fuerzas Armadas Chinas\n24                    P36STMB.A Confianza en el FMI (Fondo Monetario Internacional)\n25               P36STMB.B Confianza en el BID (Banco Interamericano de Desarrollo)\n26            P36STMB.C Confianza en el CAF (Banco de Desarrollo de América Latina)\n27                                          P36STMB.D Confianza en el Banco Mundial\n\n\nNos informa que hay una serie de variables relacionadas con confianza interpersonal y con instituciones. Probemos con la variable p13st_e.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_data, donde “proc” hace referencia a base procesada:\n\nproc_data &lt;- latinobarometro2020 %&gt;% select(p13st_e, # Confianza en el Gobierno\n                          p13st_d, # Confianza en el congreso\n                          p13st_f, # Confianza en el Poder Judicial\n                          p13st_g, # Confianza en los partidos políticos\n                          reeduc_1,# nivel educacional\n                          sexo,# sexo\n                          edad,# edad\n                          idenpa) # pais \n\n# Comprobar\nnames(proc_data)\n\n[1] \"p13st_e\"  \"p13st_d\"  \"p13st_f\"  \"p13st_g\"  \"reeduc_1\" \"sexo\"     \"edad\"    \n[8] \"idenpa\"  \n\n\nMediante el comando get_label obtenemos el atributo label de las variables.\n\nsjlabelled::get_label(proc_data)\n\n                                                             p13st_e \n                                  \"P13ST.E Confianza en el Gobierno\" \n                                                             p13st_d \n                                  \"P13ST.D Confianza en el Congreso\" \n                                                             p13st_f \n                            \"P13ST.F Confianza en el Poder Judicial\" \n                                                             p13st_g \n                       \"P13ST.G Confianza en los Partidos Políticos\" \n                                                            reeduc_1 \n\"REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)\" \n                                                                sexo \n                                                         \"SEXO Sexo\" \n                                                                edad \n                                                         \"EDAD Edad\" \n                                                              idenpa \n                                    \"IDENPA Identificación del País\" \n\n\nPodemos ver que son largas o con códigos poco informativos, por lo tanto, es necesario cambiarlas por etiquetas más cortas y de fácil identificación.\nPara facilitar el análisis, vamos a filtrar la base de datos para quedarnos solo con los casos de Chile. Para esto utilizamos la función filter de dplyr. Si revisamos el libro de códigos, el identificador de Chile es 152\n\nproc_data &lt;- proc_data %&gt;% dplyr::filter(idenpa==152)",
    "crumbs": [
      "Practicos",
      "Práctico 3"
    ]
  },
  {
    "objectID": "resource/03-resource.html#procesamiento-de-variables",
    "href": "resource/03-resource.html#procesamiento-de-variables",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "4. Procesamiento de variables",
    "text": "4. Procesamiento de variables\nPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\n\nDescriptivo general\nRecodificación: de casos perdidos y otros valores (en caso necesario)\nEtiquetado: cambio de nombres de variables y valores (en caso necesario)\nOtros ajustes\n\nY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n\n4.1 Confianza en el Gobierno\nEn Latinobarómetro, lass variables que permiten medir la Confianza en instituciones políticas en Chile son las siguientes:\n\n[p13st_e]: “P13ST.E Confianza en el Gobierno” (1 = Mucha; 4 = Ninguna)\n[p13st_d]: “P13ST.D Confianza en el Congreso” (1 = Mucha; 4 = Ninguna)\n[p13st_f]: “P13ST.F Confianza en el Poder Judicial” (1 = Mucha; 4 = Ninguna)\n[p13st_g]: “P13ST.G Confianza en los Partidos Políticos” (1 = Mucha; 4 = Ninguna)\n\na. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\n\nfrq(proc_data$p13st_e)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=3.27 sd=0.99\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n   -2 |   8 |  0.67 |    0.67 |   0.67\n   -1 |  11 |  0.92 |    0.92 |   1.58\n    1 |  23 |  1.92 |    1.92 |   3.50\n    2 | 176 | 14.67 |   14.67 |  18.17\n    3 | 358 | 29.83 |   29.83 |  48.00\n    4 | 624 | 52.00 |   52.00 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nEn esta variable vemos valores asociados a la opción “No contesta” (-2) y “No sabe” (-1), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en un orden contraintuitivo (mayor valor indica menos confianza), así que en la recodificiación nos haremos cargo de los casos perdidos y de reordenar las categorías.\nb. Recodificación\nPara recodificar utilizamos la función recode, de la librería car\n\nproc_data$p13st_e &lt;- recode(proc_data$p13st_e, \"c(-2,-1)=NA\")\nproc_data$p13st_d &lt;- recode(proc_data$p13st_d, \"c(-2,-1)=NA\")\nproc_data$p13st_f &lt;- recode(proc_data$p13st_f, \"c(-2,-1)=NA\")\nproc_data$p13st_g &lt;- recode(proc_data$p13st_g, \"c(-2,-1)=NA\")\n\nnota: con la función set_na de la librería sjmisc podemos recodificar toda la base de datos con un solo código, pero debemos estar completamente segur-s de que estos valores no tienen otra categoría asociada en otra variable.\n\nproc_data &lt;- proc_data %&gt;% set_na(., na = c(-2, -1))\n\nPara reordenar las categorías volvemos a utilizar la función recode, de la librería car\n\nproc_data$p13st_e &lt;- recode(proc_data$p13st_e, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_d &lt;- recode(proc_data$p13st_d, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_f &lt;- recode(proc_data$p13st_f, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_g &lt;- recode(proc_data$p13st_g, \"1=3; 2=2; 3=1; 4=0\")\n\nc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\n\nproc_data &lt;- proc_data %&gt;% rename(\"conf_gob\"=p13st_e, # Confianza en el gobierno\n                                  \"conf_cong\"=p13st_d, # Confianza en el congreso\n                                  \"conf_jud\"=p13st_f, # Confianza en el Poder Judicial\n                                  \"conf_partpol\"=p13st_g) # Confianza en los partidos políticos \n\nAdemás de cambiar el nombre, queremos cambiar las etiquetas de las variables.\n\nproc_data$conf_gob &lt;- set_label(x = proc_data$conf_gob,label = \"Confianza: Gobierno\")\nget_label(proc_data$conf_gob)\n\n[1] \"Confianza: Gobierno\"\n\nproc_data$conf_cong  &lt;- set_label(x = proc_data$conf_cong, label = \"Confianza: Congreso\")\nget_label(proc_data$conf_cong)\n\n[1] \"Confianza: Congreso\"\n\nproc_data$conf_jud  &lt;- set_label(x = proc_data$conf_jud, label = \"Confianza: Poder judicial\")\nget_label(proc_data$conf_jud)\n\n[1] \"Confianza: Poder judicial\"\n\nproc_data$conf_partpol  &lt;- set_label(x = proc_data$conf_partpol, label = \"Confianza: Partidos politicos\")\nget_label(proc_data$conf_partpol)\n\n[1] \"Confianza: Partidos politicos\"\n\n\nd. Otros ajustes\nPara este caso vamos a crear una variable que sea la suma de los cuatro items de confianza.\n\nproc_data$conf_inst &lt;- (proc_data$conf_gob+proc_data$conf_cong+proc_data$conf_jud+proc_data$conf_partpol)\nsummary(proc_data$conf_inst)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    0.00    2.00    2.42    4.00   12.00      38 \n\n\n\nget_label(proc_data$conf_inst)\n\n[1] \"Confianza: Gobierno\"\n\n\nVemos que una etiqueta de la variable anterior.\n\nproc_data$conf_inst  &lt;- set_label(x = proc_data$conf_inst, label = \"Confianza en instituciones\")\n\nRevisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\n\nfrq(proc_data$conf_gob)\n\nConfianza: Gobierno (x) &lt;numeric&gt; \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 624 | 52.00 |   52.84 |  52.84\n    1 | 358 | 29.83 |   30.31 |  83.15\n    2 | 176 | 14.67 |   14.90 |  98.05\n    3 |  23 |  1.92 |    1.95 | 100.00\n &lt;NA&gt; |  19 |  1.58 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$conf_cong)\n\nConfianza: Congreso (x) &lt;numeric&gt; \n# total N=1200 valid N=1178 mean=0.59 sd=0.71\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 628 | 52.33 |   53.31 |  53.31\n    1 | 408 | 34.00 |   34.63 |  87.95\n    2 | 134 | 11.17 |   11.38 |  99.32\n    3 |   8 |  0.67 |    0.68 | 100.00\n &lt;NA&gt; |  22 |  1.83 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$conf_inst)\n\nConfianza en instituciones (x) &lt;numeric&gt; \n# total N=1200 valid N=1162 mean=2.42 sd=2.49\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 397 | 33.08 |   34.17 |  34.17\n    1 | 141 | 11.75 |   12.13 |  46.30\n    2 | 130 | 10.83 |   11.19 |  57.49\n    3 | 111 |  9.25 |    9.55 |  67.04\n    4 | 169 | 14.08 |   14.54 |  81.58\n    5 |  71 |  5.92 |    6.11 |  87.69\n    6 |  41 |  3.42 |    3.53 |  91.22\n    7 |  41 |  3.42 |    3.53 |  94.75\n    8 |  44 |  3.67 |    3.79 |  98.54\n    9 |  11 |  0.92 |    0.95 |  99.48\n   10 |   4 |  0.33 |    0.34 |  99.83\n   11 |   1 |  0.08 |    0.09 |  99.91\n   12 |   1 |  0.08 |    0.09 | 100.00\n &lt;NA&gt; |  38 |  3.17 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nVemos que los valores (labels) de cada categoría de las primeras variables que recodificamos no se corresponden con el nuevo valor. Para re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\n\nproc_data$conf_gob &lt;- set_labels(proc_data$conf_gob,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_cong &lt;- set_labels(proc_data$conf_cong,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_jud &lt;- set_labels(proc_data$conf_jud,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_partpol &lt;- set_labels(proc_data$conf_partpol,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\ny volvemos a revisar\n\nfrq(proc_data$conf_gob)\n\nConfianza: Gobierno (x) &lt;numeric&gt; \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 624 | 52.00 |   52.84 |  52.84\n    1 |    Poca | 358 | 29.83 |   30.31 |  83.15\n    2 |    Algo | 176 | 14.67 |   14.90 |  98.05\n    3 |   Mucha |  23 |  1.92 |    1.95 | 100.00\n &lt;NA&gt; |    &lt;NA&gt; |  19 |  1.58 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$conf_cong)\n\nConfianza: Congreso (x) &lt;numeric&gt; \n# total N=1200 valid N=1178 mean=0.59 sd=0.71\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 628 | 52.33 |   53.31 |  53.31\n    1 |    Poca | 408 | 34.00 |   34.63 |  87.95\n    2 |    Algo | 134 | 11.17 |   11.38 |  99.32\n    3 |   Mucha |   8 |  0.67 |    0.68 | 100.00\n &lt;NA&gt; |    &lt;NA&gt; |  22 |  1.83 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n4.2. Educación\n\n[reeduc_1] = REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)\n\na. Descriptivo\n\nfrq(proc_data$reeduc_1)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=5.05 sd=1.22\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |   8 |  0.67 |    0.67 |   0.67\n    2 |  53 |  4.42 |    4.42 |   5.08\n    3 |  36 |  3.00 |    3.00 |   8.08\n    4 | 161 | 13.42 |   13.42 |  21.50\n    5 | 643 | 53.58 |   53.58 |  75.08\n    6 | 109 |  9.08 |    9.08 |  84.17\n    7 | 190 | 15.83 |   15.83 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación\n\nVemos que no hay datos perdidos\nValores\n\nPara hacer más fácil el análisis, recodificamos en tres categorías (en este caso decisión arbitraria. Se debería tener una razón teórica para recodificar)\n1.  Analfabeto                                =   Educacion basica    =   1\n2   Básica incompleta                         =   Educacion basica    =   1\n3.  Básica completa                           =   Educacion basica    =   1\n4.  Secundaria, media, técnica incompleta     =   Educacion media     =   2\n5.  Secundaria, media, técnica completa       =   Educacion media     =   2\n6.  Superior incompleta                       =   Educacion superior  =   3\n7.  Superior completa                         =   Educacion superior  =   3\n\n\n# recodificacion usando funcion 'recode' de la libreria car\nproc_data$reeduc_1 &lt;- car::recode(proc_data$reeduc_1, \"c(1,2,3)=1; c(4,5)=2; c(6,7)=3\")\n\nComprobar con un nuevo descriptivo:\n\nfrq(proc_data$reeduc_1)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=2.17 sd=0.55\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |  97 |  8.08 |    8.08 |   8.08\n    2 | 804 | 67.00 |   67.00 |  75.08\n    3 | 299 | 24.92 |   24.92 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nSe observa que los valores coinciden con la recodificación (los casos se acumulan entre las categorías 1 y 3), pero las etiquetas ahora no coinciden; se soluciona en el siguiente paso.\nc. Etiquetado\nPara re-etiquetar valores usamos la función factor, de R base. Con esta función aprovechamos de transformar la variable educación en una variable categórica, que es lo que corresponde para una variable ordinal.\n\nproc_data$reeduc_1 &lt;- factor(proc_data$reeduc_1,\n                             labels = c(\"Educacion basica\", \"Educacion media\", \"Educacion superior\"),\n                             levels = c(1, 2, 3))\n\nLuego renombramos la variable con un nombre más sustantivo\n\nproc_data &lt;- rename(proc_data,\"educacion\"=reeduc_1)\n\nAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\n\nget_label(proc_data$educacion)\n\nNULL\n\nproc_data$educacion &lt;- set_label(x = proc_data$educacion,label = \"Educación\")\n\n\n\n\n4.3. Sexo\n\n[sexo] = SEXO Sexo\n\na. Descriptivo\n\nfrq(proc_data$sexo)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=1.54 sd=0.50\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 | 555 | 46.25 |   46.25 |  46.25\n    2 | 645 | 53.75 |   53.75 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación\nEn general esta variable no tiene problemas de casos perdidos ni de etiquetas, pero de todas maneras vamos a hacer un cambio de acuerdo a convenciones en análisis de datos, donde por lo general hombres tienen valor 0 y mujeres 1:\n\nproc_data$sexo &lt;- car::recode(proc_data$sexo, \"1=0;2=1\")\n\nc. Etiquetado\nY ahora cambiamos las etiquetas de acuerdo a la recodificación anterior:\n\nproc_data$sexo &lt;- factor(proc_data$sexo,\n            labels=c( \"Hombre\",\n                      \"Mujer\"),\n            levels=c(0,1))\n\nTambién queremos cambiar la etiqueta de la variable.\n\nget_label(proc_data$sexo)\n\nNULL\n\nproc_data$sexo &lt;- set_label(x = proc_data$sexo,label = \"Sexo\")\n\nRevisar con un nuevo descriptivo:\n\nfrq(proc_data$sexo)\n\nSexo (x) &lt;categorical&gt; \n# total N=1200 valid N=1200 mean=1.54 sd=0.50\n\nValue  |   N | Raw % | Valid % | Cum. %\n---------------------------------------\nHombre | 555 | 46.25 |   46.25 |  46.25\nMujer  | 645 | 53.75 |   53.75 | 100.00\n&lt;NA&gt;   |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\n4.4 Edad\n\n[edad] = EDAD Edad.\n\na. Descriptivo\n\nfrq(proc_data$edad)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=44.49 sd=17.01\n\nValue |  N | Raw % | Valid % | Cum. %\n-------------------------------------\n   18 | 31 |  2.58 |    2.58 |   2.58\n   19 | 29 |  2.42 |    2.42 |   5.00\n   20 | 25 |  2.08 |    2.08 |   7.08\n   21 | 23 |  1.92 |    1.92 |   9.00\n   22 | 21 |  1.75 |    1.75 |  10.75\n   23 | 26 |  2.17 |    2.17 |  12.92\n   24 | 28 |  2.33 |    2.33 |  15.25\n   25 | 19 |  1.58 |    1.58 |  16.83\n   26 | 21 |  1.75 |    1.75 |  18.58\n   27 | 23 |  1.92 |    1.92 |  20.50\n   28 | 19 |  1.58 |    1.58 |  22.08\n   29 | 22 |  1.83 |    1.83 |  23.92\n   30 | 34 |  2.83 |    2.83 |  26.75\n   31 | 21 |  1.75 |    1.75 |  28.50\n   32 | 26 |  2.17 |    2.17 |  30.67\n   33 | 21 |  1.75 |    1.75 |  32.42\n   34 | 14 |  1.17 |    1.17 |  33.58\n   35 | 22 |  1.83 |    1.83 |  35.42\n   36 | 28 |  2.33 |    2.33 |  37.75\n   37 | 14 |  1.17 |    1.17 |  38.92\n   38 | 24 |  2.00 |    2.00 |  40.92\n   39 | 23 |  1.92 |    1.92 |  42.83\n   40 | 32 |  2.67 |    2.67 |  45.50\n   41 | 21 |  1.75 |    1.75 |  47.25\n   42 | 16 |  1.33 |    1.33 |  48.58\n   43 | 22 |  1.83 |    1.83 |  50.42\n   44 | 16 |  1.33 |    1.33 |  51.75\n   45 | 25 |  2.08 |    2.08 |  53.83\n   46 | 19 |  1.58 |    1.58 |  55.42\n   47 | 15 |  1.25 |    1.25 |  56.67\n   48 | 26 |  2.17 |    2.17 |  58.83\n   49 | 19 |  1.58 |    1.58 |  60.42\n   50 | 35 |  2.92 |    2.92 |  63.33\n   51 |  6 |  0.50 |    0.50 |  63.83\n   52 | 24 |  2.00 |    2.00 |  65.83\n   53 |  7 |  0.58 |    0.58 |  66.42\n   54 | 13 |  1.08 |    1.08 |  67.50\n   55 | 27 |  2.25 |    2.25 |  69.75\n   56 | 18 |  1.50 |    1.50 |  71.25\n   57 | 17 |  1.42 |    1.42 |  72.67\n   58 | 34 |  2.83 |    2.83 |  75.50\n   59 | 17 |  1.42 |    1.42 |  76.92\n   60 | 24 |  2.00 |    2.00 |  78.92\n   61 | 18 |  1.50 |    1.50 |  80.42\n   62 | 21 |  1.75 |    1.75 |  82.17\n   63 | 15 |  1.25 |    1.25 |  83.42\n   64 | 20 |  1.67 |    1.67 |  85.08\n   65 | 12 |  1.00 |    1.00 |  86.08\n   66 | 24 |  2.00 |    2.00 |  88.08\n   67 |  9 |  0.75 |    0.75 |  88.83\n   68 | 12 |  1.00 |    1.00 |  89.83\n   69 | 15 |  1.25 |    1.25 |  91.08\n   70 | 30 |  2.50 |    2.50 |  93.58\n   71 |  9 |  0.75 |    0.75 |  94.33\n   72 | 10 |  0.83 |    0.83 |  95.17\n   73 |  8 |  0.67 |    0.67 |  95.83\n   74 |  8 |  0.67 |    0.67 |  96.50\n   75 |  8 |  0.67 |    0.67 |  97.17\n   76 | 12 |  1.00 |    1.00 |  98.17\n   77 |  5 |  0.42 |    0.42 |  98.58\n   78 |  2 |  0.17 |    0.17 |  98.75\n   79 |  2 |  0.17 |    0.17 |  98.92\n   80 |  4 |  0.33 |    0.33 |  99.25\n   82 |  1 |  0.08 |    0.08 |  99.33\n   84 |  2 |  0.17 |    0.17 |  99.50\n   85 |  3 |  0.25 |    0.25 |  99.75\n   86 |  1 |  0.08 |    0.08 |  99.83\n   87 |  1 |  0.08 |    0.08 |  99.92\n   89 |  1 |  0.08 |    0.08 | 100.00\n &lt;NA&gt; |  0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación: no es necesario en este caso\nc. Etiquetado\nCambio la etiqueta de la variable.\n\nget_label(proc_data$edad)\n\nNULL\n\nproc_data$edad &lt;- set_label(x = proc_data$edad,label = \"Edad\")",
    "crumbs": [
      "Practicos",
      "Práctico 3"
    ]
  },
  {
    "objectID": "resource/03-resource.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "href": "resource/03-resource.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "5. Generación de base de datos procesada para el análisis",
    "text": "5. Generación de base de datos procesada para el análisis\nAntes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nPrimero vamos a reformatear el objeto proc_data como base de datos (as.data.frame), paso necesario para que sea reconocido como tal por stargazer\n\nproc_data &lt;-as.data.frame(proc_data)\nstargazer(proc_data, type=\"text\")\n\n\n===========================================\nStatistic      N    Mean   St. Dev. Min Max\n-------------------------------------------\nconf_gob     1,181  0.660   0.800    0   3 \nconf_cong    1,178  0.594   0.714    0   3 \nconf_jud     1,186  0.717   0.789    0   3 \nconf_partpol 1,178  0.451   0.673    0   3 \nedad         1,200 44.491   17.008  18  89 \nidenpa       1,200 152.000  0.000   152 152\nconf_inst    1,162  2.420   2.489    0  12 \n-------------------------------------------\n\n\n\nSi se desea modificar las columnas que aparecen en la tabla se puede ocupar la opción summary.stat, donde se pueden especificar:\n\n“max” maximum\n“mean” mean\n“median” median\n“min” minimum\n“n” number of observations\n“p25” 25th percentile\n“p75” 75th percentile\n“sd” standard deviation\n\nPor ejemplo, si quiero una tabla solo con promedio, n, sd y p75: stargazer(data, type=\"text\", summary.stat = c(\"mean\", \"n\", \"sd\", \"p75\"))\n\n\nGuardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como “C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar\n\nEl comando para guardar es save:\n\nsave(proc_data,file = \"[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData\")\n\nEn este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\n\nsave(proc_data, file = \"input/data/proc/data_proc.RData\")",
    "crumbs": [
      "Practicos",
      "Práctico 3"
    ]
  },
  {
    "objectID": "resource/02-resource.html",
    "href": "resource/02-resource.html",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos en los procedimientos básicos del uso del lenguaje y ambiente R.\nEn detalle, aprenderemos:\n\nHerramientas básicas de programación en R\nOperadores en R\nTipos de datos\n\n\n\n\nTal vez una de las dificultades más comunes o cotidianas del uso de R es el orden de trabajo, en donde tenemos cientos de archivos, scripts, gráficos, bases de datos u otros repartidos desordenadamente en nuestro computador. También se da mucho el caso en que, cuando queremos trabajar con alguien, tenemos que cambiar las rutas de los archivos, por ejemplo en dónde están las bases de datos, ya que nuestros ordenadores y usuarios se llaman y son escencialmente distintos.\n¿Cómo podemos sortear eso? Siguiendo un flujo de trabajo reproducible, autocontenido y ordenado. En este curso trabajaremos R con un flujo de trabajo reproducible, basado en el sistema IPO. El protocolor IPO es una plantilla/protocolo de estructura digital de carpetas que tiene por objetivo el organizar, procesar y documentar los datos de un proyecto de investigación con miras a la apertura de los datos en un repositorio público y de acceso libre. En concreto, el sistema IPO se propone abordar brevemente todo lo referente a los Datos, Métodos y Resultados.\nLleva este nombre por el sistema de carpetas que se implementan: Input, Procesamiento y Output. En la carpeta Input guardaremos todos aquellso recursos iniciales que usaremos, como las bases de datos, el libro de códigos, entre otros. En la carpeta de Procesamiento, como dice el nombre, guardaremos todos los archivos que procesen y analicen datos. En la carpeta Output guardaremos todo aquello que hayamos producido en los archivos de procesamiento, como las bases de datos procesadas listas para compartir o publicas, los documentos de reporte, informes o analísis, gráficos o tablas.\n\n\n\n\n\n\n\n\n\nLa implementación de la reproducibilidad en este tipo de protocolos se basa en generar un conjunto de archivos auto-contenidos organizado en una estructura de proyecto que cualquier persona pueda compartir y ejecutar. En otras palabras, debe tener todo lo que necesita para ejecutar y volver a ejecutar el análisis. Para conocer más, visita el Laboratorio de Ciencia Abierta.\n\n\n\n\n\n\n\n\n\n\n\n\nUn Rproject es una herramienta de R que nos permite establecer un directorio de trabajo en una carpeta de nuestro computador. Al hacerlo, establecemos un espacio de trabajo que permite crear una estructura de carpetas donde guardar los documentos asociados al proyecto. De esta forma, creamos un conjunto de archivos autocontenidos en un solo lugar que nos permite organizar nuestro trabajo y facilitar la reproducibilidad. En las próximas sesiones estableceremos un protocolo de trabajo que permite organizar y armonizar el trabajo: el protocolo IPO.\nPara crear un Rproject:\n\nAbrir Rstudio\nSeleccionar Archivo -&gt; Nuevo proyecto\n\n\n\nSeleccionamos la opción de directorio existente\nSeleccionamos la carpeta donde descargamos nuestro repositorio de Github en el paso anterior\nApretamos el botón de crear proyecto\n\n\n\n\nRevisemos algunos conocimientos básicos para la programación en R. Pero antes, tengamos dos cosas en mente:\n\nPrimero, ¿qué es codificar?, en programación codificar corresponde a un proceso de entrega de instrucciones en un lenguaje específico, siguiendo un orden lógico y coherente.\nSegundo, de aquí en adelante nos manejaremos con una máxima en el curso; existe un acuerdo implícito entre tú y R: R hará todos los cálculos por ti, pero en cambio tú debes dar las instrucciones con total precisión.\n\n\n\nUno de los usos más sencillos y que están a la base de R, es usarlo como una calculadora.\n\n5+5\n\n[1] 10\n\n25/5\n\n[1] 5\n\n2*2\n\n[1] 4\n\n27-2\n\n[1] 25\n\n\nComo podrás ver, el resultado de estas instrucciones aparecen como un [1] en la consola. También podemos hacer operatorias más complejas y con más cálculos.\n\n12*(7+2)+(45-32)+8\n\n[1] 129\n\n22^2 - 2^2\n\n[1] 480\n\n1/200 * 30\n\n[1] 0.15\n\n\n\n\n\nR es un lenguaje de programación orientado a objetos. ¿Qué significa eso?, implica que podemos crear elementos dentro del ambiente de R, a los cuales les asignaremos información que quedará almacenada, información que puede ir desde números, palabras, cálculos hasta grandes bases de datos.\nTodas las instrucciones en R en las que crees objetos, es decir, instrucciones de asignación, tendrán la misma estructura:\nnombre_objeto &lt;- valor\nEl asignador &lt;- se utiliza para crear objetos y forma parte de uno de los operadores usados en R.\nLos elementos que podemos asignar a objetos son múltiples, como números, palabras acompañadas siempre de corchetes \" \" y vectores que corresponden a un conjunto o secuencia de elementos del mismo tipo definidos por la funcion de concatenar = c().\nVeamos un ejemplo creando objetos:\n\nx &lt;- 4 # asignar\n\nx # ejecutar\n\n[1] 4\n\ny &lt;- \"Hola mundo\" # los carácteres alfabéticos siempre van acompañados de corchetes\n\ny \n\n[1] \"Hola mundo\"\n\n\nHagamos un pequeño reto: ¿Cuál es el valor de a y b? Si a &lt;- 5; b &lt;- a; a &lt;- 4\n\na &lt;- 5\nb &lt;- a\na &lt;- 4\n\nprint(a) # imprimir en la consola\n\n[1] 4\n\nprint(b)\n\n[1] 5\n\na + 10\n\n[1] 14\n\n\nAhora, sea z = a^2 ¿qué resultado obtenemos de a * b + z?\n\nz &lt;- a^2 # asignar\n\na * b + z\n\n[1] 36\n\n\n¿Y concatenando? Hacemos un vector.\n\nedad &lt;- c(18,22,36,19,35) # concatenar (variable de razon)\n\nedad\n\n[1] 18 22 36 19 35\n\ngenero &lt;- c(3,1,1,2,3) # masculino = 1; femenino = 2; transgenero = 3 (variable nominal)\n\ngenero \n\n[1] 3 1 1 2 3\n\ngse &lt;- c(\"ABC1\", \"C2\", \"E\", \"AbC1\", \"E\")  # tambíen se pueden usar carácteres (variable ordinal)\n\ngse\n\n[1] \"ABC1\" \"C2\"   \"E\"    \"AbC1\" \"E\"   \n\n\nAdemás de lo anterior, en R es fundamental la creación de data.frames. Un Data.frame es una estructura de datos de dos dimensiones (columnas y filas), donde las columnas pueden ser de diferente naturaleza, pero deben tener el mismo largo. A partir de ella agrupamos variables en una matriz, o sea, construimos una base de datos. Es como “pegar” las columnas (variables) una al lado de otra.\nCreemos un data.frame con los vectores que ya creamos antes.\n\nbase1 &lt;- data.frame(genero, gse, edad) # Resulta como objeto de \"datos\" en\n                                       # entorno.\n\nbase1\n\n  genero  gse edad\n1      3 ABC1   18\n2      1   C2   22\n3      1    E   36\n4      2 AbC1   19\n5      3    E   35\n\n\nComo puedes ver, para crear el data.frame usamos la función que lleva el mismo nombre, colocando dentro del paréntesis los vectores que creamos anteriormente: data.frame(mis_vectores).\nAhora, creemos un data.frame desce cero. En este ejemplo, crearemos los vectores dentro de la función data.frame().\n\n# Ejemplo de como crear un data.frame desde 0: \n\nbase2 &lt;- data.frame(Sexo=c(\"H\",\"M\",\"H\",\"M\",\"H\",\"M\"),\n                    Estatura=c(1.83,1.76,1.82,1.60,1.90,1.66),\n                    Peso=c(67,58,66,48,75,55))\n\nhead(base2)  # Me permite visualizar las primeras filas\n\n  Sexo Estatura Peso\n1    H     1.83   67\n2    M     1.76   58\n3    H     1.82   66\n4    M     1.60   48\n5    H     1.90   75\n6    M     1.66   55\n\n\n\n\n\n\nAntes de trabajar con datos, debemos conocer el concepto de operadores. Estos símbolos no son de uso exclusivo en R, pero no todos tienen el mismo significado que en otros softwares.\nLos operadores son símbolos que permiten, en los distintos procedimientos de procesamiento, simplificar procesos. Por ejemplo, serán útilizados cuando filtremos nuestros datos para personas de ciertas categorías, cuando calculemos variables nuevas (de manera aritmética o condicional) o, simplemente, cuando queramos hacer procesos “concatenados”.\n\nVeamos algunos ejemplos:\n\n20 == 5 # igualdad\n\n[1] FALSE\n\n30 &gt;= 14 # mayor o igual que\n\n[1] TRUE\n\n22 &lt;= 2 # menor o igual que\n\n[1] FALSE\n\n25 != 10 # no es igual a\n\n[1] TRUE\n\np = 10; y = 5; p &lt;= y # operatoria en objetos\n\n[1] FALSE\n\n\n\n\n\n\n\nEn R, al igual que en la mayoría de lenguajes de programación, contamos con datos de diversos tipos, en razón de los cuales podemos realizar determinados procedimientos de tratamiento o análisis.\nLos tipos de datos están íntimamente relacionados con el nivel de medición de las variables a las que corresponden. Como viste en clases, la teoría de los niveles de medición contempla cuatro tipos:\n\n\n\n\nPara responder esta pregunta, exploremos algunos datos. En esta oportunidad trabajaremos con el Estudio Longitudinal Social de Chile, que es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena, basándose en modelos conceptuales descritos en la literatura nacional e internacional que abordan dichas materias. Se orienta a examinar los principales antecedentes, factores moderadores y mediadores, así como las principales consecuencias asociadas al desarrollo de distintas formas de conflicto y cohesión social en Chile. Su objetivo fundamental es constituirse en un insumo empírico para la comprensión de las creencias, actitudes y percepciones de los chilenos hacia las distintas dimensiones de la convivencia y el conflicto, y como éstas cambian a lo largo del tiempo.\n\n\n\n\nEn R es es posible importar y exportar datos que se encuentren en cualquier formato: ya sea .csv, .dta, .sav, .xlsx y, por supuesto, .rds y .RData. Sin embargo, para poder hacerlo, lo primero es instalar y cargar las librerías que contienen las funciones necesarias para la importación de distintos tipos de archivos.\nPero, ¿dónde están mis datos? Como hemos mencionado, nuestros datos los dejaremos en la carpeta input/data de nuestro proyecto. La base con la que trabajaremos en este práctico pueden encontrarla en la página oficial de ELSOC en este enlace.\nLuego de descargar la base de datos, asegurate de dejar el archivo .sav en la carpeta input/data de tu proyecto. Nota: Los datos tendrán distinto nombre según su formato (.sav, .csv, .dta, etc.).\nUna vez descargados los datos, procedemos a importar nuestra base de datos. Para ello, en nuestro script, dejamos indicado que a partir de la lectura de los datos con load(), crearemos un objeto que contiene la base de datos. Fijate en el Enviroment, ya que si lo anterior se logra, el objeto aparecerá allí.\nLa estructura general para importar datos es la siguiente:\nread_*(\"ruta_hacia_archivo/nombre_archivo.*\")\nSin embargo, por esta vez podemos descargar la base desde internet\n\nload(url((\"https://github.com/cursos-metodos-facso/metod1-MCS/raw/main/resource/files/ELSOC_W05_v1.0_R.RData\"))\n\n\n\n\n\n\n\nNota\n\n\n\nPara importar los datos en R debemos tener en consideración tres cosas:\n\nCómo se llaman los datos (en nuestro caso ELSOC_W05_v1.0_SPSS)\nEl formato de nuestros datos (en nuestro caso .sav)\nEl lugar de donde están alojados nuestros datos\n\n\n\n\n\nNo siempre nuestros datos vendrán en un único formato. Para ello, R cuenta con otras formas de leer distintos tipos de formatos.\n\nreadxl para archivos .xlsx\nhaven para archivos .sav\nreadr para .csv\n\n\n\n\n\nLo más probable es que no trabajemos con todos los datos que importamos, por lo que debemos seleccionar aquellas variables con las que trabajaremos para nuestro problema de investigación (cualquiera sea).\nPero, para ello primero debemos explorar nuestros datos. En R, las funciones más comunes para explorar datos son:\n\nView(elsoc_2021) # Ver datos\nnames(elsoc_2021) # Nombre de columnas\ndim(elsoc_2021) # Dimensiones\n\nTenemos una base de datos con 2740 casos o filas y con 311 variables o columnas.\n\n\n\nEn R se trabaja a partir de paquetes (packages). ¿Qué son? De forma resumida, los paquetes son un conjunto de funciones o herramientas que pueden ser usadas en R. Los directorios de R donde se almacenan los paquetes se denominan librerías. La lógica es instalar paquetes y luego cargar (o llamar) las librerías cada vez que es necesario usarlas.\nUsualmente para cargar paquetes lo hacemos de la siguiente manera:\n\ninstall.packages(\"paquete\")\nlibrary(paquete)\n\nPero en esta ocasión utilizaremos un paquete llamado pacman, que facilita y agiliza la lectura (instalación y carga) de los paquetes a utilizar en R. De esta forma lo instalamos 1 única vez así:\n\ninstall.packages(\"pacman\")\nlibrary(pacman)\n\nLuego instalaremos y cargaremos los paquetes de R de la siguiente manera, volviendo más eficiente el procedimiento de carga de paquetes.\nEn este práctico utilizaremos seis paquetes\n\npacman: este facilita y agiliza la lectura de los paquetes a utilizar en R\ntidyverse: colección de paquetes, de la cual utilizaremos dplyr y haven\ndplyr: nos permite seleccionar variables de un set de datos\nhaven: cargar y exportar bases de datos en formatos .sav y .dta\ncar: para recodificar/agrupar valores de variables\n\n\npacman::p_load(dplyr, # para manipular datos\n               car # para recodificar datos\n               )\n\nComo se puede ver, antes de la función p_load hay un ::, esto se refiere a que se “fuerza” que esa función provenga de ese paquete (en este caso del paquete pacman).\n\n\n\n\n\nLos datos character están directamente asociados a las variables cualitativas (o categóricas). Generalmente suelen ser variables de texto abierto, como es el caso de la variable pais, que detalla el país de procedencia de la persona encuestada.\nPara conocer cuál es el tipo de variable en R, utilizamos el comando class(), y para detallar dentro de la base de datos cuál es la variable de interés, utilizamos el símbolo $ posterior a la base de datos:\n\nclass(elsoc_2021$comuna) # siempre es la misma estructura = base$variable\n\n[1] \"character\"\n\n\nSin embargo, estas variables no tienden a ser las mejores a la hora de presentar nuestros resultados. Como solución, tenemos las variables de tipo Factor.\n\n\n\nLas variables de tipo factor son ideales para trabajar con variables de tipo nominal u ordinal. Esto es así debido a que permiten establecer un orden entre las categorías de la variable, lo cual es fundamental si trabajamos, por ejemplo, con variables nominales como el sexo de los encuestados, o si trabajamos con variables ordinales como su ideología política.\n\nclass(elsoc_2021$m0_sexo)\n\n[1] \"factor\"\n\nclass(elsoc_2021$m38) #religion\n\n[1] \"factor\"\n\n\n\n\n\nLas variables de tipo numeric son variables de tipo númerica, las cuales pueden ser intervales o de razón. Así, por ejemplo, cuando trabajamos con variables de razón trabajamos con variables como el número de hijos o la edad (aunque sería extraño encuestar a alguien con 0 años).\n\nclass(elsoc_2021$m0_edad)\n\n[1] \"numeric\"",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "resource/02-resource.html#objetivo-de-la-práctica",
    "href": "resource/02-resource.html#objetivo-de-la-práctica",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos en los procedimientos básicos del uso del lenguaje y ambiente R.\nEn detalle, aprenderemos:\n\nHerramientas básicas de programación en R\nOperadores en R\nTipos de datos",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "resource/02-resource.html#flujo-de-trabajo-en-r",
    "href": "resource/02-resource.html#flujo-de-trabajo-en-r",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Tal vez una de las dificultades más comunes o cotidianas del uso de R es el orden de trabajo, en donde tenemos cientos de archivos, scripts, gráficos, bases de datos u otros repartidos desordenadamente en nuestro computador. También se da mucho el caso en que, cuando queremos trabajar con alguien, tenemos que cambiar las rutas de los archivos, por ejemplo en dónde están las bases de datos, ya que nuestros ordenadores y usuarios se llaman y son escencialmente distintos.\n¿Cómo podemos sortear eso? Siguiendo un flujo de trabajo reproducible, autocontenido y ordenado. En este curso trabajaremos R con un flujo de trabajo reproducible, basado en el sistema IPO. El protocolor IPO es una plantilla/protocolo de estructura digital de carpetas que tiene por objetivo el organizar, procesar y documentar los datos de un proyecto de investigación con miras a la apertura de los datos en un repositorio público y de acceso libre. En concreto, el sistema IPO se propone abordar brevemente todo lo referente a los Datos, Métodos y Resultados.\nLleva este nombre por el sistema de carpetas que se implementan: Input, Procesamiento y Output. En la carpeta Input guardaremos todos aquellso recursos iniciales que usaremos, como las bases de datos, el libro de códigos, entre otros. En la carpeta de Procesamiento, como dice el nombre, guardaremos todos los archivos que procesen y analicen datos. En la carpeta Output guardaremos todo aquello que hayamos producido en los archivos de procesamiento, como las bases de datos procesadas listas para compartir o publicas, los documentos de reporte, informes o analísis, gráficos o tablas.\n\n\n\n\n\n\n\n\n\nLa implementación de la reproducibilidad en este tipo de protocolos se basa en generar un conjunto de archivos auto-contenidos organizado en una estructura de proyecto que cualquier persona pueda compartir y ejecutar. En otras palabras, debe tener todo lo que necesita para ejecutar y volver a ejecutar el análisis. Para conocer más, visita el Laboratorio de Ciencia Abierta.",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "resource/02-resource.html#rproject",
    "href": "resource/02-resource.html#rproject",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Un Rproject es una herramienta de R que nos permite establecer un directorio de trabajo en una carpeta de nuestro computador. Al hacerlo, establecemos un espacio de trabajo que permite crear una estructura de carpetas donde guardar los documentos asociados al proyecto. De esta forma, creamos un conjunto de archivos autocontenidos en un solo lugar que nos permite organizar nuestro trabajo y facilitar la reproducibilidad. En las próximas sesiones estableceremos un protocolo de trabajo que permite organizar y armonizar el trabajo: el protocolo IPO.\nPara crear un Rproject:\n\nAbrir Rstudio\nSeleccionar Archivo -&gt; Nuevo proyecto\n\n\n\nSeleccionamos la opción de directorio existente\nSeleccionamos la carpeta donde descargamos nuestro repositorio de Github en el paso anterior\nApretamos el botón de crear proyecto",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "resource/02-resource.html#conocimientos-básicos-de-programación",
    "href": "resource/02-resource.html#conocimientos-básicos-de-programación",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Revisemos algunos conocimientos básicos para la programación en R. Pero antes, tengamos dos cosas en mente:\n\nPrimero, ¿qué es codificar?, en programación codificar corresponde a un proceso de entrega de instrucciones en un lenguaje específico, siguiendo un orden lógico y coherente.\nSegundo, de aquí en adelante nos manejaremos con una máxima en el curso; existe un acuerdo implícito entre tú y R: R hará todos los cálculos por ti, pero en cambio tú debes dar las instrucciones con total precisión.\n\n\n\nUno de los usos más sencillos y que están a la base de R, es usarlo como una calculadora.\n\n5+5\n\n[1] 10\n\n25/5\n\n[1] 5\n\n2*2\n\n[1] 4\n\n27-2\n\n[1] 25\n\n\nComo podrás ver, el resultado de estas instrucciones aparecen como un [1] en la consola. También podemos hacer operatorias más complejas y con más cálculos.\n\n12*(7+2)+(45-32)+8\n\n[1] 129\n\n22^2 - 2^2\n\n[1] 480\n\n1/200 * 30\n\n[1] 0.15\n\n\n\n\n\nR es un lenguaje de programación orientado a objetos. ¿Qué significa eso?, implica que podemos crear elementos dentro del ambiente de R, a los cuales les asignaremos información que quedará almacenada, información que puede ir desde números, palabras, cálculos hasta grandes bases de datos.\nTodas las instrucciones en R en las que crees objetos, es decir, instrucciones de asignación, tendrán la misma estructura:\nnombre_objeto &lt;- valor\nEl asignador &lt;- se utiliza para crear objetos y forma parte de uno de los operadores usados en R.\nLos elementos que podemos asignar a objetos son múltiples, como números, palabras acompañadas siempre de corchetes \" \" y vectores que corresponden a un conjunto o secuencia de elementos del mismo tipo definidos por la funcion de concatenar = c().\nVeamos un ejemplo creando objetos:\n\nx &lt;- 4 # asignar\n\nx # ejecutar\n\n[1] 4\n\ny &lt;- \"Hola mundo\" # los carácteres alfabéticos siempre van acompañados de corchetes\n\ny \n\n[1] \"Hola mundo\"\n\n\nHagamos un pequeño reto: ¿Cuál es el valor de a y b? Si a &lt;- 5; b &lt;- a; a &lt;- 4\n\na &lt;- 5\nb &lt;- a\na &lt;- 4\n\nprint(a) # imprimir en la consola\n\n[1] 4\n\nprint(b)\n\n[1] 5\n\na + 10\n\n[1] 14\n\n\nAhora, sea z = a^2 ¿qué resultado obtenemos de a * b + z?\n\nz &lt;- a^2 # asignar\n\na * b + z\n\n[1] 36\n\n\n¿Y concatenando? Hacemos un vector.\n\nedad &lt;- c(18,22,36,19,35) # concatenar (variable de razon)\n\nedad\n\n[1] 18 22 36 19 35\n\ngenero &lt;- c(3,1,1,2,3) # masculino = 1; femenino = 2; transgenero = 3 (variable nominal)\n\ngenero \n\n[1] 3 1 1 2 3\n\ngse &lt;- c(\"ABC1\", \"C2\", \"E\", \"AbC1\", \"E\")  # tambíen se pueden usar carácteres (variable ordinal)\n\ngse\n\n[1] \"ABC1\" \"C2\"   \"E\"    \"AbC1\" \"E\"   \n\n\nAdemás de lo anterior, en R es fundamental la creación de data.frames. Un Data.frame es una estructura de datos de dos dimensiones (columnas y filas), donde las columnas pueden ser de diferente naturaleza, pero deben tener el mismo largo. A partir de ella agrupamos variables en una matriz, o sea, construimos una base de datos. Es como “pegar” las columnas (variables) una al lado de otra.\nCreemos un data.frame con los vectores que ya creamos antes.\n\nbase1 &lt;- data.frame(genero, gse, edad) # Resulta como objeto de \"datos\" en\n                                       # entorno.\n\nbase1\n\n  genero  gse edad\n1      3 ABC1   18\n2      1   C2   22\n3      1    E   36\n4      2 AbC1   19\n5      3    E   35\n\n\nComo puedes ver, para crear el data.frame usamos la función que lleva el mismo nombre, colocando dentro del paréntesis los vectores que creamos anteriormente: data.frame(mis_vectores).\nAhora, creemos un data.frame desce cero. En este ejemplo, crearemos los vectores dentro de la función data.frame().\n\n# Ejemplo de como crear un data.frame desde 0: \n\nbase2 &lt;- data.frame(Sexo=c(\"H\",\"M\",\"H\",\"M\",\"H\",\"M\"),\n                    Estatura=c(1.83,1.76,1.82,1.60,1.90,1.66),\n                    Peso=c(67,58,66,48,75,55))\n\nhead(base2)  # Me permite visualizar las primeras filas\n\n  Sexo Estatura Peso\n1    H     1.83   67\n2    M     1.76   58\n3    H     1.82   66\n4    M     1.60   48\n5    H     1.90   75\n6    M     1.66   55",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "resource/02-resource.html#operadores-en-r",
    "href": "resource/02-resource.html#operadores-en-r",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Antes de trabajar con datos, debemos conocer el concepto de operadores. Estos símbolos no son de uso exclusivo en R, pero no todos tienen el mismo significado que en otros softwares.\nLos operadores son símbolos que permiten, en los distintos procedimientos de procesamiento, simplificar procesos. Por ejemplo, serán útilizados cuando filtremos nuestros datos para personas de ciertas categorías, cuando calculemos variables nuevas (de manera aritmética o condicional) o, simplemente, cuando queramos hacer procesos “concatenados”.\n\nVeamos algunos ejemplos:\n\n20 == 5 # igualdad\n\n[1] FALSE\n\n30 &gt;= 14 # mayor o igual que\n\n[1] TRUE\n\n22 &lt;= 2 # menor o igual que\n\n[1] FALSE\n\n25 != 10 # no es igual a\n\n[1] TRUE\n\np = 10; y = 5; p &lt;= y # operatoria en objetos\n\n[1] FALSE",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "resource/02-resource.html#tipos-de-datos",
    "href": "resource/02-resource.html#tipos-de-datos",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "En R, al igual que en la mayoría de lenguajes de programación, contamos con datos de diversos tipos, en razón de los cuales podemos realizar determinados procedimientos de tratamiento o análisis.\nLos tipos de datos están íntimamente relacionados con el nivel de medición de las variables a las que corresponden. Como viste en clases, la teoría de los niveles de medición contempla cuatro tipos:\n\n\n\n\nPara responder esta pregunta, exploremos algunos datos. En esta oportunidad trabajaremos con el Estudio Longitudinal Social de Chile, que es una encuesta desarrollada para analizar intertemporalmente la evolución del conflicto y cohesión en la sociedad chilena, basándose en modelos conceptuales descritos en la literatura nacional e internacional que abordan dichas materias. Se orienta a examinar los principales antecedentes, factores moderadores y mediadores, así como las principales consecuencias asociadas al desarrollo de distintas formas de conflicto y cohesión social en Chile. Su objetivo fundamental es constituirse en un insumo empírico para la comprensión de las creencias, actitudes y percepciones de los chilenos hacia las distintas dimensiones de la convivencia y el conflicto, y como éstas cambian a lo largo del tiempo.",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "resource/02-resource.html#importar-datos",
    "href": "resource/02-resource.html#importar-datos",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "En R es es posible importar y exportar datos que se encuentren en cualquier formato: ya sea .csv, .dta, .sav, .xlsx y, por supuesto, .rds y .RData. Sin embargo, para poder hacerlo, lo primero es instalar y cargar las librerías que contienen las funciones necesarias para la importación de distintos tipos de archivos.\nPero, ¿dónde están mis datos? Como hemos mencionado, nuestros datos los dejaremos en la carpeta input/data de nuestro proyecto. La base con la que trabajaremos en este práctico pueden encontrarla en la página oficial de ELSOC en este enlace.\nLuego de descargar la base de datos, asegurate de dejar el archivo .sav en la carpeta input/data de tu proyecto. Nota: Los datos tendrán distinto nombre según su formato (.sav, .csv, .dta, etc.).\nUna vez descargados los datos, procedemos a importar nuestra base de datos. Para ello, en nuestro script, dejamos indicado que a partir de la lectura de los datos con load(), crearemos un objeto que contiene la base de datos. Fijate en el Enviroment, ya que si lo anterior se logra, el objeto aparecerá allí.\nLa estructura general para importar datos es la siguiente:\nread_*(\"ruta_hacia_archivo/nombre_archivo.*\")\nSin embargo, por esta vez podemos descargar la base desde internet\n\nload(url((\"https://github.com/cursos-metodos-facso/metod1-MCS/raw/main/resource/files/ELSOC_W05_v1.0_R.RData\"))\n\n\n\n\n\n\n\nNota\n\n\n\nPara importar los datos en R debemos tener en consideración tres cosas:\n\nCómo se llaman los datos (en nuestro caso ELSOC_W05_v1.0_SPSS)\nEl formato de nuestros datos (en nuestro caso .sav)\nEl lugar de donde están alojados nuestros datos\n\n\n\n\n\nNo siempre nuestros datos vendrán en un único formato. Para ello, R cuenta con otras formas de leer distintos tipos de formatos.\n\nreadxl para archivos .xlsx\nhaven para archivos .sav\nreadr para .csv",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "resource/02-resource.html#explorar-datos",
    "href": "resource/02-resource.html#explorar-datos",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Lo más probable es que no trabajemos con todos los datos que importamos, por lo que debemos seleccionar aquellas variables con las que trabajaremos para nuestro problema de investigación (cualquiera sea).\nPero, para ello primero debemos explorar nuestros datos. En R, las funciones más comunes para explorar datos son:\n\nView(elsoc_2021) # Ver datos\nnames(elsoc_2021) # Nombre de columnas\ndim(elsoc_2021) # Dimensiones\n\nTenemos una base de datos con 2740 casos o filas y con 311 variables o columnas.",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "resource/02-resource.html#cargar-librerías",
    "href": "resource/02-resource.html#cargar-librerías",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "En R se trabaja a partir de paquetes (packages). ¿Qué son? De forma resumida, los paquetes son un conjunto de funciones o herramientas que pueden ser usadas en R. Los directorios de R donde se almacenan los paquetes se denominan librerías. La lógica es instalar paquetes y luego cargar (o llamar) las librerías cada vez que es necesario usarlas.\nUsualmente para cargar paquetes lo hacemos de la siguiente manera:\n\ninstall.packages(\"paquete\")\nlibrary(paquete)\n\nPero en esta ocasión utilizaremos un paquete llamado pacman, que facilita y agiliza la lectura (instalación y carga) de los paquetes a utilizar en R. De esta forma lo instalamos 1 única vez así:\n\ninstall.packages(\"pacman\")\nlibrary(pacman)\n\nLuego instalaremos y cargaremos los paquetes de R de la siguiente manera, volviendo más eficiente el procedimiento de carga de paquetes.\nEn este práctico utilizaremos seis paquetes\n\npacman: este facilita y agiliza la lectura de los paquetes a utilizar en R\ntidyverse: colección de paquetes, de la cual utilizaremos dplyr y haven\ndplyr: nos permite seleccionar variables de un set de datos\nhaven: cargar y exportar bases de datos en formatos .sav y .dta\ncar: para recodificar/agrupar valores de variables\n\n\npacman::p_load(dplyr, # para manipular datos\n               car # para recodificar datos\n               )\n\nComo se puede ver, antes de la función p_load hay un ::, esto se refiere a que se “fuerza” que esa función provenga de ese paquete (en este caso del paquete pacman).",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "resource/02-resource.html#tipos-de-datos-1",
    "href": "resource/02-resource.html#tipos-de-datos-1",
    "title": "Práctica 2. Conocimientos básicos de programación en R",
    "section": "",
    "text": "Los datos character están directamente asociados a las variables cualitativas (o categóricas). Generalmente suelen ser variables de texto abierto, como es el caso de la variable pais, que detalla el país de procedencia de la persona encuestada.\nPara conocer cuál es el tipo de variable en R, utilizamos el comando class(), y para detallar dentro de la base de datos cuál es la variable de interés, utilizamos el símbolo $ posterior a la base de datos:\n\nclass(elsoc_2021$comuna) # siempre es la misma estructura = base$variable\n\n[1] \"character\"\n\n\nSin embargo, estas variables no tienden a ser las mejores a la hora de presentar nuestros resultados. Como solución, tenemos las variables de tipo Factor.\n\n\n\nLas variables de tipo factor son ideales para trabajar con variables de tipo nominal u ordinal. Esto es así debido a que permiten establecer un orden entre las categorías de la variable, lo cual es fundamental si trabajamos, por ejemplo, con variables nominales como el sexo de los encuestados, o si trabajamos con variables ordinales como su ideología política.\n\nclass(elsoc_2021$m0_sexo)\n\n[1] \"factor\"\n\nclass(elsoc_2021$m38) #religion\n\n[1] \"factor\"\n\n\n\n\n\nLas variables de tipo numeric son variables de tipo númerica, las cuales pueden ser intervales o de razón. Así, por ejemplo, cuando trabajamos con variables de razón trabajamos con variables como el número de hijos o la edad (aunque sería extraño encuestar a alguien con 0 años).\n\nclass(elsoc_2021$m0_edad)\n\n[1] \"numeric\"",
    "crumbs": [
      "Practicos",
      "Práctico 2"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Metodología I\n        ",
    "section": "",
    "text": "Metodología I\n        \n        \n            Magister en Ciencias Sociales, mención Sociología de la Modernización\n        \n        \n            MCS7113 • Primer Semestre 2024Departamento de Sociología FACSOUniversidad de Chile\n        \n    \n    \n        \n    \n\n\n\n\n\n\nProfesores\n\n   Daniela Olivares\n   Departamento de Sociología N° 328\n   &lt;a href=“mailto:danielaolivarescollio@gmail.com”&gt;danielaolivarescollio@gmail.com\n\n\n\n   Kevin Carrasco\n   Departamento de Sociología N° 328\n   &lt;a href=“mailto:kevin.carrasco@ug.uchile.cl”&gt;kevin.carrasco@ug.uchile.cl\n   KevinCarrascoQ1\n\n\n\nInformación del curso\n\n   Viernes\n   Marzo 22–Julio 07, 2024\n   09:00-11:45 AM\n   Sala 44. Cuarto piso edificio antiguo FACSO\n\n\n\nContacto\nA través de correo"
  },
  {
    "objectID": "content/11-content.html#lecturas",
    "href": "content/11-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nPráctica en R"
  },
  {
    "objectID": "content/09-content.html#lecturas",
    "href": "content/09-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/07-content.html#lecturas",
    "href": "content/07-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nBrown (2015)The Common Factor Model and Exploratory Factor Analysis"
  },
  {
    "objectID": "content/05-content.html#lecturas",
    "href": "content/05-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science",
    "crumbs": [
      "Clases",
      "Sesiones",
      "05: Sesión 5"
    ]
  },
  {
    "objectID": "content/03-content.html#lecturas",
    "href": "content/03-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science",
    "crumbs": [
      "Clases",
      "Sesiones",
      "03: Sesión 3"
    ]
  },
  {
    "objectID": "content/01-content.html#lecturas",
    "href": "content/01-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science",
    "crumbs": [
      "Clases",
      "Sesiones",
      "01: Sesión 1"
    ]
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Assignments",
    "section": "",
    "text": "The main goals of this class are to help you design, critique, code, and run rigorous, valid, and feasible evaluations of public sector programs. Each type of assignment in this class is designed to help you achieve one or more of these goals."
  },
  {
    "objectID": "assignment/index.html#weekly-check-in",
    "href": "assignment/index.html#weekly-check-in",
    "title": "Assignments",
    "section": "Weekly check-in",
    "text": "Weekly check-in\nEvery week, after you finish working through the content, I want to hear about what you learned and what questions you still have. Because the content in thsi course is flipped, these questions are crucial for our weekly in-class discussions.\nTo encourage engagement with the course content—and to allow me to collect the class’s questions each week—you’ll need to fill out a short response on iCollege. This should be ≈150 words. That’s fairly short: there are ≈250 words on a typical double-spaced page in Microsoft Word (500 when single-spaced).\nThese check-ins are due by noon on the days we have class. This is so I can look through the responses and start structuring the discussion for the evening’s class.\nYou should answer these two questions each week:\n\nWhat were the three (3) most interesting or exciting things you learned from the session? Why?\nWhat were the three (3) muddiest or unclear things from the session this week? What are you still wondering about?\n\nYou can include more than three interesting or muddiest things, but you must include at least three. There should be six easily identifiable things in each check-in: three exciting things and three questions.\nI will grade these check-ins using a check system:\n\n✔+: (11.5 points (115%) in gradebook) Response shows phenomenal thought and engagement with the course content. I will not assign these often.\n✔: (10 points (100%) in gradebook) Response is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance.\n✔−: (5 points (50%) in gradebook) Response is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.\n\nNotice that is essentially a pass/fail or completion-based system. I’m not grading your writing ability, I’m not counting the exact number of words you’re writing, and I’m not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. I’m looking for thoughtful engagement, three interesting things, and three questions. That’s all. Do good work and you’ll get a ✓.\nYou will submit these check-ins via iCollege."
  },
  {
    "objectID": "assignment/index.html#problem-sets",
    "href": "assignment/index.html#problem-sets",
    "title": "Assignments",
    "section": "Problem sets",
    "text": "Problem sets\nTo practice writing R code, running inferential models, and thinking about causation, you will complete a series of problem sets.\nYou need to show that you made a good faith effort to work each question. I will not grade these in detail. The problem sets will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often.\n\nYou may (and should!) work together on the problem sets, but you must turn in your own answers. You cannot work in groups of more than four people, and you must note who participated in the group in your assignment."
  },
  {
    "objectID": "assignment/index.html#evaluation-assignments",
    "href": "assignment/index.html#evaluation-assignments",
    "title": "Assignments",
    "section": "Evaluation assignments",
    "text": "Evaluation assignments\nFor your final project, you will conduct a pre-registered evaluation of a social program using synthetic data. To (1) give you practice with the principles of program evaluation, research design, measurement, and causal diagrams, and (2) help you with the foundation of your final project, you will complete a set of four evaluation-related assignments.\nIdeally these will become major sections of your final project. However, there is no requirement that the programs you use in these assignments must be the same as the final project. If, through these assignments, you discover that your initially chosen program is too simple, too complex, too boring, etc., you can change at any time.\nThese assignments will be graded using a check system:\n\n✔+: (33 points (110%) in gradebook) Assignment is 100% completed. Every question was attempted and answered, and most answers are correct. Document is clean and easy to follow. Work is exceptional. I will not assign these often.\n✔: (30 points (100%) in gradebook) Assignment is 70–99% complete and most answers are correct. This is the expected level of performance.\n✔−: (15 points (50%) in gradebook) Assignment is less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not asisgn these often."
  },
  {
    "objectID": "assignment/index.html#exams",
    "href": "assignment/index.html#exams",
    "title": "Assignments",
    "section": "Exams",
    "text": "Exams\nThere will be two exams covering (1) program evaluation, design, and causation, and (2) the core statistical tools of program evaluation and causal inference.\nYou will take these exams online through iCollege. The exams will have a time limit, but you can use notes and readings and the Google. You must take the exams on your own though, and not talk to anyone about them."
  },
  {
    "objectID": "assignment/index.html#final-project",
    "href": "assignment/index.html#final-project",
    "title": "Assignments",
    "section": "Final project",
    "text": "Final project\nAt the end of the course, you will demonstrate your knowledge of program evaluation and causal inference by completing a final project.\nComplete details for the final project are here.\nThere is no final exam. This project is your final exam."
  },
  {
    "objectID": "content/02-content.html#lecturas",
    "href": "content/02-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science",
    "crumbs": [
      "Clases",
      "Sesiones",
      "02: Sesión 2"
    ]
  },
  {
    "objectID": "content/04-content.html#lecturas",
    "href": "content/04-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science",
    "crumbs": [
      "Clases",
      "Sesiones",
      "04: Sesión 4"
    ]
  },
  {
    "objectID": "content/06-content.html#lecturas",
    "href": "content/06-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas\nR for Data Science",
    "crumbs": [
      "Clases",
      "Sesiones",
      "06: Sesión 6"
    ]
  },
  {
    "objectID": "content/08-content.html#lecturas",
    "href": "content/08-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/10-content.html#lecturas",
    "href": "content/10-content.html#lecturas",
    "title": "Presentación",
    "section": "Lecturas",
    "text": "Lecturas"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Presentaciones, lecturas y actividades",
    "section": "",
    "text": "En esta sección se encuentran los documentos de presentación correspondientes a cada clase, lecturas y también actividades prácticas.",
    "crumbs": [
      "Clases",
      "Información general",
      "Presentaciones, lecturas y actividades"
    ]
  },
  {
    "objectID": "resource/01-resource.html",
    "href": "resource/01-resource.html",
    "title": "Práctica 1. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.\n\n\n\n\n\n\nAcceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.2.2 \n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto:\n\n\n\nRecomendaciones generales:\n\n\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())\n\n\n\n\n\nEn primer lugar vamos a abrir un archivo de R (script). Esto se puede hacer manualmente con File -&gt; new file -&gt; R script o directamente con ctrl + shift + N\nEsta es nuestra hoja de código, que utilizaremos para procesar bases de datos, modificar variables y crear tablas y gráficos.\n\n\nR puede ser una calculadora\n\n10 + 5 # ¿cuánto es 10 + 5?\n\n[1] 15\n\n\n\n10 * 5 # ¿cuánto es 10 * 5?\n\n[1] 50\n\n\nSe pueden crear objetos y asignarles valores\n\na &lt;- 28\nb &lt;- 8\n\na + b\n\n[1] 36\n\n\nO asignar operaciones a un objeto\n\nc &lt;- a + b\n\nAsí como también agregar texto\n\nd &lt;- \"hola\"\n\nd\n\n[1] \"hola\"\n\n\ny operaciones un poco más complejas\n\ne &lt;- b^2\n\ne + a * c\n\n[1] 1072\n\n\nSin embargo, la mayor parte del tiempo usamos funciones que ya existen en R\n\nsum(28,8)\n\n[1] 36\n\n\n\nround(10.14536) #aproximar\n\n[1] 10",
    "crumbs": [
      "Practicos",
      "Práctico 1"
    ]
  },
  {
    "objectID": "resource/01-resource.html#objetivos-de-la-práctica",
    "href": "resource/01-resource.html#objetivos-de-la-práctica",
    "title": "Práctica 1. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.",
    "crumbs": [
      "Practicos",
      "Práctico 1"
    ]
  },
  {
    "objectID": "resource/01-resource.html#r-y-rstudio",
    "href": "resource/01-resource.html#r-y-rstudio",
    "title": "Práctica 1. Aproximación inicial a R",
    "section": "",
    "text": "Acceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.2.2 \n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto:\n\n\n\nRecomendaciones generales:\n\n\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())",
    "crumbs": [
      "Practicos",
      "Práctico 1"
    ]
  },
  {
    "objectID": "resource/01-resource.html#primeros-pasos",
    "href": "resource/01-resource.html#primeros-pasos",
    "title": "Práctica 1. Aproximación inicial a R",
    "section": "",
    "text": "En primer lugar vamos a abrir un archivo de R (script). Esto se puede hacer manualmente con File -&gt; new file -&gt; R script o directamente con ctrl + shift + N\nEsta es nuestra hoja de código, que utilizaremos para procesar bases de datos, modificar variables y crear tablas y gráficos.\n\n\nR puede ser una calculadora\n\n10 + 5 # ¿cuánto es 10 + 5?\n\n[1] 15\n\n\n\n10 * 5 # ¿cuánto es 10 * 5?\n\n[1] 50\n\n\nSe pueden crear objetos y asignarles valores\n\na &lt;- 28\nb &lt;- 8\n\na + b\n\n[1] 36\n\n\nO asignar operaciones a un objeto\n\nc &lt;- a + b\n\nAsí como también agregar texto\n\nd &lt;- \"hola\"\n\nd\n\n[1] \"hola\"\n\n\ny operaciones un poco más complejas\n\ne &lt;- b^2\n\ne + a * c\n\n[1] 1072\n\n\nSin embargo, la mayor parte del tiempo usamos funciones que ya existen en R\n\nsum(28,8)\n\n[1] 36\n\n\n\nround(10.14536) #aproximar\n\n[1] 10",
    "crumbs": [
      "Practicos",
      "Práctico 1"
    ]
  },
  {
    "objectID": "resource/01-resource.html#flujo-de-trabajo-en-r",
    "href": "resource/01-resource.html#flujo-de-trabajo-en-r",
    "title": "Práctica 1. Aproximación inicial a R",
    "section": "2. Flujo de trabajo en R",
    "text": "2. Flujo de trabajo en R\nTal vez una de las dificultades más comunes o cotidianas del uso de R es el orden de trabajo, en donde tenemos cientos de archivos, scripts, gráficos, bases de datos u otros repartidos desordenadamente en nuestro computador. También se da mucho el caso en que, cuando queremos trabajar con alguien, tenemos que cambiar las rutas de los archivos, por ejemplo en dónde están las bases de datos, ya que nuestros ordenadores y usuarios se llaman y son escencialmente distintos.\n¿Cómo podemos sortear eso? Siguiendo un flujo de trabajo reproducible, autocontenido y ordenado. En este curso trabajaremos R con un flujo de trabajo reproducible, basado en el sistema IPO. El protocolor IPO es una plantilla/protocolo de estructura digital de carpetas que tiene por objetivo el organizar, procesar y documentar los datos de un proyecto de investigación con miras a la apertura de los datos en un repositorio público y de acceso libre. En concreto, el sistema IPO se propone abordar brevemente todo lo referente a los Datos, Métodos y Resultados.\n\n\nRproject\nUn Rproject es una herramienta de R que nos permite establecer un directorio de trabajo en una carpeta de nuestro computador. Al hacerlo, establecemos un espacio de trabajo que permite crear una estructura de carpetas donde guardar los documentos asociados al proyecto. De esta forma, creamos un conjunto de archivos autocontenidos en un solo lugar que nos permite organizar nuestro trabajo y facilitar la reproducibilidad. En las próximas sesiones estableceremos un protocolo de trabajo que permite organizar y armonizar el trabajo: el protocolo IPO.\nPara crear un Rproject:\n\nAbrir Rstudio\nSeleccionar Archivo -&gt; Nuevo proyecto\n\n\n\nSeleccionamos la opción de directorio existente\nSeleccionamos la carpeta donde descargamos nuestro repositorio de Github en el paso anterior\nApretamos el botón de crear proyecto\n\nY muchas de estas funciones que utilizamos en R están contenidas en librerías o paquetes (packages)\n\n\n1. Librerías principales (de R) a utilizar\nLa lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, guaguas, ggplot2)\n\nPara esta sesión las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nguaguas: Paquete que contiene los datos de nombres de guaguas (bebés) registrados en Chile entre 1920 y 2021 según el Registro Civil e Identificación\n\n\n\n2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nCargamos la base de datos desde el paquete (para otras bases de datos se deben importar de otra forma, esto es solo como ejemplo)\n\nbase &lt;- guaguas\n\nConocemos las dimensiones de la base de datos\n\ndim(base)\n\n[1] 858782      5\n\n\nSon 858782 casos y 5 variables. Los nombres de estas variables son:\n\nnames(base)\n\n[1] \"anio\"       \"nombre\"     \"sexo\"       \"n\"          \"proporcion\"\n\n\nY la base se ve así:\n\nhead(base)\n\n# A tibble: 6 × 5\n   anio nombre sexo      n proporcion\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1  1920 María  F      2130     0.104 \n2  1920 José   M       984     0.0483\n3  1920 Juan   M       636     0.0312\n4  1920 Luis   M       631     0.0310\n5  1920 Rosa   F       426     0.0209\n6  1920 Ana    F       340     0.0167\n\n\nAhora probemos algunas funciones para seguir explorando la base\n\ntable(base$sexo)\n\n\n     F      I      M \n531038    318 327426 \n\n\nPodemos ver la cantidad de nombres “F” (femenino), “M” (masculino) e “I” (indefinido) inscritos entre 1920 y 2021.\nPueden buscar sus nombres y probar, utilizamos la funcion filter del paquete dplyr\n\nfilter(base, nombre==\"Kevin\")\n\n# A tibble: 63 × 5\n    anio nombre sexo      n proporcion\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1  1931 Kevin  M         1 0.0000120 \n 2  1963 Kevin  M         1 0.0000035 \n 3  1964 Kevin  M         1 0.00000344\n 4  1967 Kevin  M         4 0.0000131 \n 5  1970 Kevin  M         6 0.0000210 \n 6  1971 Kevin  M         3 0.00000936\n 7  1972 Kevin  M         3 0.00000945\n 8  1973 Kevin  M         2 0.00000633\n 9  1974 Kevin  M         5 0.0000163 \n10  1976 Kevin  M         2 0.00000724\n# ℹ 53 more rows\n\n\nE incluso pueden ver la cantidad de personas con su nombre, en el mismo año que ustedes nacieron\n\nd &lt;- filter(base, nombre==\"Kevin\" & anio==1996)\nsum(d$n)\n\n[1] 1312\n\n\nAvanzando un poco más, podemos utilizar ggplot2 para hacer un gráfico de líneas que muestre la evolución en el tiempo\n\ndatos &lt;- filter(base, nombre==\"Kevin\")\nggplot(datos, aes(x = anio, y = n)) +\n  geom_line() + \n  labs(x = \"Año\", y = \"Número de personas\", title = \"Número de personas llamadas Kevin por año\")\n\n\n\n\n\n\n\n\n¿Qué puede explicar el peak de “Kevins” previo a los 2000?\nspoiler: link",
    "crumbs": [
      "Practicos",
      "Práctico 1"
    ]
  },
  {
    "objectID": "resource/01-resource.html#otro-ejemplo",
    "href": "resource/01-resource.html#otro-ejemplo",
    "title": "Práctica 1. Aproximación inicial a R",
    "section": "Otro ejemplo",
    "text": "Otro ejemplo\n\nguaguas %&gt;% \n  filter(nombre %in% c(\"Salvador\", \"Augusto\"), anio &gt;= 1960 & anio &lt;= 1979) %&gt;% \n  ggplot(aes(anio, n, color = nombre)) + \n  geom_line() +\n  labs(x = \"año\", y = \"total inscripciones\", color = \"nombre\", \n       title = \"Inscripciones de 'Salvador' y 'Augusto' entre 1960 - 1979\")",
    "crumbs": [
      "Practicos",
      "Práctico 1"
    ]
  },
  {
    "objectID": "resource/03-content.html",
    "href": "resource/03-content.html",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\n\nDe rutas, estructura de carpetas y otros \n\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado anteriormente. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos.\n\n\n\n\n\n\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de confianza en instituciones políticas y variables de caracterización sociodemográfica utilizando los datos de la encuesta Latinobarómetro .\n\n\n\n\nLatinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 20.000 entrevistas en 18 países de América Latina representando a más de 600 millones de habitantes\n“Los gobiernos latinoamericanos, que venían en declive junto con sus democracias desde inicios de la década de 2010, como reflejan los datos de Latinobarómetro, llegaron a fines de 2018 al annus horribilis con la caída de Nicaragua y Venezuela desde su condición de democracias para entrar en la categoría de autocracias y dictadura.\nDe los hiperpresidentes de la primera década del siglo con altos niveles de crecimiento en todos los países y altos niveles de aprobación, la región pasó en la segunda década a los subpresidentes, con una baja en aprobación de gobierno a la mitad, en menos de 10 años. Este rechazo al desempeño de las elites gobernantes, indica su fracaso a fines de 2019 en varios países de la región.” (Latinobarómetro, informe 2021, p. 7)\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Confianza en instituciones políticas, entendida como el grado en que los individuos confian en distintas instituciones políticas a nivel nacional, como el gobierno, la justicia, los partidos políticos, etc. Para ello, junto con variables de confianza, consideraremos también variables de estatus (educación), y variables de caracterización sociodemográfica (sexo y edad)."
  },
  {
    "objectID": "resource/03-content.html#objetivo-de-la-práctica",
    "href": "resource/03-content.html#objetivo-de-la-práctica",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "",
    "text": "El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.\n\n\n\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código.\nArchivo de código R: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: File &gt; New File &gt; R Script (o ctrl+shift+N), y para grabarlo File &gt; Save (o ctrl+s), y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) \nEl documento de código de preparación posee 5 partes, más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: cargar librerías a utilizar\nDatos: carga de datos\nSelección de variables a utilizar\nProcesamiento de variables: en este punto, por cada variable se realiza lo siguiente:\n\nDescriptivo básico\nRecodificación: datos perdidos y valores (en caso de ser necesario)\nEtiquetamiento: de variable y valores (en caso de ser necesario)\nOtros ajustes\n\nGeneración de base de datos preparada para el análisis.\n\n\nDe rutas, estructura de carpetas y otros \n\nEncontrando la ruta a carpeta local: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar “Propiedades”, en la ventana emergente debería aparecer la ruta hacia la carpeta en “Ubicación”. Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)\nSobre los “slashes” (\\ o /): en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser slash (/) o backslash (\\). En R por defecto se usa slash, pero en Windows backslash, por lo que si se usa Windows hay que reemplazarlos por backslash o también puede ser por un doble slash (//).\nPor temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).\nEstructura de carpetas: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo IPO, y que se adapta al flujo de trabajo presentado anteriormente. Básicamente son tres carpetas: input, procesamiento, output. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos.\n\n\n\n\n\n\n\nAl final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.\nEn el ejemplo vamos a procesar variables de confianza en instituciones políticas y variables de caracterización sociodemográfica utilizando los datos de la encuesta Latinobarómetro ."
  },
  {
    "objectID": "resource/03-content.html#antecedentes-de-los-datos-a-utilizar",
    "href": "resource/03-content.html#antecedentes-de-los-datos-a-utilizar",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "",
    "text": "Latinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 20.000 entrevistas en 18 países de América Latina representando a más de 600 millones de habitantes\n“Los gobiernos latinoamericanos, que venían en declive junto con sus democracias desde inicios de la década de 2010, como reflejan los datos de Latinobarómetro, llegaron a fines de 2018 al annus horribilis con la caída de Nicaragua y Venezuela desde su condición de democracias para entrar en la categoría de autocracias y dictadura.\nDe los hiperpresidentes de la primera década del siglo con altos niveles de crecimiento en todos los países y altos niveles de aprobación, la región pasó en la segunda década a los subpresidentes, con una baja en aprobación de gobierno a la mitad, en menos de 10 años. Este rechazo al desempeño de las elites gobernantes, indica su fracaso a fines de 2019 en varios países de la región.” (Latinobarómetro, informe 2021, p. 7)\nEl presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la Confianza en instituciones políticas, entendida como el grado en que los individuos confian en distintas instituciones políticas a nivel nacional, como el gobierno, la justicia, los partidos políticos, etc. Para ello, junto con variables de confianza, consideraremos también variables de estatus (educación), y variables de caracterización sociodemográfica (sexo y edad)."
  },
  {
    "objectID": "resource/03-content.html#librerias",
    "href": "resource/03-content.html#librerias",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "1. Librerías principales (de R) a utilizar en el análisis",
    "text": "1. Librerías principales (de R) a utilizar en el análisis\nComo sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer, haven)\n\nPara esta sesión vamos a utilizar Las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nsjmisc: descripción y exploración de base de datos\ncar: principalmente la función recode para recodificar/agrupar valores de variable\nstargazer: para tabla descriptiva"
  },
  {
    "objectID": "resource/03-content.html#cargar-base-de-datos",
    "href": "resource/03-content.html#cargar-base-de-datos",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nLas bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: latinobarometro2020.RData. Abrir bases de datos en otros formatos: Los formatos mas comunes en que se almacenan las bases de datos son .dta (Stata), .sav (Spss) y RData (R). Para abrir desde R utlilizamos la librería haven y sus funciones read_dta y read_sav según corresponda. Ej: datos &lt;- read_dta(\"base_casen.dta\"). Recordar antes instalar/cargar la librería: pacman::p_load(haven) \n\n#cargamos la base de datos desde internet\nload(url(\"https://github.com/Kevin-carrasco/metod1-MCS/raw/main/files/data/external_data/latinobarometro2020.RData\"))\n\no de manera local:\n\nlatinobarometro2020 &lt;- read_dta(\"../files/data/external_data/latinobarometro2020.dta\", encoding = \"UTF-8\")\n\nLa base de datos aparece como un objeto en nuestro espacio de trabajo, con el nombre original con la que fue guardada (latinobarometro2020):\n\nRealizamos un chequeo básico de la lectura de datos: nombres de las variables y tamaño de la base en términos de casos y variables (en este ejemplo, 20204, 408 ).\n\ndim(latinobarometro2020) # dimension de la base\n\n[1] 20204   408\n\n\nY si se quiere revisar en formato de planilla de datos:\n\nView(latinobarometro2020)"
  },
  {
    "objectID": "resource/03-content.html#selección-de-variables-a-utilizar",
    "href": "resource/03-content.html#selección-de-variables-a-utilizar",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "3. Selección de variables a utilizar",
    "text": "3. Selección de variables a utilizar\nEste paso consiste en crear un subset reducido de datos que contenga solo las variables de interés. Para ello:\n\nSe identifica el nombre de las variables que registran la información de preguntas o items del instrumento: esto aparece en el libro de códigos y/o en el cuestionario, o también se puede hacer buscando en la base de datos mediante alguna palabra clave asociada a la pregunta. Por ejemplo, si queremos buscar variables asociadas a educación, utilizamos la función find_var (de sjmisc, librería que cargamos en el paso 1), que nos entrega nombre de la variable en columna var.name. Por ejemplo, si buscamos alguna variable asociada al concepto Confianza:\n\n\nfind_var(data = latinobarometro2020,\"Confianza\")\n\n   col.nr   var.name\n1      36    p9stgbs\n2      41 P13STGBS_A\n3      42 P13STGBS_B\n4      43    p13st_c\n5      44    p13st_d\n6      45    p13st_e\n7      46    p13st_f\n8      47    p13st_g\n9      48    p13st_h\n10     49    p13st_i\n11     51    p15st_a\n12     52    p15st_b\n13     53    p15st_c\n14     54    p15st_d\n15     55    p15st_e\n16     56    p15st_f\n17     57    p15st_g\n18     58     p15n_h\n19     59     p15n_i\n20     60     p15n_j\n21     61     p15n_k\n22    154     p36n_a\n23    155     p36n_b\n24    160  P36STMB_A\n25    161  P36STMB_B\n26    162  P36STMB_C\n27    163  P36STMB_D\n                                                                          var.label\n1                                                   P9STGBS Confianza Interpersonal\n2                                       P13STGBS.A Confianza en las Fuerzas Armadas\n3                                  P13STGBS.B Confianza en la Policía / Carabineros\n4                                                   P13ST.C Confianza en la Iglesia\n5                                                  P13ST.D Confianza en el Congreso\n6                                                  P13ST.E Confianza en el Gobierno\n7                                            P13ST.F Confianza en el Poder Judicial\n8                                       P13ST.G Confianza en los Partidos Políticos\n9                           P13ST.H Confianza en: La institución Electoral del país\n10                                              P13ST.I Confianza en: El presidente\n11 P15ST.A Confianza en que las instituciones operan para mejorar nuestra calidad d\n12 P15ST.B Confianza en que las instituciones operan para mejorar nuestra calidad d\n13 P15ST.C Confianza en que las instituciones operan para mejorar nuestra calidad d\n14 P15ST.D Confianza en que las instituciones operan para mejorar nuestra calidad d\n15 P15ST.E Confianza en que las instituciones operan para mejorar nuestra calidad d\n16 P15ST.F Confianza en que las instituciones operan para mejorar nuestra calidad d\n17 P15ST.G Confianza en que las instituciones operan para mejorar nuestra calidad d\n18 P15N.H Confianza en que las instituciones operan para mejorar nuestra calidad de\n19 P15N.I Confianza en que las instituciones operan para mejorar nuestra calidad de\n20 P15N.J Confianza en que las instituciones operan para mejorar nuestra calidad de\n21 P15N.K Confianza en que las instituciones operan para mejorar nuestra calidad de\n22                        P36N.A Confianza en las Fuerzas Armadas de Estados Unidos\n23                                   P36N.B Confianza en las fuerzas Armadas Chinas\n24                    P36STMB.A Confianza en el FMI (Fondo Monetario Internacional)\n25               P36STMB.B Confianza en el BID (Banco Interamericano de Desarrollo)\n26            P36STMB.C Confianza en el CAF (Banco de Desarrollo de América Latina)\n27                                          P36STMB.D Confianza en el Banco Mundial\n\n\nNos informa que hay una serie de variables relacionadas con confianza interpersonal y con instituciones. Probemos con la variable p13st_e.\nMediante la función select de dplyr, seleccionamos cada una de nuestras variables de interés y creamos una nueva base con el nombre proc_data, donde “proc” hace referencia a base procesada:\n\nproc_data &lt;- latinobarometro2020 %&gt;% select(p13st_e, # Confianza en el Gobierno\n                          p13st_d, # Confianza en el congreso\n                          p13st_f, # Confianza en el Poder Judicial\n                          p13st_g, # Confianza en los partidos políticos\n                          reeduc_1,# nivel educacional\n                          sexo,# sexo\n                          edad,# edad\n                          idenpa) # pais \n\n# Comprobar\nnames(proc_data)\n\n[1] \"p13st_e\"  \"p13st_d\"  \"p13st_f\"  \"p13st_g\"  \"reeduc_1\" \"sexo\"     \"edad\"    \n[8] \"idenpa\"  \n\n\nMediante el comando get_label obtenemos el atributo label de las variables.\n\nsjlabelled::get_label(proc_data)\n\n                                                             p13st_e \n                                  \"P13ST.E Confianza en el Gobierno\" \n                                                             p13st_d \n                                  \"P13ST.D Confianza en el Congreso\" \n                                                             p13st_f \n                            \"P13ST.F Confianza en el Poder Judicial\" \n                                                             p13st_g \n                       \"P13ST.G Confianza en los Partidos Políticos\" \n                                                            reeduc_1 \n\"REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)\" \n                                                                sexo \n                                                         \"SEXO Sexo\" \n                                                                edad \n                                                         \"EDAD Edad\" \n                                                              idenpa \n                                    \"IDENPA Identificación del País\" \n\n\nPodemos ver que son largas o con códigos poco informativos, por lo tanto, es necesario cambiarlas por etiquetas más cortas y de fácil identificación.\nPara facilitar el análisis, vamos a filtrar la base de datos para quedarnos solo con los casos de Chile. Para esto utilizamos la función filter de dplyr. Si revisamos el libro de códigos, el identificador de Chile es 152\n\nproc_data &lt;- proc_data %&gt;% dplyr::filter(idenpa==152)"
  },
  {
    "objectID": "resource/03-content.html#procesamiento-de-variables",
    "href": "resource/03-content.html#procesamiento-de-variables",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "4. Procesamiento de variables",
    "text": "4. Procesamiento de variables\nPara el procesamiento de cada variable se seguirá el siguiente flujo de trabajo:\n\nDescriptivo general\nRecodificación: de casos perdidos y otros valores (en caso necesario)\nEtiquetado: cambio de nombres de variables y valores (en caso necesario)\nOtros ajustes\n\nY se recomienda también un descriptivo final para revisar que el procesamiento de cada variable está ok.\n\n4.1 Confianza en el Gobierno\nEn Latinobarómetro, lass variables que permiten medir la Confianza en instituciones políticas en Chile son las siguientes:\n\n[p13st_e]: “P13ST.E Confianza en el Gobierno” (1 = Mucha; 4 = Ninguna)\n[p13st_d]: “P13ST.D Confianza en el Congreso” (1 = Mucha; 4 = Ninguna)\n[p13st_f]: “P13ST.F Confianza en el Poder Judicial” (1 = Mucha; 4 = Ninguna)\n[p13st_g]: “P13ST.G Confianza en los Partidos Políticos” (1 = Mucha; 4 = Ninguna)\n\na. Descriptivo\nPara los descriptivos se utilizará la función frq, de la librería sjmisc:\n\nfrq(proc_data$p13st_e)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=3.27 sd=0.99\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n   -2 |   8 |  0.67 |    0.67 |   0.67\n   -1 |  11 |  0.92 |    0.92 |   1.58\n    1 |  23 |  1.92 |    1.92 |   3.50\n    2 | 176 | 14.67 |   14.67 |  18.17\n    3 | 358 | 29.83 |   29.83 |  48.00\n    4 | 624 | 52.00 |   52.00 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nEn esta variable vemos valores asociados a la opción “No contesta” (-2) y “No sabe” (-1), que corresponde definirlos como casos perdidos (en el caso de R, como casos NA). El resto de los valores y etiquetas se encuentran en un orden contraintuitivo (mayor valor indica menos confianza), así que en la recodificiación nos haremos cargo de los casos perdidos y de reordenar las categorías.\nb. Recodificación\nPara recodificar utilizamos la función recode, de la librería car\n\nproc_data$p13st_e &lt;- recode(proc_data$p13st_e, \"c(-2,-1)=NA\")\nproc_data$p13st_d &lt;- recode(proc_data$p13st_d, \"c(-2,-1)=NA\")\nproc_data$p13st_f &lt;- recode(proc_data$p13st_f, \"c(-2,-1)=NA\")\nproc_data$p13st_g &lt;- recode(proc_data$p13st_g, \"c(-2,-1)=NA\")\n\nnota: con la función set_na de la librería sjmisc podemos recodificar toda la base de datos con un solo código, pero debemos estar completamente segur-s de que estos valores no tienen otra categoría asociada en otra variable.\n\nproc_data &lt;- proc_data %&gt;% set_na(., na = c(-2, -1))\n\nPara reordenar las categorías volvemos a utilizar la función recode, de la librería car\n\nproc_data$p13st_e &lt;- recode(proc_data$p13st_e, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_d &lt;- recode(proc_data$p13st_d, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_f &lt;- recode(proc_data$p13st_f, \"1=3; 2=2; 3=1; 4=0\")\nproc_data$p13st_g &lt;- recode(proc_data$p13st_g, \"1=3; 2=2; 3=1; 4=0\")\n\nc - Etiquetado\nVamos a dar un nombre más sustantivo a las variables con la función rename, de la librería dplyr:\n\nproc_data &lt;- proc_data %&gt;% rename(\"conf_gob\"=p13st_e, # Confianza en el gobierno\n                                  \"conf_cong\"=p13st_d, # Confianza en el congreso\n                                  \"conf_jud\"=p13st_f, # Confianza en el Poder Judicial\n                                  \"conf_partpol\"=p13st_g) # Confianza en los partidos políticos \n\nAdemás de cambiar el nombre, queremos cambiar las etiquetas de las variables.\n\nproc_data$conf_gob &lt;- set_label(x = proc_data$conf_gob,label = \"Confianza: Gobierno\")\nget_label(proc_data$conf_gob)\n\n[1] \"Confianza: Gobierno\"\n\nproc_data$conf_cong  &lt;- set_label(x = proc_data$conf_cong, label = \"Confianza: Congreso\")\nget_label(proc_data$conf_cong)\n\n[1] \"Confianza: Congreso\"\n\nproc_data$conf_jud  &lt;- set_label(x = proc_data$conf_jud, label = \"Confianza: Poder judicial\")\nget_label(proc_data$conf_jud)\n\n[1] \"Confianza: Poder judicial\"\n\nproc_data$conf_partpol  &lt;- set_label(x = proc_data$conf_partpol, label = \"Confianza: Partidos politicos\")\nget_label(proc_data$conf_partpol)\n\n[1] \"Confianza: Partidos politicos\"\n\n\nd. Otros ajustes\nPara este caso vamos a crear una variable que sea la suma de los cuatro items de confianza.\n\nproc_data$conf_inst &lt;- (proc_data$conf_gob+proc_data$conf_cong+proc_data$conf_jud+proc_data$conf_partpol)\nsummary(proc_data$conf_inst)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    0.00    2.00    2.42    4.00   12.00      38 \n\n\n\nget_label(proc_data$conf_inst)\n\n[1] \"Confianza: Gobierno\"\n\n\nVemos que una etiqueta de la variable anterior.\n\nproc_data$conf_inst  &lt;- set_label(x = proc_data$conf_inst, label = \"Confianza en instituciones\")\n\nRevisión final\nNuevamente un descriptivo de cada variable para confirmar que el procesamiento está ok:\n\nfrq(proc_data$conf_gob)\n\nConfianza: Gobierno (x) &lt;numeric&gt; \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 624 | 52.00 |   52.84 |  52.84\n    1 | 358 | 29.83 |   30.31 |  83.15\n    2 | 176 | 14.67 |   14.90 |  98.05\n    3 |  23 |  1.92 |    1.95 | 100.00\n &lt;NA&gt; |  19 |  1.58 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$conf_cong)\n\nConfianza: Congreso (x) &lt;numeric&gt; \n# total N=1200 valid N=1178 mean=0.59 sd=0.71\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 628 | 52.33 |   53.31 |  53.31\n    1 | 408 | 34.00 |   34.63 |  87.95\n    2 | 134 | 11.17 |   11.38 |  99.32\n    3 |   8 |  0.67 |    0.68 | 100.00\n &lt;NA&gt; |  22 |  1.83 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$conf_inst)\n\nConfianza en instituciones (x) &lt;numeric&gt; \n# total N=1200 valid N=1162 mean=2.42 sd=2.49\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    0 | 397 | 33.08 |   34.17 |  34.17\n    1 | 141 | 11.75 |   12.13 |  46.30\n    2 | 130 | 10.83 |   11.19 |  57.49\n    3 | 111 |  9.25 |    9.55 |  67.04\n    4 | 169 | 14.08 |   14.54 |  81.58\n    5 |  71 |  5.92 |    6.11 |  87.69\n    6 |  41 |  3.42 |    3.53 |  91.22\n    7 |  41 |  3.42 |    3.53 |  94.75\n    8 |  44 |  3.67 |    3.79 |  98.54\n    9 |  11 |  0.92 |    0.95 |  99.48\n   10 |   4 |  0.33 |    0.34 |  99.83\n   11 |   1 |  0.08 |    0.09 |  99.91\n   12 |   1 |  0.08 |    0.09 | 100.00\n &lt;NA&gt; |  38 |  3.17 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nVemos que los valores (labels) de cada categoría de las primeras variables que recodificamos no se corresponden con el nuevo valor. Para re-etiquetar valores usamos la función set_labels, de la librería sjlabelled\n\nproc_data$conf_gob &lt;- set_labels(proc_data$conf_gob,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_cong &lt;- set_labels(proc_data$conf_cong,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_jud &lt;- set_labels(proc_data$conf_jud,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\nproc_data$conf_partpol &lt;- set_labels(proc_data$conf_partpol,\n            labels=c( \"Ninguna\"=0,\n                      \"Poca\"=1,\n                      \"Algo\"=2,\n                      \"Mucha\"=3))\n\ny volvemos a revisar\n\nfrq(proc_data$conf_gob)\n\nConfianza: Gobierno (x) &lt;numeric&gt; \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 624 | 52.00 |   52.84 |  52.84\n    1 |    Poca | 358 | 29.83 |   30.31 |  83.15\n    2 |    Algo | 176 | 14.67 |   14.90 |  98.05\n    3 |   Mucha |  23 |  1.92 |    1.95 | 100.00\n &lt;NA&gt; |    &lt;NA&gt; |  19 |  1.58 |    &lt;NA&gt; |   &lt;NA&gt;\n\nfrq(proc_data$conf_cong)\n\nConfianza: Congreso (x) &lt;numeric&gt; \n# total N=1200 valid N=1178 mean=0.59 sd=0.71\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 628 | 52.33 |   53.31 |  53.31\n    1 |    Poca | 408 | 34.00 |   34.63 |  87.95\n    2 |    Algo | 134 | 11.17 |   11.38 |  99.32\n    3 |   Mucha |   8 |  0.67 |    0.68 | 100.00\n &lt;NA&gt; |    &lt;NA&gt; |  22 |  1.83 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n4.2. Educación\n\n[reeduc_1] = REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)\n\na. Descriptivo\n\nfrq(proc_data$reeduc_1)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=5.05 sd=1.22\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |   8 |  0.67 |    0.67 |   0.67\n    2 |  53 |  4.42 |    4.42 |   5.08\n    3 |  36 |  3.00 |    3.00 |   8.08\n    4 | 161 | 13.42 |   13.42 |  21.50\n    5 | 643 | 53.58 |   53.58 |  75.08\n    6 | 109 |  9.08 |    9.08 |  84.17\n    7 | 190 | 15.83 |   15.83 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación\n\nVemos que no hay datos perdidos\nValores\n\nPara hacer más fácil el análisis, recodificamos en tres categorías (en este caso decisión arbitraria. Se debería tener una razón teórica para recodificar)\n1.  Analfabeto                                =   Educacion basica    =   1\n2   Básica incompleta                         =   Educacion basica    =   1\n3.  Básica completa                           =   Educacion basica    =   1\n4.  Secundaria, media, técnica incompleta     =   Educacion media     =   2\n5.  Secundaria, media, técnica completa       =   Educacion media     =   2\n6.  Superior incompleta                       =   Educacion superior  =   3\n7.  Superior completa                         =   Educacion superior  =   3\n\n\n# recodificacion usando funcion 'recode' de la libreria car\nproc_data$reeduc_1 &lt;- car::recode(proc_data$reeduc_1, \"c(1,2,3)=1; c(4,5)=2; c(6,7)=3\")\n\nComprobar con un nuevo descriptivo:\n\nfrq(proc_data$reeduc_1)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=2.17 sd=0.55\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |  97 |  8.08 |    8.08 |   8.08\n    2 | 804 | 67.00 |   67.00 |  75.08\n    3 | 299 | 24.92 |   24.92 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nSe observa que los valores coinciden con la recodificación (los casos se acumulan entre las categorías 1 y 3), pero las etiquetas ahora no coinciden; se soluciona en el siguiente paso.\nc. Etiquetado\nPara re-etiquetar valores usamos la función factor, de R base. Con esta función aprovechamos de transformar la variable educación en una variable categórica, que es lo que corresponde para una variable ordinal.\n\nproc_data$reeduc_1 &lt;- factor(proc_data$reeduc_1,\n                             labels = c(\"Educacion basica\", \"Educacion media\", \"Educacion superior\"),\n                             levels = c(1, 2, 3))\n\nLuego renombramos la variable con un nombre más sustantivo\n\nproc_data &lt;- rename(proc_data,\"educacion\"=reeduc_1)\n\nAdemás de cambiar el nombre, queremos cambiar la etiqueta de la variable.\n\nget_label(proc_data$educacion)\n\nNULL\n\nproc_data$educacion &lt;- set_label(x = proc_data$educacion,label = \"Educación\")\n\n\n\n\n4.3. Sexo\n\n[sexo] = SEXO Sexo\n\na. Descriptivo\n\nfrq(proc_data$sexo)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=1.54 sd=0.50\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 | 555 | 46.25 |   46.25 |  46.25\n    2 | 645 | 53.75 |   53.75 | 100.00\n &lt;NA&gt; |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación\nEn general esta variable no tiene problemas de casos perdidos ni de etiquetas, pero de todas maneras vamos a hacer un cambio de acuerdo a convenciones en análisis de datos, donde por lo general hombres tienen valor 0 y mujeres 1:\n\nproc_data$sexo &lt;- car::recode(proc_data$sexo, \"1=0;2=1\")\n\nc. Etiquetado\nY ahora cambiamos las etiquetas de acuerdo a la recodificación anterior:\n\nproc_data$sexo &lt;- factor(proc_data$sexo,\n            labels=c( \"Hombre\",\n                      \"Mujer\"),\n            levels=c(0,1))\n\nTambién queremos cambiar la etiqueta de la variable.\n\nget_label(proc_data$sexo)\n\nNULL\n\nproc_data$sexo &lt;- set_label(x = proc_data$sexo,label = \"Sexo\")\n\nRevisar con un nuevo descriptivo:\n\nfrq(proc_data$sexo)\n\nSexo (x) &lt;categorical&gt; \n# total N=1200 valid N=1200 mean=1.54 sd=0.50\n\nValue  |   N | Raw % | Valid % | Cum. %\n---------------------------------------\nHombre | 555 | 46.25 |   46.25 |  46.25\nMujer  | 645 | 53.75 |   53.75 | 100.00\n&lt;NA&gt;   |   0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\n4.4 Edad\n\n[edad] = EDAD Edad.\n\na. Descriptivo\n\nfrq(proc_data$edad)\n\nx &lt;numeric&gt; \n# total N=1200 valid N=1200 mean=44.49 sd=17.01\n\nValue |  N | Raw % | Valid % | Cum. %\n-------------------------------------\n   18 | 31 |  2.58 |    2.58 |   2.58\n   19 | 29 |  2.42 |    2.42 |   5.00\n   20 | 25 |  2.08 |    2.08 |   7.08\n   21 | 23 |  1.92 |    1.92 |   9.00\n   22 | 21 |  1.75 |    1.75 |  10.75\n   23 | 26 |  2.17 |    2.17 |  12.92\n   24 | 28 |  2.33 |    2.33 |  15.25\n   25 | 19 |  1.58 |    1.58 |  16.83\n   26 | 21 |  1.75 |    1.75 |  18.58\n   27 | 23 |  1.92 |    1.92 |  20.50\n   28 | 19 |  1.58 |    1.58 |  22.08\n   29 | 22 |  1.83 |    1.83 |  23.92\n   30 | 34 |  2.83 |    2.83 |  26.75\n   31 | 21 |  1.75 |    1.75 |  28.50\n   32 | 26 |  2.17 |    2.17 |  30.67\n   33 | 21 |  1.75 |    1.75 |  32.42\n   34 | 14 |  1.17 |    1.17 |  33.58\n   35 | 22 |  1.83 |    1.83 |  35.42\n   36 | 28 |  2.33 |    2.33 |  37.75\n   37 | 14 |  1.17 |    1.17 |  38.92\n   38 | 24 |  2.00 |    2.00 |  40.92\n   39 | 23 |  1.92 |    1.92 |  42.83\n   40 | 32 |  2.67 |    2.67 |  45.50\n   41 | 21 |  1.75 |    1.75 |  47.25\n   42 | 16 |  1.33 |    1.33 |  48.58\n   43 | 22 |  1.83 |    1.83 |  50.42\n   44 | 16 |  1.33 |    1.33 |  51.75\n   45 | 25 |  2.08 |    2.08 |  53.83\n   46 | 19 |  1.58 |    1.58 |  55.42\n   47 | 15 |  1.25 |    1.25 |  56.67\n   48 | 26 |  2.17 |    2.17 |  58.83\n   49 | 19 |  1.58 |    1.58 |  60.42\n   50 | 35 |  2.92 |    2.92 |  63.33\n   51 |  6 |  0.50 |    0.50 |  63.83\n   52 | 24 |  2.00 |    2.00 |  65.83\n   53 |  7 |  0.58 |    0.58 |  66.42\n   54 | 13 |  1.08 |    1.08 |  67.50\n   55 | 27 |  2.25 |    2.25 |  69.75\n   56 | 18 |  1.50 |    1.50 |  71.25\n   57 | 17 |  1.42 |    1.42 |  72.67\n   58 | 34 |  2.83 |    2.83 |  75.50\n   59 | 17 |  1.42 |    1.42 |  76.92\n   60 | 24 |  2.00 |    2.00 |  78.92\n   61 | 18 |  1.50 |    1.50 |  80.42\n   62 | 21 |  1.75 |    1.75 |  82.17\n   63 | 15 |  1.25 |    1.25 |  83.42\n   64 | 20 |  1.67 |    1.67 |  85.08\n   65 | 12 |  1.00 |    1.00 |  86.08\n   66 | 24 |  2.00 |    2.00 |  88.08\n   67 |  9 |  0.75 |    0.75 |  88.83\n   68 | 12 |  1.00 |    1.00 |  89.83\n   69 | 15 |  1.25 |    1.25 |  91.08\n   70 | 30 |  2.50 |    2.50 |  93.58\n   71 |  9 |  0.75 |    0.75 |  94.33\n   72 | 10 |  0.83 |    0.83 |  95.17\n   73 |  8 |  0.67 |    0.67 |  95.83\n   74 |  8 |  0.67 |    0.67 |  96.50\n   75 |  8 |  0.67 |    0.67 |  97.17\n   76 | 12 |  1.00 |    1.00 |  98.17\n   77 |  5 |  0.42 |    0.42 |  98.58\n   78 |  2 |  0.17 |    0.17 |  98.75\n   79 |  2 |  0.17 |    0.17 |  98.92\n   80 |  4 |  0.33 |    0.33 |  99.25\n   82 |  1 |  0.08 |    0.08 |  99.33\n   84 |  2 |  0.17 |    0.17 |  99.50\n   85 |  3 |  0.25 |    0.25 |  99.75\n   86 |  1 |  0.08 |    0.08 |  99.83\n   87 |  1 |  0.08 |    0.08 |  99.92\n   89 |  1 |  0.08 |    0.08 | 100.00\n &lt;NA&gt; |  0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nb. Recodificación: no es necesario en este caso\nc. Etiquetado\nCambio la etiqueta de la variable.\n\nget_label(proc_data$edad)\n\nNULL\n\nproc_data$edad &lt;- set_label(x = proc_data$edad,label = \"Edad\")"
  },
  {
    "objectID": "resource/03-content.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "href": "resource/03-content.html#generación-de-base-de-datos-procesada-para-el-análisis",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "5. Generación de base de datos procesada para el análisis",
    "text": "5. Generación de base de datos procesada para el análisis\nAntes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función stargazer (de la librería homónima)\nPrimero vamos a reformatear el objeto proc_data como base de datos (as.data.frame), paso necesario para que sea reconocido como tal por stargazer\n\nproc_data &lt;-as.data.frame(proc_data)\nstargazer(proc_data, type=\"text\")\n\n\n===========================================\nStatistic      N    Mean   St. Dev. Min Max\n-------------------------------------------\nconf_gob     1,181  0.660   0.800    0   3 \nconf_cong    1,178  0.594   0.714    0   3 \nconf_jud     1,186  0.717   0.789    0   3 \nconf_partpol 1,178  0.451   0.673    0   3 \nedad         1,200 44.491   17.008  18  89 \nidenpa       1,200 152.000  0.000   152 152\nconf_inst    1,162  2.420   2.489    0  12 \n-------------------------------------------\n\n\n\nSi se desea modificar las columnas que aparecen en la tabla se puede ocupar la opción summary.stat, donde se pueden especificar:\n\n“max” maximum\n“mean” mean\n“median” median\n“min” minimum\n“n” number of observations\n“p25” 25th percentile\n“p75” 75th percentile\n“sd” standard deviation\n\nPor ejemplo, si quiero una tabla solo con promedio, n, sd y p75: stargazer(data, type=\"text\", summary.stat = c(\"mean\", \"n\", \"sd\", \"p75\"))\n\n\nGuardar base de datos procesada: en carpeta local La ruta hacia su carpeta local si está trabajando en windows debería ser algo como “C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar\n\nEl comando para guardar es save:\n\nsave(proc_data,file = \"[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData\")\n\nEn este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:\n\nsave(proc_data,file = \"files/data/latinobarometro_proc.RData\")"
  },
  {
    "objectID": "resource/03-content.html#descriptivos-básicos-de-las-variables",
    "href": "resource/03-content.html#descriptivos-básicos-de-las-variables",
    "title": "Práctico 3. Operacionalización de variables",
    "section": "Descriptivos básicos de las variables",
    "text": "Descriptivos básicos de las variables\nPodemos conocer ciertas medidas de tendencia central utilizando algunas funciones de dplyr\n\nMedia por grupos\n\nproc_data %&gt;% dplyr::group_by(sexo) %&gt;% summarise(mean(conf_inst, na.rm=TRUE))\n\n# A tibble: 2 × 2\n  sexo   `mean(conf_inst, na.rm = TRUE)`\n  &lt;fct&gt;                            &lt;dbl&gt;\n1 Hombre                            2.48\n2 Mujer                             2.36\n\n\n\nproc_data %&gt;% dplyr::group_by(educacion) %&gt;% summarise(mean(conf_inst, na.rm=TRUE))\n\n# A tibble: 3 × 2\n  educacion          `mean(conf_inst, na.rm = TRUE)`\n  &lt;fct&gt;                                        &lt;dbl&gt;\n1 Educacion basica                              2.96\n2 Educacion media                               2.38\n3 Educacion superior                            2.36\n\n\n\n\nRepresentación\n\nlibrary(sjPlot)\nsjt.xtab(proc_data$educacion, proc_data$conf_inst, encoding = \"UTF-8\")\n\n\n \n Educación\n Confianza eninstituciones\n Total\n \n \n\n 0\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n 10\n 11\n 12\n \n \n \nEducacion basica\n30\n11\n6\n6\n12\n6\n4\n4\n7\n3\n0\n0\n1\n90 \n\n \n \nEducacion media\n268\n95\n83\n79\n121\n45\n24\n29\n28\n3\n4\n1\n0\n780 \n\n \n \nEducacion superior\n99\n35\n41\n26\n36\n20\n13\n8\n9\n5\n0\n0\n0\n292 \n\n \n \nTotal\n397\n141\n130\n111\n169\n71\n41\n41\n44\n11\n4\n1\n1\n1162 \n\nχ2=37.850 · df=24 · Cramer's V=0.128 · Fisher's p=0.127"
  },
  {
    "objectID": "resource/04-resource.html",
    "href": "resource/04-resource.html",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "",
    "text": "El objetivo de esta guía práctica es conocer las principales formas de realizar analísis estadísticos descriptivo en R, aplicando los concocimientos aprendidos durante el curso.\nEn detalle, aprenderemos:\n\nEstablecer un flujo de trabajo ordenado en un script (.R).\nAplicar análisis estadísticos descriptivos a variables según su nivel de medición\n\n\n\n\nEn esta práctica trabajeremos con los datos procesados que obtuvimos en la práctica anterior a partir de los datos del Estudio Latinobarómetro.\n\n\n\nPor temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación: corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias a los datos para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona con análisis estadísticos, en este caso descriptivos, asociados a las preguntas e hipótesis de investigación.\n\nLos procesos de preparación y análisis vinculados tanto a datos y resultados se presentan en el siguiente esquema:\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código respectivo.\nEn esta guía nos centraremos en el análisis de datos con R. El documento de código de análisis tiene, por lo menos, 4 partes más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: instalar/cargar librerías a utilizar\nDatos: carga de datos\nExplorar: explorar datos\nAnálisis: analizar datos y realizar estimaciones",
    "crumbs": [
      "Practicos",
      "Práctico 4"
    ]
  },
  {
    "objectID": "resource/04-resource.html#objetivo-de-la-práctica",
    "href": "resource/04-resource.html#objetivo-de-la-práctica",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "",
    "text": "El objetivo de esta guía práctica es conocer las principales formas de realizar analísis estadísticos descriptivo en R, aplicando los concocimientos aprendidos durante el curso.\nEn detalle, aprenderemos:\n\nEstablecer un flujo de trabajo ordenado en un script (.R).\nAplicar análisis estadísticos descriptivos a variables según su nivel de medición",
    "crumbs": [
      "Practicos",
      "Práctico 4"
    ]
  },
  {
    "objectID": "resource/04-resource.html#recursos-de-la-práctica",
    "href": "resource/04-resource.html#recursos-de-la-práctica",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "",
    "text": "En esta práctica trabajeremos con los datos procesados que obtuvimos en la práctica anterior a partir de los datos del Estudio Latinobarómetro.",
    "crumbs": [
      "Practicos",
      "Práctico 4"
    ]
  },
  {
    "objectID": "resource/04-resource.html#flujo-de-trabajo-reproducible",
    "href": "resource/04-resource.html#flujo-de-trabajo-reproducible",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "",
    "text": "Por temas de orden y reproducibilidad, en este curso vamos a separar en dos momentos el trabajo con datos, y dos archivos de código correspondientes:\n\nPreparación: corresponde a lo que se conoce generalmente como “limpieza”, es decir, realizar las modificaciones necesarias a los datos para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).\nAnálisis: se relaciona con análisis estadísticos, en este caso descriptivos, asociados a las preguntas e hipótesis de investigación.\n\nLos procesos de preparación y análisis vinculados tanto a datos y resultados se presentan en el siguiente esquema:\n\nTanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un archivo de código respectivo.\nEn esta guía nos centraremos en el análisis de datos con R. El documento de código de análisis tiene, por lo menos, 4 partes más una sección de identificación inicial:\n\nIdentificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento\nLibrerías: instalar/cargar librerías a utilizar\nDatos: carga de datos\nExplorar: explorar datos\nAnálisis: analizar datos y realizar estimaciones",
    "crumbs": [
      "Practicos",
      "Práctico 4"
    ]
  },
  {
    "objectID": "resource/04-resource.html#cargar-librerías",
    "href": "resource/04-resource.html#cargar-librerías",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "1 Cargar librerías",
    "text": "1 Cargar librerías\nEste paso ya lo realizamos y cargamos todas las librerías necesarias. Pero si, al trabajar los distintos script lo hacemos en sesiones diferentes, debemos volver a cargar las librerías.\n\ninstall.packages(\"pacman\") #para instalar\nlibrary(pacman) # para llamar/cargar\n\nEn este práctico utilizaremos los siguientes paquetes:\n\npacman: este facilita y agiliza la lectura de los paquetes a utilizar en R\ntidyverse: colección de paquetes, de la cual utilizaremos dplyr y haven\ndplyr: nos permite seleccionar variables de un set de datos\npsych: para analizar descriptivamente datos\nsjmisc: para analizar descriptivamente datos\nsjPlot: para tablas cruzadas o de contingencia\n\n\npacman::p_load(tidyverse, # colección de paquetes para manipulación de datos\n               dplyr, # para manipular datos\n               psych, # para analizar datos\n               sjmisc, # para analizar datos\n               sjPlot) # para tablas de contingencia\n\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo",
    "crumbs": [
      "Practicos",
      "Práctico 4"
    ]
  },
  {
    "objectID": "resource/04-resource.html#importar-datos",
    "href": "resource/04-resource.html#importar-datos",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "2 Importar datos",
    "text": "2 Importar datos\nUsamos los datos creados en el procesamiento que se encuentran guardados en la carpeta output.\n\nload(\"input/data/proc/data_proc.Rdata\")\n\no desde internet si no completamos el práctico anterior:\n\nload(url(\"https://github.com/cursos-metodos-facso/metod1-MCS/raw/main/files/data/latinobarometro_proc.RData\"))",
    "crumbs": [
      "Practicos",
      "Práctico 4"
    ]
  },
  {
    "objectID": "resource/04-resource.html#explorar-datos",
    "href": "resource/04-resource.html#explorar-datos",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "3 Explorar datos",
    "text": "3 Explorar datos\n\nView(proc_data) # Ver datos\nnames(proc_data) # Nombre de columnas\ndim(proc_data) # Dimensiones\nstr(proc_data) # Estructura de los datos (las clases y categorias de repuesta)\n\nEn este caso, nuestra base de datos procesada tiene 1200 casos y 9 variables.",
    "crumbs": [
      "Practicos",
      "Práctico 4"
    ]
  },
  {
    "objectID": "resource/04-resource.html#análisis",
    "href": "resource/04-resource.html#análisis",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "4 Análisis",
    "text": "4 Análisis\n\n4.1 Estadísticos descriptivos para variables categóricas\nCuando tenemos variables catégoricas, sean nominales u ordinales, podemos utilizar tablas de frecuencias. Recordemos que las frecuencias es una manera ordenar datos según el valor alcanzado en la distribución de una variable.\n\n4.1.1 Frecuencias\n\na) Absolutas y relativas\nPara las variables nominales podemos usar tablas de frecuencias absolutas y relativas, y con ellas conocer la moda, es dedir, el valor con mayor cantidad de observaciones. Para ello, una manera sencilla de hacerlo es mediante la función table de R.\n\ntable(proc_data$sexo)\n\n\nHombre  Mujer \n   555    645 \n\ntable(proc_data$educacion)\n\n\n  Educacion basica    Educacion media Educacion superior \n                97                804                299 \n\ntable(proc_data$conf_gob)\n\n\n  0   1   2   3 \n624 358 176  23 \n\n\nLo anterior nos entrega la frecuencia absoluta de las variables. Con ello, podemos observar que, en cuanto la preferencias entre autoritarismo y democracia, la mayoría de nuestros casos se concentran en “La democracia es preferible a cualquier otra forma de gobierno”. Para conocer la frecuencia relativa o porcentual de estas podemos utilizar el comando prop.table.\n\n(freq_table1 &lt;-table(proc_data$conf_gob))\n\n\n  0   1   2   3 \n624 358 176  23 \n\nprop.table(freq_table1)*100 \n\n\n        0         1         2         3 \n52.836579 30.313294 14.902625  1.947502 \n\n\nAsí, podemos sostener que un 52,8% de los casos no confían nada en el congreso.\n\n\nb) Acumuladas\nMientras que si trabajamos con variables ordinales, podemos usar también la frecuencia acumulada:\n\n(freq_table2 &lt;- table(proc_data$conf_gob))\n\n\n  0   1   2   3 \n624 358 176  23 \n\n(freq_table3 &lt;- prop.table(freq_table2)*100)\n\n\n        0         1         2         3 \n52.836579 30.313294 14.902625  1.947502 \n\ncumsum(freq_table3)\n\n        0         1         2         3 \n 52.83658  83.14987  98.05250 100.00000 \n\n\nA partir de este estadístico, podemos ver que un 83,1% de los casos se ubican debajo de la categoría ‘1’ de confianza, lo cual en términos sustantivos señala que un 83,1% de las observaciones confían nada o poco en el congreso.\nTambién podemos unir todas estas frecuencias en una sola tabla:\n\ntbl3 &lt;- table(proc_data$conf_gob)\ncbind(Freq=tbl3, relat = prop.table(tbl3)*100, Cum = cumsum(prop.table(tbl3)*100))\n\n  Freq     relat       Cum\n0  624 52.836579  52.83658\n1  358 30.313294  83.14987\n2  176 14.902625  98.05250\n3   23  1.947502 100.00000\n\n\nOtra manera de calcular frecuencias (absolutas, relativas y acumuladas) en R, es mediante la función frq() del paquete sjmisc, el cual entrega todo lo anterior con un solo comando.\n\nsjmisc::frq(proc_data$conf_gob)\n\nConfianza: Gobierno (x) &lt;numeric&gt; \n# total N=1200 valid N=1181 mean=0.66 sd=0.80\n\nValue |   Label |   N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    0 | Ninguna | 624 | 52.00 |   52.84 |  52.84\n    1 |    Poca | 358 | 29.83 |   30.31 |  83.15\n    2 |    Algo | 176 | 14.67 |   14.90 |  98.05\n    3 |   Mucha |  23 |  1.92 |    1.95 | 100.00\n &lt;NA&gt; |    &lt;NA&gt; |  19 |  1.58 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\n\n\n\n4.1.2 Tablas de contingencia\nTambién podemos cruzar dos variables mediante las llamadas tablas de contingencia o tablas cruzadas. Además de conocer la frecuencia absoluta en cada casilla, podemos también conocer la proporción o frecuencia relativa para cada casilla y el total de la filas y columnas.\n\nsjt.xtab(proc_data$sexo, proc_data$conf_gob)\n\n\n \n Sexo\n Confianza: Gobierno\n Total\n \n \n\n Ninguna\n Poca\n Algo\n Mucha\n \n \n \nHombre\n280\n167\n93\n9\n549 \n\n \n \nMujer\n344\n191\n83\n14\n632 \n\n \n \nTotal\n624\n358\n176\n23\n1181 \n\nχ2=4.015 · df=3 · Cramer's V=0.058 · p=0.260 \n\n \n\n\nsjt.xtab(proc_data$sexo, proc_data$conf_gob,\n         show.row.prc = TRUE, #solo fila\n         show.summary = FALSE) \n\n\n\n\n\n\n\n\n\n\n\n\n\nSexo\nConfianza: Gobierno\nTotal\n\n\nNinguna\nPoca\nAlgo\nMucha\n\n\nHombre\n280\n51 %\n167\n30.4 %\n93\n16.9 %\n9\n1.6 %\n549\n100 %\n\n\nMujer\n344\n54.4 %\n191\n30.2 %\n83\n13.1 %\n14\n2.2 %\n632\n100 %\n\n\nTotal\n624\n52.8 %\n358\n30.3 %\n176\n14.9 %\n23\n1.9 %\n1181\n100 %\n\n\n\n\n\nsjt.xtab(proc_data$sexo, proc_data$conf_gob,\n         show.col.prc=TRUE, #solo columna\n         show.summary=FALSE) \n\n\n\n\n\n\n\n\n\n\n\n\n\nSexo\nConfianza: Gobierno\nTotal\n\n\nNinguna\nPoca\nAlgo\nMucha\n\n\nHombre\n280\n44.9 %\n167\n46.6 %\n93\n52.8 %\n9\n39.1 %\n549\n46.5 %\n\n\nMujer\n344\n55.1 %\n191\n53.4 %\n83\n47.2 %\n14\n60.9 %\n632\n53.5 %\n\n\nTotal\n624\n100 %\n358\n100 %\n176\n100 %\n23\n100 %\n1181\n100 %\n\n\n\n\n\nsjt.xtab(proc_data$sexo, proc_data$conf_gob,\n         show.cell.prc = TRUE, #fila y columna\n         show.summary = FALSE) \n\n\n\n\n\n\n\n\n\n\n\n\n\nSexo\nConfianza: Gobierno\nTotal\n\n\nNinguna\nPoca\nAlgo\nMucha\n\n\nHombre\n280\n23.7 %\n167\n14.1 %\n93\n7.9 %\n9\n0.8 %\n549\n46.5 %\n\n\nMujer\n344\n29.1 %\n191\n16.2 %\n83\n7 %\n14\n1.2 %\n632\n53.5 %\n\n\nTotal\n624\n52.8 %\n358\n30.3 %\n176\n14.9 %\n23\n1.9 %\n1181\n100 %\n\n\n\n\n\n\n\n\n\n4.2 Estadísticos descriptivos para variables númericas\nA diferencia de las variables categóricas, a las variables numéricas (intervalaras o de razón) les podemos calcular una mayor cantidad de estadísticos descriptivos, como medidas de tendencia central, dispersión o posición.\nComo ya vimos en clases:\n\ndentro de las medidas de tendencia central que podemos calcular para describir a una variable numérica encontramos: media, mediana;\ndentro de las medidas de dispersión podemos señalar: desviación estándar, varianza, coeficiente de variación, rango;\ndentro de las medidas de posición podemos mencionar: mediana, q1, q3, mínimo, máximo.\n\n\n\n\n\n\n\nTip\n\n\n\nRecordemos que:\n\nlas medidas de tendencia central expresan el valor alrededor del cual se sitúa la mayor cantidad de los datos. Estamos mirando hacia el centro de los datos.\nlas medidas de dispersión buscan cuantificar lo próximo o alejado que están los valores de una variable de un punto central. Estamos mirando la dispersión de los datos respecto a su centro.\nlas medidas de posición señalan en qué “lugar” de una distribución se encuentra un dato o un conjunto de datos en relación al resto.\n\n\n\nEn R existen distintas formas de calcular este tipo de estadísticos descriptivos.\n\na) Con summary\nPodemos obtener rapidamente un resumen de los datos con la funcion summary de R\n\nsummary(proc_data$conf_inst)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    0.00    2.00    2.42    4.00   12.00      38 \n\nsummary(proc_data$edad)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   30.00   43.00   44.49   58.00   89.00 \n\n\nCon esto podemos ver que el promedio o media aritmética de la confianza en instituciones de los/as entrevistados de nuestra base es de 2.42, mientras que la mediana es de 2.\nAsimismo, observamos que el 25% de la parte inferior de nuestros datos confía nada en las instituciones, en tanto que el 25% superior de la distribución de los datos confía ‘4’ en las instituciones.\nSin embargo, aunque es informativo, no nos entrega toda la información que quisiéramos.\n\n\nb) Con psych\n\npsych::describe(proc_data$conf_inst,\n                quant = c(.25,.75),\n                IQR = T)\n\n   vars    n mean   sd median trimmed  mad min max range skew kurtosis   se IQR\nX1    1 1162 2.42 2.49      2    2.07 2.97   0  12    12 0.88    -0.01 0.07   4\n   Q0.25 Q0.75\nX1     0     4\n\n\nUsando la funcion describe del paquete psych podemos obtener mayor cantidad de estadísticos, además de especificarle otros adicionales.\nAsí, por ejemplo, ahora además de la media aritmética y la media, también tenemos la media recortada.\nPero lo más relevante es que nos aporta estadísticos de la dispersión de los datos, como la desviación estándar que nos indica que el grado de dispersión de mis datos respecto al promedio de confianza es de 2,49. Con esto, podemos obtener también la varianza de los datos, que corresponde a la DS al cuadrado.\nAdemás de eso, nos aporta el rango (el valor máximo menos el mínimo), y el recorrido interquartilico (Q3 - Q1) que nos indica el grado de dispersión del 50% de los datos.\nCon esta información, podemos calcular los demás estadísticos que necesitamos “a mano”, es decir, computándolos directamente en R como una calculadora.\n\n\nc) Con summarise de dplyr\nOtra manera de obtener todos los estadísticos que necesitamos es utilizando dplyr. Aquí, le especificamos lo que requerimos, pero debemos saber bien cómo calcular tales medidas:\n\nproc_data %&gt;% na.omit() %&gt;% \n  summarise(media = mean(conf_inst),\n            mediana = median(conf_inst),\n            q1 = quantile(conf_inst, probs = .25),\n            q2 = quantile(conf_inst, probs = .75),\n            rango = max(conf_inst) - min(conf_inst),\n            desviacion_estandar = sd(conf_inst),\n            varianza = var(conf_inst),\n            coef_variacion = sd(conf_inst)/mean(conf_inst))\n\n     media mediana q1 q2 rango desviacion_estandar varianza coef_variacion\n1 2.419966       2  0  4    12            2.488744 6.193847       1.028421\n\n\nAhora, conocemos no solo los estádisticos anteriores, sino que también obtuvimos la varianza y el coeficiente de variación.",
    "crumbs": [
      "Practicos",
      "Práctico 4"
    ]
  },
  {
    "objectID": "resource/04-resource.html#resumen",
    "href": "resource/04-resource.html#resumen",
    "title": "Práctica 4 Correlación y Regresión",
    "section": "Resumen",
    "text": "Resumen\nHoy aprendimos a procesar datos en R. En detalle, vimos:\n\nCómo establecer un flujo de trabajo de procesamiento y análisis de datos en R.\nRealizar análisis descriptivos en R según el nivel de medición de las variables",
    "crumbs": [
      "Practicos",
      "Práctico 4"
    ]
  },
  {
    "objectID": "resource/06-resource.html#librerías",
    "href": "resource/06-resource.html#librerías",
    "title": "Práctica 6 Visualización de datos",
    "section": "1. Librerías",
    "text": "1. Librerías\n\npacman::p_load(sjlabelled,\n               dplyr, #Manipulacion de datos\n              stargazer, #Tablas\n              sjmisc, # Tablas\n              summarytools, # Tablas\n              kableExtra, #Tablas\n              sjPlot, #Tablas y gráficos\n              sessioninfo, # Información de la sesión de trabajo\n              ggplot2) # Para la mayoría de los gráficos",
    "crumbs": [
      "Practicos",
      "Práctico 6"
    ]
  },
  {
    "objectID": "resource/06-resource.html#cargar-base-de-datos",
    "href": "resource/06-resource.html#cargar-base-de-datos",
    "title": "Práctica 6 Visualización de datos",
    "section": "2. Cargar base de datos",
    "text": "2. Cargar base de datos\nVamos a cargar la base de datos latinobarometro_proc.Rdata, que generamos durante la práctica anterior. Se puede llamar desde el directorio en que se guardó anteriormente dando la ruta completa:\n\nload(\"ruta-hacia-carpeta-local/latinobarometro_proc.RData\") #Cargar base de datos\n\nO también para esta práctica la podemos llamar directamente desde nuestro sitio web:\n\nload(url(\"https://github.com/Kevin-carrasco/R-data-analisis/raw/main/files/data/latinobarometro_total.RData\")) #Cargar base de datos\n\n\nExploración inicial general de la base de datos\n\n\nnames(proc_data) # Muestra los nombres de las variables de la base de datos\n\n[1] \"conf_gob\"     \"conf_cong\"    \"conf_jud\"     \"conf_partpol\" \"educacion\"   \n[6] \"sexo\"         \"edad\"         \"idenpa\"       \"conf_inst\"   \n\ndim(proc_data) # Dimensiones\n\n[1] 20204     9\n\n\nEn el caso de esta base, 20204 casos y 9 variables\nRecordando el contenido de cada variable preparada en la práctica anterior:\n\n[conf_gob] = Confianza en el gobierno.\n[conf_cong] = Confianza en el congreso.\n[conf_jud] = Confianza en el poder judicial.\n[conf_partpol] = Confianza en los partidos políticos.\n[conf_inst] = Indice sumativo de confianza en instituciones políticas.\n[educacion] = Nivel educacional(1 = Educacion básica, 2 = Educacion media, 3 = superior)\n[sexo] = Sexo (O = Hombre; 1 = Mujer)\n[edad] = ¿Cuáles su edad?",
    "crumbs": [
      "Practicos",
      "Práctico 6"
    ]
  },
  {
    "objectID": "resource/06-resource.html#descripción-de-variables",
    "href": "resource/06-resource.html#descripción-de-variables",
    "title": "Práctica 6 Visualización de datos",
    "section": "3. Descripción de variables",
    "text": "3. Descripción de variables\nLos resultados referidos a descripción de variables se presentan en dos momentos del reporte de investigación:\n\nen la sección de metodología, cuando se presentan las variables del estudio en una tabla descriptiva de variables.\nen la sección de análisis, que en general comienza con una exploración de asociaciones entre variables, también conocido como análisis descriptivo.\n\n\n3.1 Tabla descriptiva de variables para sección metodológica\nA continuación se presentan dos opciones de generar esta tabla descriptiva de variables con distintas librerías de R.\na. Tabla descriptiva con stargazerstargazer\nLa función stargazer (de la librería del mismo nombre) permitirá mostrar los principales estadísticos descriptivos univariados de las variables: medidas de tendencia central (media), de dispersión (desviación estándar) y posición (mínimo, máximo, percentiles).\n\nstargazer(proc_data,type = \"text\")\n\n\n============================================\nStatistic      N     Mean   St. Dev. Min Max\n--------------------------------------------\nconf_gob     19,748  0.967   1.001    0   3 \nconf_cong    19,382  0.819   0.876    0   3 \nconf_jud     19,467  0.940   0.923    0   3 \nconf_partpol 19,653  0.603   0.798    0   3 \nedad         20,204 40.999   16.538  16  100\nidenpa       20,204 365.378 260.493  32  862\nconf_inst    18,768  3.303   2.851    0  12 \n--------------------------------------------\n\n\nAlgunas observaciones sobre esta tabla:\n\nLa opción type=\"text\" permite que podamos ver los resultados directamente en la consola, de manera bastante rudimentaria. Con otras opciones que veremos más adelante se puede estilizar para su publicación.\nUna distinción relevante a considerar cuando se describen variables es si estas son categóricas o continuas. La definición de si una variables es tratada como categórica o continua es algo que hace el/la autor/a del reporte, sin embargo hay variables nominales como sexo que claramente corresponden a categóricas, y por lo tanto no corresponde hacer un promedio entre ambas. Sin embargo, como esta variable está codificada 0 (hombre) y 1 (mujer), en este caso lo que indica el valor de la columna promedio (Mean=0.537) es la proporción de mujeres vs hombres. En otras palabras, hay un 54% de mujeres y 46% de hombres en la muestra.\n\nb. Tablas descriptivas con descr, librería sjmisc sjmisc::descr\nLa opción básica de descr es la siguiente:\n\nsjmisc::descr(proc_data)\n\n\n## Basic descriptive statistics\n\n          var        type                         label     n NA.prc   mean\n     conf_gob     numeric           Confianza: Gobierno 19748   2.26   0.97\n    conf_cong     numeric           Confianza: Congreso 19382   4.07   0.82\n     conf_jud     numeric     Confianza: Poder judicial 19467   3.65   0.94\n conf_partpol     numeric Confianza: Partidos politicos 19653   2.73   0.60\n    educacion categorical                     Educación 20201   0.01   1.88\n         sexo categorical                          Sexo 20204   0.00   1.52\n         edad     numeric                          Edad 20204   0.00  41.00\n       idenpa     numeric                        idenpa 20204   0.00 365.38\n    conf_inst     numeric    Confianza en instituciones 18768   7.11   3.30\n     sd   se  md trimmed        range iqr  skew\n   1.00 0.01   1    0.83      3 (0-3)   2  0.70\n   0.88 0.01   1    0.71      3 (0-3)   1  0.82\n   0.92 0.01   1    0.84      3 (0-3)   2  0.65\n   0.80 0.01   0    0.47      3 (0-3)   1  1.19\n   0.76 0.01   2    1.85      2 (1-3)   1  0.20\n   0.50 0.00   2    1.53      1 (1-2)   1 -0.09\n  16.54 0.12  39   39.90  84 (16-100)  28  0.49\n 260.49 1.83 222  343.35 830 (32-862) 421  0.56\n   2.85 0.02   3    2.99    12 (0-12)   4  0.75\n\n\nEn este caso utilizamos la forma librería::función (sjmisc::descr), ya que la función descr también existe en otras librerías y así nos aseguramos que la función utilizada es de esa librería específica.\nSeleccionamos algunas columnas específicas con información más relevante con la opción show. Además, agregamos la función kable para obtener una tabla que luego sea fácilmente publicable en distintos formatos (a profundizar en ejercicios posteriores):\n\nsjmisc::descr(proc_data,\n      show = c(\"label\",\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\"))%&gt;%\n      kable(.,\"markdown\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\n2\nconf_gob\nConfianza: Gobierno\n19748\n2.2569788\n0.9668321\n1.0013733\n3 (0-3)\n\n\n1\nconf_cong\nConfianza: Congreso\n19382\n4.0685013\n0.8193169\n0.8761394\n3 (0-3)\n\n\n4\nconf_jud\nConfianza: Poder judicial\n19467\n3.6477925\n0.9404633\n0.9232323\n3 (0-3)\n\n\n5\nconf_partpol\nConfianza: Partidos politicos\n19653\n2.7271827\n0.6032158\n0.7975983\n3 (0-3)\n\n\n7\neducacion\nEducación\n20201\n0.0148485\n1.8826296\n0.7588656\n2 (1-3)\n\n\n9\nsexo\nSexo\n20204\n0.0000000\n1.5215304\n0.4995486\n1 (1-2)\n\n\n6\nedad\nEdad\n20204\n0.0000000\n40.9985151\n16.5383434\n84 (16-100)\n\n\n8\nidenpa\nidenpa\n20204\n0.0000000\n365.3783409\n260.4932509\n830 (32-862)\n\n\n3\nconf_inst\nConfianza en instituciones\n18768\n7.1075035\n3.3030158\n2.8506243\n12 (0-12)\n\n\n\n\n\nc. Tabla descriptiva con summarytools::dfSummary summarytools::dfSummary\nEsta tercera opción nos ofrece una tabla aún más detallada, con gráficos para cada variable, las frecuencias para cada valor, y las etiquetas de las variables, por lo que es muy recomendable.\nSe específica de la siguiente manera:\n\nsummarytools::dfSummary(proc_data, plain.ascii = FALSE)\n\n### Data Frame Summary  \n#### proc_data  \n**Dimensions:** 20204 x 9  \n**Duplicates:** 2673  \n\n----------------------------------------------------------------------------------------------------------------------------------------------------------\nNo   Variable        Label                           Stats / Values               Freqs (% of Valid)   Graph                          Valid      Missing  \n---- --------------- ------------------------------- ---------------------------- -------------------- ------------------------------ ---------- ---------\n1    conf_gob\\       Confianza: Gobierno             Mean (sd) : 1 (1)\\           0 : 8138 (41.2%)\\    IIIIIIII \\                     19748\\     456\\     \n     [numeric]                                       min &lt; med &lt; max:\\            1 : 6228 (31.5%)\\    IIIIII \\                       (97.7%)    (2.3%)   \n                                                     0 &lt; 1 &lt; 3\\                   2 : 3281 (16.6%)\\    III \\                                              \n                                                     IQR (CV) : 2 (1)             3 : 2101 (10.6%)     II                                                 \n\n2    conf_cong\\      Confianza: Congreso             Mean (sd) : 0.8 (0.9)\\       0 : 8495 (43.8%)\\    IIIIIIII \\                     19382\\     822\\     \n     [numeric]                                       min &lt; med &lt; max:\\            1 : 6905 (35.6%)\\    IIIIIII \\                      (95.9%)    (4.1%)   \n                                                     0 &lt; 1 &lt; 3\\                   2 : 2971 (15.3%)\\    III \\                                              \n                                                     IQR (CV) : 1 (1.1)           3 : 1011 ( 5.2%)     I                                                  \n\n3    conf_jud\\       Confianza: Poder judicial       Mean (sd) : 0.9 (0.9)\\       0 : 7550 (38.8%)\\    IIIIIII \\                      19467\\     737\\     \n     [numeric]                                       min &lt; med &lt; max:\\            1 : 6886 (35.4%)\\    IIIIIII \\                      (96.4%)    (3.6%)   \n                                                     0 &lt; 1 &lt; 3\\                   2 : 3671 (18.9%)\\    III \\                                              \n                                                     IQR (CV) : 2 (1)             3 : 1360 ( 7.0%)     I                                                  \n\n4    conf_partpol\\   Confianza: Partidos politicos   Mean (sd) : 0.6 (0.8)\\       0 : 11097 (56.5%)\\   IIIIIIIIIII \\                  19653\\     551\\     \n     [numeric]                                       min &lt; med &lt; max:\\            1 :  5857 (29.8%)\\   IIIII \\                        (97.3%)    (2.7%)   \n                                                     0 &lt; 0 &lt; 3\\                   2 :  2099 (10.7%)\\   II \\                                               \n                                                     IQR (CV) : 1 (1.3)           3 :   600 ( 3.1%)                                                       \n\n5    educacion\\      Educación                       1\\. Educacion basica\\        7141 (35.3%)\\        IIIIIII \\                      20201\\     3\\       \n     [factor]                                        2\\. Educacion media\\         8290 (41.0%)\\        IIIIIIII \\                     (100.0%)   (0.0%)   \n                                                     3\\. Educacion superior       4770 (23.6%)         IIII                                               \n\n6    sexo\\           Sexo                            1\\. Hombre\\                  9667 (47.8%)\\        IIIIIIIII \\                    20204\\     0\\       \n     [factor]                                        2\\. Mujer                    10537 (52.2%)        IIIIIIIIII                     (100.0%)   (0.0%)   \n\n7    edad\\           Edad                            Mean (sd) : 41 (16.5)\\       81 distinct values   : : :\\                         20204\\     0\\       \n     [numeric]                                       min &lt; med &lt; max:\\                                 : : : \\ \\ .\\                   (100.0%)   (0.0%)   \n                                                     16 &lt; 39 &lt; 100\\                                    : : : : : :\\                                       \n                                                     IQR (CV) : 28 (0.4)                               : : : : : : .\\                                     \n                                                                                                       : : : : : : : .                                    \n\n8    idenpa\\                                         Mean (sd) : 365.4 (260.5)\\   18 distinct values   \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ :\\     20204\\     0\\       \n     [numeric]                                       min &lt; med &lt; max:\\                                 : : . \\ \\ \\ \\ \\ \\ :\\           (100.0%)   (0.0%)   \n                                                     32 &lt; 222 &lt; 862\\                                   : : : . \\ \\ \\ \\ : \\ \\ \\ \\ .\\                       \n                                                     IQR (CV) : 421 (0.7)                              : : : : \\ \\ . : \\ \\ \\ \\ :\\                         \n                                                                                                       : : : : \\ \\ : : \\ \\ \\ \\ :                          \n\n9    conf_inst\\      Confianza en instituciones      Mean (sd) : 3.3 (2.9)\\       13 distinct values   :\\                             18768\\     1436\\    \n     [numeric]                                       min &lt; med &lt; max:\\                                 :\\                             (92.9%)    (7.1%)   \n                                                     0 &lt; 3 &lt; 12\\                                       : \\ \\ \\ \\ .\\                                       \n                                                     IQR (CV) : 4 (0.9)                                : . : : :\\                                         \n                                                                                                       : : : : : . . . \\ \\ .                              \n----------------------------------------------------------------------------------------------------------------------------------------------------------\n\n\nEs muy ancha para visualizar bien en la consola de R, pero en su versión más definitiva de publicación se verá así:\n\nview(dfSummary(proc_data, headings=FALSE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\nconf_gob [numeric]\nConfianza: Gobierno\n\n\n\nMean (sd) : 1 (1)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 1 ≤ 3\n\n\nIQR (CV) : 2 (1)\n\n\n\n\n\n\n0\n:\n8138\n(\n41.2%\n)\n\n\n1\n:\n6228\n(\n31.5%\n)\n\n\n2\n:\n3281\n(\n16.6%\n)\n\n\n3\n:\n2101\n(\n10.6%\n)\n\n\n\n\n19748 (97.7%)\n456 (2.3%)\n\n\n2\nconf_cong [numeric]\nConfianza: Congreso\n\n\n\nMean (sd) : 0.8 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 1 ≤ 3\n\n\nIQR (CV) : 1 (1.1)\n\n\n\n\n\n\n0\n:\n8495\n(\n43.8%\n)\n\n\n1\n:\n6905\n(\n35.6%\n)\n\n\n2\n:\n2971\n(\n15.3%\n)\n\n\n3\n:\n1011\n(\n5.2%\n)\n\n\n\n\n19382 (95.9%)\n822 (4.1%)\n\n\n3\nconf_jud [numeric]\nConfianza: Poder judicial\n\n\n\nMean (sd) : 0.9 (0.9)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 1 ≤ 3\n\n\nIQR (CV) : 2 (1)\n\n\n\n\n\n\n0\n:\n7550\n(\n38.8%\n)\n\n\n1\n:\n6886\n(\n35.4%\n)\n\n\n2\n:\n3671\n(\n18.9%\n)\n\n\n3\n:\n1360\n(\n7.0%\n)\n\n\n\n\n19467 (96.4%)\n737 (3.6%)\n\n\n4\nconf_partpol [numeric]\nConfianza: Partidos politicos\n\n\n\nMean (sd) : 0.6 (0.8)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 0 ≤ 3\n\n\nIQR (CV) : 1 (1.3)\n\n\n\n\n\n\n0\n:\n11097\n(\n56.5%\n)\n\n\n1\n:\n5857\n(\n29.8%\n)\n\n\n2\n:\n2099\n(\n10.7%\n)\n\n\n3\n:\n600\n(\n3.1%\n)\n\n\n\n\n19653 (97.3%)\n551 (2.7%)\n\n\n5\neducacion [factor]\nEducación\n\n\n\n1. Educacion basica\n\n\n2. Educacion media\n\n\n3. Educacion superior\n\n\n\n\n\n\n7141\n(\n35.3%\n)\n\n\n8290\n(\n41.0%\n)\n\n\n4770\n(\n23.6%\n)\n\n\n\n\n20201 (100.0%)\n3 (0.0%)\n\n\n6\nsexo [factor]\nSexo\n\n\n\n1. Hombre\n\n\n2. Mujer\n\n\n\n\n\n\n9667\n(\n47.8%\n)\n\n\n10537\n(\n52.2%\n)\n\n\n\n\n20204 (100.0%)\n0 (0.0%)\n\n\n7\nedad [numeric]\nEdad\n\n\n\nMean (sd) : 41 (16.5)\n\n\nmin ≤ med ≤ max:\n\n\n16 ≤ 39 ≤ 100\n\n\nIQR (CV) : 28 (0.4)\n\n\n\n81 distinct values\n\n20204 (100.0%)\n0 (0.0%)\n\n\n8\nidenpa [numeric]\n\n\n\n\nMean (sd) : 365.4 (260.5)\n\n\nmin ≤ med ≤ max:\n\n\n32 ≤ 222 ≤ 862\n\n\nIQR (CV) : 421 (0.7)\n\n\n\n18 distinct values\n\n20204 (100.0%)\n0 (0.0%)\n\n\n9\nconf_inst [numeric]\nConfianza en instituciones\n\n\n\nMean (sd) : 3.3 (2.9)\n\n\nmin ≤ med ≤ max:\n\n\n0 ≤ 3 ≤ 12\n\n\nIQR (CV) : 4 (0.9)\n\n\n\n13 distinct values\n\n18768 (92.9%)\n1436 (7.1%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2024-05-30\n\n\n\n\n\nNota sobre casos perdidos (NAs) na.omit(data)\nHasta ahora hemos mantenido los casos perdidos en la base de datos, ya que son importantes de reportar en la tabla general de variables. Sin embargo, de aquí en adelante se recomienda trabajar solo con casos completos, es decir, sacar los casos perdidos. El quitar los casos perdidos de una base de datos es muy simple con la función na.omit, pero para tomar precauciones y asegurarse que funciona se recomienda el siguiente procedimiento:\n\nrespaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos), la dejaremos con el nombre proc_data_original.\ncontamos el número de casos con el comando dim\ncontamos el número de casos perdidos con sum(is.na(proc_data))\nborramos los casos perdidos con proc_data &lt;-na.omit(proc_data)\ncontamos nuevamente con dim para asegurarnos que se borraron\ny por temas de funcionamiento de R, al realizar la operación de sacar casos perdidos, se borra toda la información de las etiquetas (labels), así que las recuperamos de la base original con el comando copy_labels, de la librería sjlabelled.\n\n\nproc_data_original &lt;-proc_data\ndim(proc_data)\n\n[1] 20204     9\n\nsum(is.na(proc_data))\n\n[1] 4005\n\nproc_data &lt;-na.omit(proc_data)\ndim(proc_data)\n\n[1] 18765     9\n\nproc_data &lt;-sjlabelled::copy_labels(proc_data,proc_data_original)\n\n\n\n\n3.2 Visualización de variables\nPara visualizar variables mediante gráficos, en R el paquete más comúnmente usado es ggplot2. La lógica detrás de este paquete es que funciona por capas.\n\nggplot()\n\n\n\n\n\n\n\n\n\nggplot(proc_data, aes(x = conf_inst))\n\n\n\n\n\n\n\n\n\nproc_data %&gt;% ggplot(aes(x = conf_inst)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\nproc_data %&gt;% ggplot(aes(x = conf_inst)) + \n  geom_bar(fill = \"coral\")\n\n\n\n\n\n\n\n\n\nproc_data %&gt;% ggplot(aes(x = conf_inst)) + \n  geom_bar(fill = \"coral\")+\n  labs(title = \"Confianza en instituciones\",\n       x = \"Confianza en instituciones\",\n       y = \"Frecuencia\")\n\n\n\n\n\n\n\n\n\n# Crear el gráfico usando ggplot2\ngraph1 &lt;- proc_data %&gt;% ggplot(aes(x = conf_inst)) + \n  geom_bar(fill = \"coral\")+\n  labs(title = \"Confianza en instituciones\",\n       x = \"Confianza en instituciones\",\n       y = \"Frecuencia\") +\n  geom_text(aes(label = ..count..), stat = \"count\", colour = \"black\", \n    vjust = 1.5, position = position_dodge(.9)) + # agregamos freq de cada barra por grupo\n  theme_bw()\n\ngraph1\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n# y lo podemos guardar:\n\nggsave(graph1, file=\"output/graphs/graph1.png\")\n\nSaving 7 x 5 in image\n\n\n\n\n3.3 Exploración de asociación entre variables\nDado que las hipótesis de investigación corresponden a asociación entre variables, antes de realizar el contraste de hipótesis se suele presentar un análisis descriptivo que explora las asociaciones entre variables.\nLa forma de explorar las asociaciones entre variables dependen de la naturaleza de las variables que se asocian:\n\nVariables categóricas: tabla de contingencia\nVariable categórica y continua: tabla de promedios por cada categoría\n\nEn esta sección también es muy relevante la visualización de datos mediante gráficos, por lo que incluiremos algunos.\nEl uso tanto de tablas como de gráficos en el reporte queda a discreción del/a autor/a. La pregunta que orienta esta decisión es: ¿Me permite enriquecer la discusión de los resultados en relación a las hipótesis planteadas?\n\nTablas de contingencia para variables categóricas\nPara tablas de contingencia categóricas utilizaremos la función sjt.xtab, de la librería sjPlot. Veamos primero una especificación simple: sjPlot::sjt.xtab\n\nsjt.xtab(proc_data$educacion, proc_data$sexo)\n\n\n \n Educación\n Sexo\n Total\n \n \n\n Hombre\n Mujer\n \n \n \nEducacion basica\n3027\n3216\n6243 \n\n \n \nEducacion media\n3845\n4041\n7886 \n\n \n \nEducacion superior\n2252\n2384\n4636 \n\n \n \nTotal\n9124\n9641\n18765 \n\nχ2=0.108 · df=2 · Cramer's V=0.002 · p=0.948 \n\n \n\n\n\nAl ejecutar el comando, el resultado aparece automáticamente en el visor de RStudio. A esta tabla podemos también agregar porcentajes de filas y/o columnas, según sea lo más relevante analizar. En general se recomienda agregar solo un porcentaje, de otra manera la tabla se satura de información. Además, vamos a quitar el pie de la tabla (conviene dejarlo solo si hay hipótesis asociadas al cruce simple entre las dos variables).\n\nsjt.xtab(proc_data$educacion, proc_data$sexo,\n        show.col.prc=TRUE,\n        show.summary=FALSE,\n        encoding = \"UTF-8\",\n        file=\"output/tables/tabla-contingencia.html\")\n\n\n\n\n\n\n\n\n\n\n\nEducación\nSexo\nTotal\n\n\nHombre\nMujer\n\n\nEducacion basica\n3027\n33.2 %\n3216\n33.4 %\n6243\n33.3 %\n\n\nEducacion media\n3845\n42.1 %\n4041\n41.9 %\n7886\n42 %\n\n\nEducacion superior\n2252\n24.7 %\n2384\n24.7 %\n4636\n24.7 %\n\n\nTotal\n9124\n100 %\n9641\n100 %\n18765\n100 %\n\n\n\n\n\n\n\n\nTablas de promedio de variable continua por una categóricas\nEn ejemplo vamos a explorar datos de nuestra variable de confianza en instituciones conf_inst por los niveles educacionales educacion.\nUna forma rápida de explorar esto es mediante la función tapply, que nos entrega de manera simple el promedio de una variable por otra:\n\ntapply(proc_data$conf_inst, proc_data$educacion, mean)\n\n  Educacion basica    Educacion media Educacion superior \n          3.396604           3.229647           3.303063 \n\n\nAquí vemos en promedio de conf_inst para cada uno de los 3 niveles de la variable educación educacion. Si se estima conveniente este tipo de cruces se puede representar también en una tabla con más opciones de información y también de publicación. Para esto utilizaremos una función algo más compleja de la librería dplyr.dplyr Esta librería permite aplicar una serie de funciones concatenadas y enlazadas mediante el operador %&gt;%. El sentido de cada función aparece comentado abajo:\n\nproc_data %&gt;% # se especifica la base de datos\n  select(conf_inst,educacion) %&gt;% # se seleccionan las variables\n  dplyr::group_by(Educación=sjlabelled::as_label(educacion)) %&gt;% # se agrupan por la variable categórica y se usan sus etiquetas con as_label\n  dplyr::summarise(Obs.=n(),Promedio=mean(conf_inst),SD=sd(conf_inst)) %&gt;% # se agregan las operaciones a presentar en la tabla\n  kable(., format = \"markdown\") # se genera la tabla\n\n\n\n\nEducación\nObs.\nPromedio\nSD\n\n\n\n\nEducacion basica\n6243\n3.396604\n3.038681\n\n\nEducacion media\n7886\n3.229648\n2.751494\n\n\nEducacion superior\n4636\n3.303063\n2.749961\n\n\n\n\n\nEsta asociación también se puede representar de manera más simple con un gráfico, en este caso de cajas o boxplot mediante la función geom_boxplot de gplot2:\n\ngraph &lt;- ggplot(proc_data, aes(x =educacion, y = conf_inst)) +\n  geom_boxplot() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_minimal()\n\ngraph\n\n\n\n\n\n\n\n# y lo podemos guardar:\n\nggsave(graph, file=\"output/graphs/graph.png\")\n\nSaving 7 x 5 in image\n\n\nSin embargo, al ser los promedios similares no permite ver demasiadas diferencias… Probemos otro\n\nggplot(proc_data, aes(x =educacion, y = conf_inst)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nEn este gráfico cada punto representa una observación para cada categoría. Por lo tanto, al existir tantos valores difernetes en cada categoría, el gráfico tampoco nos presenta información sustantiva ¿Qué necesitamos hacer? Necesitamos obtener exactamente los datos que queremos graficar, esto es, el promedio por cada categoría. Volvamos a group_by\n\ndatos &lt;- proc_data %&gt;% group_by(educacion) %&gt;% \n  summarise(promedio = mean(conf_inst))\n\nggplot(datos, aes(x =educacion, y = promedio)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_minimal()+\n  ylim(0, 12)\n\n\n\n\n\n\n\n\nEste gráfico entrega un poco más de información, pero al ver pocas diferencias en el promedio de cada categoría no se logran evidenciar\n\nproc_data$idenpa &lt;- factor(proc_data$idenpa,\n            labels=c(\"Argentina\",\n         \"Bolivia\",\n         \"Brasil\",\n         \"Chile\",\n         \"Colombia\",\n         \"Costa Rica\",\n         \"Cuba\",\n         \"República Dominicana\",\n         \"Ecuador\",\n         \"El Salvador\",\n         \"Guatemala\",\n         \"Honduras\",\n         \"México\",\n         \"Nicaragua\",\n         \"Panamá\",\n         \"Paraguay\",\n         \"Uruguay\",\n         \"Venezuela\"),\n            levels=c(\"32\",\n         \"68\",\n         \"76\",\n         \"152\",\n         \"170\",\n         \"188\",\n         \"214\",\n         \"218\",\n         \"222\",\n         \"320\",\n         \"340\",\n         \"484\",\n         \"558\",\n         \"591\",\n         \"600\",\n         \"604\",\n         \"858\",\n         \"862\"))\n\n\ngraph_box &lt;- ggplot(proc_data, aes(x = idenpa, y = conf_inst)) +\n  geom_boxplot() +\n  labs(x = \"País\", y = \"Confianza en instituciones\") +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotar las etiquetas del eje x\n\ngraph_box\n\n\n\n\n\n\n\n# y lo podemos guardar:\n\nggsave(graph_box, file=\"output/graphs/graph.png\")\n\nSaving 7 x 5 in image\n\n\nDe manera alternativa, podemos seguir explorando nuestros datos con otros gráficos\nPara varias variables univariadas, tipo escala likert, una buena alternativa es el paquete sjPlot, en este caso la función plot_stackfrq:\n\ngraph2 &lt;- sjPlot::plot_stackfrq(dplyr::select(proc_data, conf_gob,\n                                 conf_cong,\n                                 conf_jud,\n                                 conf_partpol),\n                                 title = \"Confianza en instituciones políticas\") +\n  theme(legend.position=\"bottom\")\n\ngraph2\n\n\n\n\n\n\n\n# Guardamos\n\nggsave(graph2, file=\"output/graphs/graph2.png\")\n\nSaving 7 x 5 in image\n\n\nPara asociación de dos variables, retomemos el primer gráfico:\n\ngraph3 &lt;- proc_data %&gt;% ggplot(aes(x = conf_inst, fill = sexo)) + \n  geom_bar(position = \"dodge2\") +\n  xlab(\"Confianza en instituciones\") +\n  ylab(\"Cantidad\") + \n  labs(fill=\"Sexo\")+\n  scale_fill_discrete(labels = c('Hombre','Mujer'))+\n  geom_text(aes(label = ..count..), stat = \"count\", colour = \"black\", \n    vjust = 1.5, position = position_dodge(.9)) # agregamos freq de cada barra por grupo\n\ngraph3\n\n\n\n\n\n\n\n# Guardamos\n\nggsave(graph3, file=\"output/graphs/graph3.png\")\n\nSaving 7 x 5 in image\n\n\nuna forma alternativa:\n\nproc_data %&gt;% ggplot(aes(x = conf_inst, fill = sexo)) + \n  geom_bar() +\n  xlab(\"Confianza en instituciones\") +\n  ylab(\"Cantidad\") + \n  labs(fill=\"Sexo\")+\n  scale_fill_discrete(labels = c('Hombre','Mujer'))\n\n\n\n\n\n\n\n\notra forma alternativa:\n\nproc_data %&gt;% ggplot(aes(x = conf_inst)) + \n  geom_bar() +\n  xlab(\"Confianza en instituciones\") +\n  ylab(\"Cantidad\")+\n  facet_wrap(~sexo)+\n  geom_text(aes(label = ..count..), stat = \"count\", colour = \"white\", \n    vjust = 1.5, position = position_dodge(.9)) # agregamos freq de cada barra por grupo\n\n\n\n\n\n\n\n\nPara variables continuas\n\ngraph4 &lt;- ggplot(proc_data, aes(x = as.numeric(edad))) +\n  geom_histogram(binwidth=0.6, colour=\"black\", fill=\"yellow\") +\n  theme_bw() +\n  xlab(\"Edad\") +\n  ylab(\"Cantidad\")\n\ngraph4 \n\n\n\n\n\n\n\n# Guardamos\n\nggsave(graph4, file=\"output/graphs/graph4.png\")\n\nSaving 7 x 5 in image\n\n\ny lo podemos complicar un poco más…\n\n\n\nAsociación entre tres variables\ncon facet_wrap dividimos el gráfico en distintos paneles, según la cantidad de categorías que tenga una variable\n\ndatos &lt;- proc_data %&gt;% group_by(educacion, sexo) %&gt;% \n  summarise(promedio = mean(conf_inst))\n\n`summarise()` has grouped output by 'educacion'. You can override using the\n`.groups` argument.\n\nggplot(datos, aes(x =educacion, y = promedio)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_bw()+\n  ylim(0, 12)+\n  facet_wrap(~sexo)\n\n\n\n\n\n\n\n\no alternativamente…\n\nggplot(datos, aes(x =sexo, y = promedio)) +\n  geom_point() +\n  labs(x = \"Sexo\", y = \"Confianza en instituciones\") +\n  theme_bw()+\n  ylim(0, 12)+\n  facet_wrap(~educacion)\n\n\n\n\n\n\n\n\nProbemos otras agrupaciones. Por ejemplo, categorizar edad en grupos para estimar promedios grupales. Una función clave para lograr esto puede ser case_when de dplyr, combinándolo con mutate. Es decir, crear una nueva variable a partir de un condicional\n\nsummary(proc_data$edad)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  16.00   26.00   38.00   40.53   53.00  100.00 \n\nproc_data &lt;- proc_data %&gt;% \n  mutate(edad_groups = case_when(edad &gt;=16 & edad&lt;=25 ~ \"Entre 16 y 25 años\",\n                                 edad &gt;=26 & edad&lt;=39 ~ \"Entre 26 y 39 años\",\n                                 edad &gt;=40 & edad&lt;=65 ~ \"Entre 40 y 65 años\",\n                                 edad &gt;65 ~ \"Más de 65 años\"))\n\ntable(proc_data$edad_groups)\n\n\nEntre 16 y 25 años Entre 26 y 39 años Entre 40 y 65 años     Más de 65 años \n              4304               5487               7390               1584 \n\n\nAhora creamos este gráfico\n\ndatos &lt;- proc_data %&gt;% group_by(educacion, edad_groups) %&gt;% \n  summarise(promedio = mean(conf_inst))\n\n`summarise()` has grouped output by 'educacion'. You can override using the\n`.groups` argument.\n\nggplot(datos, aes(x =educacion, y = promedio)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_bw()+\n  ylim(0, 7)+\n  facet_wrap(~edad_groups)\n\n\n\n\n\n\n\n\ny lo podemos seguir complicando, por ejemplo, agregando otra variable en el gráfico\n\ndatos &lt;- proc_data %&gt;% group_by(educacion, sexo, edad_groups) %&gt;% \n  summarise(promedio = mean(conf_inst))\n\n`summarise()` has grouped output by 'educacion', 'sexo'. You can override using\nthe `.groups` argument.\n\nggplot(datos, aes(x =educacion, y = promedio, color=sexo)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_bw()+\n  ylim(0, 7)+\n  facet_wrap(~edad_groups)\n\n\n\n\n\n\n\n\nCon ‘color’ (gráfico anterior) solo se diferencia la variable según color. Con ‘shape’ (gráfico siguiente) también se diferencia según la forma de la representación\n\nggplot(datos, aes(x =educacion, y = promedio, color=sexo, shape=sexo)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_bw()+\n  ylim(0, 7)+\n  facet_wrap(~edad_groups)\n\n\n\n\n\n\n\n\nY tenemos aún un problema… las categorías del eje x se están solapando. Eso lo podemos corregir modificando el ángulo del eje x.\n\nggplot(datos, aes(x = educacion, y = promedio, color = sexo, shape = sexo)) +\n  geom_point() +\n  labs(x = \"Educación\", y = \"Confianza en instituciones\") +\n  theme_bw() +\n  ylim(0, 7) +\n  facet_wrap(~edad_groups) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))",
    "crumbs": [
      "Practicos",
      "Práctico 6"
    ]
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Recursos",
    "section": "",
    "text": "Acceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.3.2\n\n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto (o en blanco):\n\n\n\n\n\n\n\n\nNota\n\n\n\nAlternativa a lo anterior: https://posit.cloud/\n\nVersión online de Rstudio\nUtilizar en caso de problemas con PC",
    "crumbs": [
      "Practicos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#r-y-rstudio",
    "href": "resource/index.html#r-y-rstudio",
    "title": "Recursos",
    "section": "",
    "text": "Acceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.3.2\n\n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto (o en blanco):\n\n\n\n\n\n\n\n\nNota\n\n\n\nAlternativa a lo anterior: https://posit.cloud/\n\nVersión online de Rstudio\nUtilizar en caso de problemas con PC",
    "crumbs": [
      "Practicos",
      "Descripción"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "::: {.grid .course-details .course-details-smaller}"
  },
  {
    "objectID": "syllabus.html#resumen",
    "href": "syllabus.html#resumen",
    "title": "Programa",
    "section": "Resumen",
    "text": "Resumen\nEste curso busca dar un primer acercamiento a la investigación social cuantitativa, abarcando desde aspectos iniciales básicos de estadística descriptiva y visualización de datos, hasta análisis e interpretación de modelos explicativos de investigación social. Asimismo, se busca que los y las estudiantes logren familiarizarse con el uso de Rstudio para el análisis de datos sociales.\nLa metodología incluye clases lectivas y trabajo práctico en R."
  },
  {
    "objectID": "syllabus.html#objetivo-general",
    "href": "syllabus.html#objetivo-general",
    "title": "Programa",
    "section": "Objetivo general",
    "text": "Objetivo general\nAl finalizar el curso, el/la estudiante podrá elaborar y analizar diseños de investigación social de carácter cuantitativo, así como describir cuantitativamente un conjunto de datos utilizando el lenguaje R."
  },
  {
    "objectID": "syllabus.html#objetivos-específicos",
    "href": "syllabus.html#objetivos-específicos",
    "title": "Programa",
    "section": "Objetivos específicos",
    "text": "Objetivos específicos\nAl concluir el curso lo/as estudiantes deberán haber alcanzado los siguientes resultados de aprendizaje:\n\nConocer las etapas de un diseño de investigación social cuantitativa y sus principales elementos\nFormular diseños de investigación social cuantitativa\nConocer y aplicar instrumentos de medición y tipos de estudios cuantitativos\nInterpretar y analizar los elementos centrales de una base de datos con información social\nAplicar e interpretar técnicas de estadística descriptiva según las distintas características de los datos\nAplicar e interpretar técnicas de estadística correlacional e inferencia estadística para variables con distinta unidad de medida\nAplicar e interpretar técnicas de regresión lineal y logística para variables numéricas y variables categóricas"
  },
  {
    "objectID": "syllabus.html#saberes-contenidos",
    "href": "syllabus.html#saberes-contenidos",
    "title": "Programa",
    "section": "Saberes / contenidos",
    "text": "Saberes / contenidos\n\nMódulo 1: Estadística descriptiva\n1.1 Elementos básicos de la investigación social\n\nEtapas de la investigación Social\nTipos de diseños\nDiseño de instrumentos de medición\nBases de datos: datos de corte transversal, series de tiempo, cohortes, panel o longitudinal\n\n1.2 Operacionalización y análisis de datos\n\nOperacionalización y niveles de medición\nTidy data: unir, dividir, filtrar y ordenar datos en R\nRecodificación de variables: descriptivos básicos, casos perdidos, etiquetamiento de variables\nAgrupación de datos y construcción de variables a partir de datos existentes\nConstrucción de índices y validez de escalas\n\n1.3 Visualización de datos en R\n\nTablas descriptivas y tablas de contingencia\nggplot2: gráficos de barra, de caja, dispersión e histograma\n\n\n\nMódulo 2: Inferencia y estadística correlacional\n2.1 Inferencia estadística\n2.2 Pruebas de hipótesis\n2.3 Correlación\n\n\nMódulo 3: Regresión lineal y regresión logística\n3.1 Regresión lineal de mínimos cuadrados\n\nAspectos centrales y supuestos de la regresión MCO\nInterpretación de coeficientes (variables cuantitativas y cualitativas) y efectos de interacción\nRepresentación gráfica de coeficientes de regresión lineal\n\n3.2 Regresión logística binaria\n\nAspectos básicos de la regresión logística\nTipos de coeficientes e interpretación\nRepresentación gráfica (cálculo de probabilidades predichas)"
  },
  {
    "objectID": "syllabus.html#bibliografía",
    "href": "syllabus.html#bibliografía",
    "title": "Programa",
    "section": "Bibliografía",
    "text": "Bibliografía\nWickham, Hadley & Grolemund, Garrett (2017). R for Data Science. Visualize, model, transform, tidy and import data. / Versión en español disponible acá\nMoore, D. S., & Comas, J. (2010). Estadística aplicada básica. Barcelona: Antoni Bosch.\nWooldridge, J. M. (2008). Introducción a la econometría: un enfoque moderno. Paraninfo Cengage Learning.\nCamarero, et al (2017) Regresión Logística: Fundamentos y aplicación a la investigación sociológica.\nHair, Joseph F., et al. (2004). Análisis multivariante. 5ta ed. Madrid: Prentice Hall.\nCharte, Francisco (2014). Análisis exploratorio y Visualización de datos con R."
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\nEl curso se organiza en sesiones semanales, con una parte lectiva seguida de una práctica. En la parte lectiva se transmiten y discuten los conceptos centrales de la investigación cuantitativa. En la parte práctica se aplicarán los conceptos transmitidos en la parte lectiva, además de resolver dudas en el avance de los trabajos de investigación"
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "Evaluación",
    "text": "Evaluación\nLa evaluación consistirá en"
  },
  {
    "objectID": "syllabus.html#requisitos-de-aprobación",
    "href": "syllabus.html#requisitos-de-aprobación",
    "title": "Programa",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\n\nNota mínima de aprobación: 4,0 (en escala de 1 a 7)."
  },
  {
    "objectID": "syllabus.html#palabras-clave",
    "href": "syllabus.html#palabras-clave",
    "title": "Programa",
    "section": "Palabras Clave",
    "text": "Palabras Clave\n\nEstadística, investigación cuantitativa, manipulación de datos, visualización de datos, interpretación de coeficientes"
  }
]